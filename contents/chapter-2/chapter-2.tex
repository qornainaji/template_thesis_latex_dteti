\chapter{Tinjauan Pustaka dan Dasar Teori}

% \section{Tinjauan Pustaka}

% Pada bab ini, akan dibahas mengenai dasar teori, penelitian sebelumnya yang berkaitan dengan penggunaan
% data \textit{learning analytics} untuk meningkatkan performa LLM dalam memberikan umpan balik 

Pada bab ini dibahas dasar teori dan penelitian sebelumnya yang berkaitan 
dengan penggunaan data \textit{learning analytics} dan teknik 
\textit{context engineering} (termasuk \textit{prompt engineering}) untuk 
meningkatkan performa LLM dalam memberikan umpan balik (kognitif), dukungan 
motivasional, dan dukungan apresiatif. Uraian dimulai dari landasan 
\textit{Self‑Regulated Learning} (SRL) dan peran umpan balik dalam fase 
perencanaan, pelaksanaan, dan refleksi. Kemudian mendefinisikan 
\textit{prompt engineering} serta \textit{context engineering} beserta 
perbedaan keduanya dan implikasinya bagi rancangan sistem tutor‑AI. 
Selanjutnya, bab ini menguraikan konsep \textit{learning analytics}—cakupan, 
sumber data proses (mis. log LMS, urutan aktivitas, \textit{time‑on‑task}, 
perpindahan tugas, beban/WIP), serta cara mengekstraksinya—dan bagaimana 
sinyal‑sinyal tersebut direkayasa menjadi konteks \textit{prompt} agar LLM 
mampu menghasilkan bimbingan yang lebih terstruktur, \textit{actionable}, 
koheren, dan berempati. Bagian tinjauan juga membandingkan karya‑karya 
terkait yang mengintegrasikan LA dan LLM (misalnya pendekatan berbasis 
\textit{knowledge tracing} dan pemetaan kesalahan untuk umpan balik 
personal) guna menegaskan posisi penelitian ini, sekaligus menyoroti isu 
skalabilitas umpan balik personal dan kebutuhan evaluasi hibrida kualitas 
respons. Sebagai penutup, bab ini merangkum kesenjangan penelitian dan 
menjelaskan kontribusi yang diusulkan—yakni \textit{pipeline} perakitan 
konteks berbasis \textit{learning analytics} yang instrumen‑agnostik 
(Kanban hanya digunakan sebagai alat pengumpul/penyaji data proses), untuk meningkatkan 
kualitas respons LLM agar mendekati mutu pakar manusia baik secara kuantitatif maupun 
kualitatif.

\section{Dasar Teori}

% buatkan saya text pengantar dasar teorinya.
Bagian ini menyajikan landasan konseptual yang menopang rancangan dan metode penelitian. 
Pertama, diringkas prinsip \textit{Self-Regulated Learning} (SRL)—termasuk peran umpan balik 
dalam fase perencanaan, pelaksanaan, dan refleksi—serta kaitannya dengan tiga fungsi pedagogis 
yang dinilai pada penelitian ini: \textit{feedback} kognitif, dukungan motivasional, 
dan dukungan apresiatif. Kedua, diuraikan konsep \textit{prompt engineering} sebagai 
praktik perumusan instruksi bagi LLM dan \textit{context engineering} sebagai pengelolaan 
muatan informasi/konteks yang dipasok ke model; perbedaan keduanya serta implikasinya bagi 
desain tutor-AI juga dibahas untuk menegaskan peran masing-masing. Ketiga, dipaparkan 
\textit{learning analytics} (LA) yang mencakup definisi, ruang lingkup, dan jenis data proses (mis. 
log LMS, urutan aktivitas, \textit{time-on-task}, perpindahan tugas, beban/WIP) beserta 
cara ekstraksinya. Pada akhirnya, dijelaskan bagaimana sinyal-sinyal LA tersebut direkayasa 
menjadi konteks \textit{prompt} agar LLM menghasilkan umpan balik yang lebih terstruktur, 
\textit{actionable}, koheren, dan berempati, sekaligus menekankan kebutuhan evaluasi hibrida 
(acuan pakar + metrik kuantitatif–kualitatif) untuk memastikan kualitas respons LLM mendekati 
mutu pakar manusia. 
% Urutan pembahasan pada bagian ini mengikuti alur: 
% (i) \textit{Prompt Engineering}, 
% (ii) \textit{Context Engineering}, 
% (iii) perbedaan keduanya, 
% dan (iv) \textit{Learning Analytics}, 
% yang kemudian menjadi pijakan operasional pada bab metode. 

\subsection{\textit{Self Regulated Learning} (SRL) dan Peran Umpan Balik}
% Self-Regulated Learning (SRL) atau pembelajaran regulasi diri adalah konsep di mana peserta didik 
% secara aktif mengarahkan dan mengontrol proses belajarnya sendiri. Menurut teori sosial-kognitif 
% Zimmerman (2000), SRL merupakan proses siklikal yang mencakup fase perencanaan, pelaksanaan, 
% dan evaluasi [7]. Dalam fase perencanaan, mahasiswa menetapkan tujuan belajar dan merencanakan 
% strategi; fase pelaksanaan melibatkan penerapan strategi kognitif (misalnya membaca, membuat 
% catatan) serta pemantauan metakognitif (misalnya manajemen waktu) untuk menyelesaikan tugas; 
% sedangkan fase evaluasi mencakup penilaian diri terhadap kemajuan belajar dan hasil yang dicapai [7]. 
% Melalui siklus ini, mahasiswa dengan SRL tinggi akan merefleksikan capaian mereka dan menyesuaikan 
% pendekatan belajarnya secara mandiri agar tujuan pembelajaran tercapai [7].

% Di tingkat pendidikan tinggi, SRL memegang peran krusial dalam menentukan keberhasilan akademik. 
% Penelitian menunjukkan bahwa kemampuan regulasi diri berhubungan erat dengan kesuksesan mahasiswa 
% di perguruan tinggi [7]. Mahasiswa yang terampil dalam SRL cenderung lebih berhasil karena mereka 
% mampu merencanakan, menetapkan tujuan, mengorganisasi kegiatan belajar, serta melakukan evaluasi 
% diri secara berkelanjutan selama proses pembelajaran [7]. Kemampuan-kemampuan ini membantu 
% mahasiswa belajar lebih efektif dan mandiri.

% Lebih lanjut, berbagai studi di pendidikan tinggi telah mengaitkan SRL dengan sejumlah indikator 
% positif: kinerja akademik yang lebih baik, tingkat retensi (ketahanan studi) yang lebih tinggi, 
% keterlibatan yang lebih mendalam dalam aktivitas perkuliahan, dan kemampuan adaptasi yang lebih 
% baik terhadap kehidupan kampus [7]. Sebagai contoh, mahasiswa yang menguasai strategi SRL 
% dilaporkan memiliki prestasi yang lebih tinggi dan risiko putus studi yang lebih rendah [7]. 
% Intervensi pendidikan yang dirancang untuk meningkatkan keterampilan regulasi diri juga 
% terbukti efektif memperbaiki performa akademis dan mencegah dropout mahasiswa [7]. Hal ini 
% menegaskan bahwa mengembangkan kompetensi SRL pada mahasiswa merupakan investasi penting 
% dalam meningkatkan kualitas pembelajaran di pendidikan tinggi.

% Pendidikan tinggi menuntut mahasiswa untuk lebih mandiri dan proaktif dalam belajar. Mahasiswa 
% tidak selalu dibimbing secara intens seperti di jenjang sebelumnya; karena itu, kemampuan 
% regulasi diri menjadi kunci. Apalagi dengan berkembangnya pembelajaran daring dan blended 
% learning, SRL semakin esensial. Studi terbaru menekankan bahwa dalam lingkungan belajar 
% online, mahasiswa dituntut memiliki kapasitas regulasi diri lebih besar dibandingkan 
% pendidikan tatap muka [7]. Tanpa SRL yang memadai, kesenjangan dalam penguasaan materi dan 
% keterampilan belajar dapat semakin lebar saat pembelajaran beralih ke moda daring [7]. 
% Oleh sebab itu, perguruan tinggi masa kini menghadapi tantangan untuk membekali mahasiswa 
% dengan keterampilan SRL agar mereka dapat sukses, baik dalam konteks pembelajaran 
% konvensional maupun digital.





% [1] Panadero, E., & Alonso-Tapia, J. (2016). Self-assessment: Theoretical and practical connotations, when it happens, how is it acquired, and what to do to develop it in our students. Electronic Journal of Research in Educational Psychology, 14(1), 551-576.
% [2] Zimmerman, B. J. (2000). Attaining self-regulation: A social cognitive perspective. In Handbook of self-regulation (pp. 13-39). Academic Press.
% [3] Hattie, J., & Timperley, H. (2007). The power of feedback. Review of Educational Research, 77(1), 81-112.
% [4] Wisniewski, B., Zierer, K., & Hattie, J. (2020). The power of feedback revisited: A meta-analysis of educational feedback research. Frontiers in Psychology, 10, 3087.
% [5] Sun, D., Xu, P., Zhang, J., Liu, R., & Zhang, J. (2025). How Self-Regulated Learning Is Affected by Feedback Based on Large Language Models: Data-Driven Sustainable Development in Computer Programming Learning. Electronics, 14(1), 194.
% [6] Nakata, Y., Wang, C., & Yamamoto, Y. (2025). Student perceptions of feedback and self-regulated language learning: A mixed-methods investigation. System, 131, 103654.
% [7] Lobos, K., Cobo-Rendón, R., Jofré, D. B., & Santana, J. (2024). New challenges for higher education: self-regulated learning in blended learning contexts. Frontiers in Education, 9, 1457367.
% [8] Steinert, S., Küchemann, S., Avila, K. E., et al. (2024). Harnessing large language models to develop research-based learning assistants for formative feedback. Smart Learning Environments, 11(1), 30.

\textit{Self-Regulated Learning} (SRL) merujuk pada kapasitas mahasiswa untuk secara aktif merencanakan, 
memantau, dan mengevaluasi proses belajarnya sendiri, melalui siklus 
perencanaan, pelaksanaan, dan refleksi yang saling terkait [1], [2]. Pada fase perencanaan, 
mahasiswa menetapkan tujuan serta strategi. Lalu, pada fase pelaksanaan, mereka menerapkan strategi 
kognitif dan melakukan pemantauan metakognitif (mis. manajemen waktu, monitoring pemahaman). 
Kemudian, pada fase refleksi, mahasiswa melibatkan penilaian diri terhadap kemajuan dan hasil untuk 
menyesuaikan strategi berikutnya [1], [2]. Berbekal mekanisme siklikal ini, SRL menggabungkan 
dimensi kognitif, motivasional, dan perilaku yang bersama-sama menentukan kualitas belajar 
mandiri di pendidikan tinggi [1], [2].

Di konteks pendidikan tinggi, SRL berperan krusial karena lingkungan belajar menuntut kemandirian,
terutama pada pembelajaran digital (daring atau campuran) yang memerlukan disiplin diri lebih tinggi
serta kemampuan mengelola distraksi. Kajian terkini menunjukkan bahwa SRL berkorelasi dengan
kinerja akademik, keterlibatan, dan ketahanan studi. Sebaliknya, kekurangan SRL di
pembelajaran daring atau campuran dapat memperlebar kesenjangan capaian yang diperoleh 
mahasiswa [3]. Dengan demikian,
pengembangan kompetensi SRL termasuk penetapan tujuan, strategi, monitoring, dan
refleksi—menjadi prasyarat penting untuk keberhasilan mahasiswa di ekosistem belajar
modern [2], [3].

Kemajuan \textit{Large Language Models} (LLM) membuka peluang penyediaan 
bimbingan pengarahan (\textit{feedback}) yang personal, 
cepat, dan interaktif untuk menopang SRL. 
Studi eksperimental di konteks pemrograman (pendidikan tinggi) menunjukkan 
\textit{feedback} berbasis LLM dapat meningkatkan strategi metakognitif, 
motivasi, dan performa mahasiswa dibanding kondisi 
tanpa \textit{feedback} dari AI [6]. Riset pengembangan menunjukkan asisten belajar 
berbasis LLM yang dirancang dengan prinsip-prinsip pedagogis 
mampu menyajikan \textit{feedback} yang scaffolded (bertahap), memicu \textit{self-explanation}, 
dan menuntun refleksi [7]. Dengan dialog natural, LLM dapat membantu ketiga fase 
SRL yaitu, (i) perencanaan (menyusun tujuan dan rencana aksi), 
(ii) pelaksanaan (memberi hint/pertanyaan pemandu saat buntu), 
dan (iii) refleksi (merangkum kekuatan-kelemahan dan langkah tindak lanjut) [6], [7]. 
Agar efektif dan aman, \textit{feedback} LLM sebaiknya disejajarkan dengan praktik pedagogis berbasis 
bukti (fokus pada proses, \textit{actionability}, dan nada empatik) dan dievaluasi kualitasnya 
secara sistematis.

% \paragraph{Landasan tiga fungsi pedagogis.}
Dalam kerangka SRL, efektivitas umpan balik dipahami melalui fokus bertingkat pada 
\textit{task}, \textit{process}, dan \textit{self-regulation}, serta dampaknya pada 
keyakinan diri dan ketekunan belajar [4]. Menurut artikel jurnal ini [4], disebutkan bahwa 
\textit{feedback} kognitif efektif bila spesifik, mendiagnosis miskonsepsi, dan 
menyarankan langkah perbaikan yang terstruktur. Lalu, \textbf{dukungan motivasional} 
menjaga \textit{self-efficacy} (keyakinan diri), menetapkan tujuan yang menantang namun realistis, 
serta mendorong komitmen rencana aksi. Terakhir, pemberian apresiasi yang spesifik 
terhadap usaha/progres dapat berkontribusi pada afek positif dan keterlibatan yang 
disertai arahan perbaikan agar tidak menjadi pujian kosong [4]. Oleh karena itu, 
penelitian ini menilai kualitas respons LLM pada ketiga fungsi tersebut karena ketiganya 
(\textit{feedback}, \textit{motivation}, dan \textit{appreciation}) 
secara langsung mendukung fase perencanaan–pelaksanaan–refleksi dalam SRL [1], [2], [4].


% [1] B. J. Zimmerman, “Becoming a self-regulated learner: An overview,” Theory Into Practice, vol. 41, no. 2, pp. 64–70, 2002.
% [2] E. Panadero, “A review of self-regulated learning: Six models and four directions for research,” Educational Psychology Review, vol. 29, no. 4, pp. 1–28, 2017.
% [3] K. Lobos, R. Cobo-Rendón, D. B. Jofré, and J. Santana, “New challenges for higher education: Self-regulated learning in blended learning contexts,” Frontiers in Education, vol. 9, art. 1457367, 2024.
% [4] D. J. Nicol and D. Macfarlane-Dick, “Formative assessment and self-regulated learning: A model and seven principles of good feedback practice,” Studies in Higher Education, vol. 31, no. 2, pp. 199–218, 2006.
% [5] J. Hattie and H. Timperley, “The power of feedback,” Review of Educational Research, vol. 77, no. 1, pp. 81–112, 2007.
% [6] D. Sun, P. Xu, J. Zhang, R. Liu, and J. Zhang, “How self-regulated learning is affected by feedback based on large language models: Data-driven sustainable development in computer programming learning,” Electronics, vol. 14, no. 1, art. 194, 2025.
% [7] S. Steinert et al., “Harnessing large language models to develop research-based learning assistants for formative feedback,” Smart Learning Environments, vol. 11, no. 1, art. 30, 2024.


\subsection{\textit{Prompt Engineering}}

\textit{Prompt engineering} merupakan bidang kajian baru yang berfokus pada perancangan, penyempurnaan, 
dan implementasi prompt atau instruksi yang diberikan kepada model bahasa besar LLM 
untuk mengarahkan keluaran model tersebut [1]. Dengan kata lain, \textit{prompt engineering} 
adalah “mekanisme pengendali” (\textit{steering mechanism}) yang digunakan pengguna kecerdasan buatan 
generatif untuk menyusun \textit{prompt} sedemikian rupa agar menghasilkan keluaran yang diinginkan [2]. 
Konsep ini menjadi semakin penting seiring munculnya LLM populer seperti ChatGPT, karena 
kemampuan merancang \textit{prompt} yang efektif memungkinkan pengguna untuk mendapatkan jawaban yang 
lebih akurat, relevan, dan sesuai kebutuhan dari model AI [1].

Sebagai suatu keterampilan, \textit{prompt engineering} dapat dipelajari dan dikembangkan. 
Para peneliti menuliskan bahwa \textit{prompt engineering} sudah mulai diajarkan secara formal, 
misalnya di perguruan tinggi, karena dianggap sebagai \textit{skillset} baru yang 
dibutuhkan di era integrasi AI [2]. Intinya, \textit{prompt engineering} 
menekankan seni merumuskan pertanyaan atau perintah dalam bahasa natural 
sedemikian rupa sehingga model AI memahami konteks tugas dan memberikan respon optimal sesuai 
keinginan pengguna.

\subsection{\textit{Context Engineering}}

\textit{Context engineering} adalah disiplin yang berkembang untuk melengkapi dan melampaui 
\textit{prompt engineering}. Jika \textit{prompt engineering} berfokus 
pada apa yang dikatakan kepada model pada satu waktu, maka \textit{context engineering} 
berfokus pada apa saja yang diketahui model saat \textit{prompt} tersebut 
diberikan. Menurut survei terbaru, \textit{context engineering} didefinisikan sebagai disiplin formal 
yang melampaui sekadar perancangan \textit{prompt} dan mencakup optimisasi sistematis dari informasi 
konteks yang disuplai ke LLM [3]. Kinerja LLM sangat ditentukan oleh informasi kontekstual 
yang diberikan selama inferensi, sehingga \textit{context engineering} berusaha memastikan model 
menerima \textit{payload} informasi yang paling relevan dan berguna.

Dalam praktiknya, \textit{context engineering} mencakup teknik-teknik seperti \textit{retrieval-augmented 
generation} (RAG) untuk mengambil pengetahuan eksternal, penggunaan \textit{memory systems} agar 
model mengingat interaksi sebelumnya, integrasi alat tambahan (\textit{tool-integrated reasoning}), 
hingga koordinasi \textit{multi-agen} AI [3]. Berbeda dengan \textit{prompt engineering} yang hanya memanipulasi 
teks \textit{prompt}-nya, \textit{context engineering} mengatur lingkungan dan konteks bagi model, misalnya 
mengumpulkan data pendukung, menyusun instruksi sistem, mendefinisikan aturan, serta memasukkan 
memori atau informasi historis sebelum \textit{prompt} diberikan. Tujuannya adalah memaksimalkan kualitas 
jawaban AI dengan menghadirkan konteks informasi yang optimal dalam batas panjang konteks model 
tersebut [3]. Dengan demikian, \textit{context engineering} menjadikan AI lebih andal dan \textit{context-aware}, 
tidak semata-mata mengandalkan satu perintah teks statis.

\subsection{Perbedaan \textit{Prompt Engineering} dan \textit{Context Engineering}}
Meskipun terkait, \textit{prompt engineering} dan \textit{context engineering} memiliki fokus dan pendekatan yang 
berbeda. Berikut adalah perbedaan utama keduanya [3]:
% •	Lingkup Input: \textit{Prompt engineering} memandang \textit{prompt} sebagai teks statis tunggal yang 
% 	menjadi masukan model. Sebaliknya, \textit{context engineering} memandang konteks secara dinamis dan 
% 	terstruktur, terdiri dari berbagai komponen informasi (instruksi sistem, pengetahuan eksternal, 
% 	memori percakapan, status pengguna, dll.) yang dirangkai bersama sebagai masukan [3]. 
% 	Dengan kata lain, \textit{prompt engineering} beroperasi di dalam jendela konteks yang ada, sedangkan 
% 	\textit{context engineering} menentukan apa saja yang mengisi jendela konteks tersebut.
% •	Informasi dan Memori: Pada \textit{prompt engineering}, informasi yang diberikan bersifat tetap 
% 	dalam teks \textit{prompt}, dan interaksi biasanya tanpa memori jangka panjang (setiap \textit{prompt} berdiri 
% 	sendiri) [3]. Pada \textit{context engineering}, tujuannya adalah memaksimalkan informasi yang relevan 
% 	dengan tugas dalam batas konteks model [3]. \textit{Context engineering} juga secara eksplisit 
% 	mempertimbangkan komponen memori atau state, sehingga model dapat memanfaatkan informasi 
% 	dari interaksi sebelumnya (stateful) [3].
% •	Pendekatan Optimasi: \textit{Prompt engineering} umumnya mengandalkan percobaan manual dan 
% 	iteratif dalam merancang kalimat \textit{prompt} hingga didapat keluaran yang diinginkan, sehingga 
% 	sering dianggap sebagai suatu art (seni coba-coba) [3]. Sebaliknya, \textit{context engineering} 
% 	menerapkan pendekatan yang lebih sistematis atau scientific. Ia melibatkan optimisasi di 
% 	level sistem secara menyeluruh, misalnya menentukan fungsi-fungsi pengambil dan pengolah 
% 	konteks yang ideal, dengan tujuan akhir meningkatkan kualitas output LLM secara konsisten [3]. 
% 	Dalam \textit{context engineering}, evaluasi dan penyempurnaan bisa dilakukan pada masing-masing 
% 	komponen konteks (misal modul pencarian pengetahuan atau mekanisme memori) secara terukur, 
% 	bukan sekadar inspeksi output akhir secara manual [3].
% •	Skalabilitas dan Kompleksitas: \textit{Prompt engineering} cenderung rapuh ketika \textit{prompt} menjadi 
% 	terlalu panjang atau kompleks, karena model dapat kehilangan fokus atau konsistensi; 
% 	pendekatan ini kurang terstruktur untuk skenario kompleks [3]. \textit{Context engineering} dirancang 
% 	untuk mengatasi hal ini dengan komposisi modular, mengelola konteks panjang melalui 
% 	segmentasi informasi, hirarki memori, dan kompresi konteks bila perlu [3]. Dengan demikian, 
% 	\textit{context engineering} lebih siap menangani skala konteks yang besar dan beragam (misalnya 
% 	input \textit{multi-modal}, pengetahuan berjenjang) dibandingkan pendekatan \textit{prompt-only}.

\begin{table}[h]
\centering
\caption{Perbandingan \textit{Prompt Engineering} dan \textit{Context Engineering}}
\label{tab:perbandingan}
\begin{tabular}{|p{0.22\linewidth}|p{0.35\linewidth}|p{0.35\linewidth}|}
\hline
\textbf{Aspek} & \textbf{\textit{Prompt Engineering}} & \textbf{\textit{Context Engineering}} \\
\hline
Lingkup Input & Memandang \textit{prompt} sebagai teks statis tunggal yang menjadi masukan model. & Memandang konteks secara dinamis dan terstruktur, terdiri dari berbagai komponen informasi (instruksi, pengetahuan, memori, status pengguna) yang dirangkai bersama. \\
\hline
Informasi dan Memori & Informasi bersifat tetap dalam teks \textit{prompt}; interaksi biasanya tanpa memori jangka panjang (setiap \textit{prompt} berdiri sendiri). & Mempertimbangkan komponen memori atau \textit{state} secara eksplisit, memungkinkan model memanfaatkan informasi dari interaksi sebelumnya (\textit{stateful}). \\
\hline
Pendekatan Optimasi & Mengandalkan percobaan manual dan iteratif; sering dianggap sebagai suatu seni (\textit{art}) coba-coba. & Menerapkan pendekatan yang sistematis dan ilmiah (\textit{scientific}); melibatkan optimisasi di level sistem secara menyeluruh. \\
\hline
Skalabilitas dan Kompleksitas & Cenderung rapuh untuk \textit{prompt} yang panjang dan kompleks; kurang terstruktur untuk skenario kompleks. & Dirancang untuk mengelola konteks yang besar dan beragam secara modular (segmentasi, hirarki, kompresi). \\
\hline
\end{tabular}
\end{table}

% \begin{table}[h]
% 	\caption{Tabel ini}
% 	\vspace{0.5em}
% 	\centering
% 	\begin{tabular}{|c|c|c|}
% 		\hline
% 		ID & Tinggi Badan (cm) & Berat Badan (kg) \\
% 		\hline \hline
% 		A23 & 173 & 62 \\
% 		A25 & 185 & 78 \\
% 		A10 & 162 & 70 \\ \hline
% 	\end{tabular}
% 	\label{Tab: Tabel Tinggi Berat}
% \end{table}
% Contoh penulisan tabel bisa dilihat pada Tabel \ref{Tab: Tabel Tinggi Berat}.


% Kasih Gambar.

Secara ringkas, \textit{prompt engineering} menitikberatkan cara merumuskan pertanyaan kepada AI, 
sedangkan \textit{context engineering} menitikberatkan apa saja informasi pendukung yang disertakan 
agar AI dapat menjawab dengan lebih baik. \textit{Context engineering} mengubah fokus dari sekadar 
“seni” merangkai prompt menjadi “ilmu” mengelola informasi untuk optimalisasi sistem AI [3]. 
Kedua pendekatan ini saling melengkapi: prompt yang baik diperlukan, namun penyajian konteks 
yang tepat akan semakin meningkatkan kemampuan model dalam menyelesaikan tugas secara andal.

\subsection{\textit{Learning Analytics} dan Cakupannya}
Learning analytics adalah bidang kajian yang memanfaatkan data pendidikan untuk memahami dan 
meningkatkan proses pembelajaran. Salah satu definisi yang umum dikutip menyatakan bahwa learning 
analytics merupakan pengukuran, pengumpulan, analisis, dan pelaporan data tentang peserta didik 
serta konteksnya, dengan tujuan memahami dan mengoptimalkan pembelajaran serta lingkungan 
di mana pembelajaran tersebut berlangsung [4]. Dalam praktiknya, learning analytics mencakup 
penggunaan berbagai sumber data (misalnya data aktivitas pada Learning Management System, 
nilai akademik, log interaksi, dan sebagainya) untuk memperoleh wawasan yang dapat ditindaklanjuti 
oleh pendidik, lembaga, ataupun peserta didik sendiri.

Cakupan learning analytics sangat luas, meliputi beragam skenario dan kepentingan pendidikan. 
Pada tingkat institusi, learning analytics digunakan untuk memonitor kinerja dan retensi mahasiswa. 
Studi menunjukkan banyak institusi pendidikan menerapkan learning analytics terutama untuk 
mengidentifikasi mahasiswa berisiko tinggi (misalnya berpotensi drop-out atau gagal studi) 
dan mengambil langkah intervensi dini guna meningkatkan retensi [4]. Dengan analisis data 
yang tepat, institusi dapat bersikap lebih preventif daripada reaktif. Model prediktif dapat 
menandai siswa yang membutuhkan bantuan, sehingga advisor atau dosen dapat memberikan bimbingan 
sebelum masalah berkembang lebih jauh [4]. Hasilnya, learning analytics berkontribusi pada 
peningkatan keberhasilan studi melalui intervensi yang tepat sasaran.

Di sisi lain, cakupan learning analytics juga mencakup tingkat kelas dan individu. Bagi pendidik, 
analitik pembelajaran dapat dipakai untuk mengevaluasi efektivitas pengajaran dan kualitas 
interaksi di kelas. Misalnya, data pola akses e-learning dan keterlibatan siswa dapat dianalisis 
untuk mengetahui bagian materi mana yang sulit dipahami atau siapa siswa yang kurang aktif, 
sehingga pendidik dapat menyesuaikan strategi pengajaran. Bagi pelajar, dashboard learning 
analytics bisa memberikan umpan balik personal tentang progres belajar mereka, membantu 
self-reflection dan pengambilan keputusan belajar yang lebih baik.

Sebagai bidang multidisiplin, learning analytics memadukan teknik dari data science,
machine learning, dan pendidikan. Penerapannya mencakup analisis deskriptif (melaporkan apa 
yang terjadi dalam pembelajaran), diagnostik (mengapa sesuatu terjadi), prediktif (memprediksi 
hasil atau risiko di masa depan, seperti kemungkinan drop-out), hingga preskriptif (memberikan 
rekomendasi intervensi untuk perbaikan). Dengan kata lain, cakupan learning analytics tidak 
hanya terbatas pada pelaporan statistik, tetapi juga pengambilan keputusan berbasis data 
dalam pendidikan.

Secara keseluruhan, learning analytics berperan sebagai alat bantu strategis bagi institusi 
pendidikan untuk meningkatkan kualitas pembelajaran. Dari meningkatkan outcome belajar siswa, 
mengoptimalkan penggunaan teknologi pendidikan, menurunkan tingkat putus studi, hingga 
meningkatkan personalisasi pembelajaran, semuanya termasuk dalam ruang lingkup learning 
analytics [4]. Dengan dukungan literatur ilmiah yang terus berkembang, learning analytics 
menawarkan kerangka berbasis data untuk memahami proses belajar mengajar secara lebih 
mendalam dan mendorong inovasi dalam praktik pendidikan.


	% [1]	Bertalan Meskó (2023). “Prompt Engineering as an Important Emerging Skill for Medical Professionals: Tutorial.” J. Med. Internet Res., 25(1):e50638 ￼.
	% [2]	Moorhouse, B.L. & Romina Jamieson-Proctor (2025). “Prompt engineering in higher education: a systematic review to help inform curricula.” Int. J. Educ. Technol. High. Educ., 22(39) ￼.
	% [3]	Lingrui Mei et al. (2025). “A Survey of Context Engineering for Large Language Models.” arXiv preprint arXiv:2507.13334 ￼ ￼.
	% [4]	Marcela Hernández-de-Menéndez et al. (2022). “Learning analytics: state of the art.” Int. J. Interact. Des. Manuf., 16:1209–1230 ￼ ￼.

% Proses pembuatan \textit{game} dimulai dari pembuatan \textit{game design document} dimana 
% dokumen ini akan menjadi landasan pengembangan game tersebut serta menginformasikan gambaran keseluruhan game yang akan dibuat \cite{ferdiana2012agile}. \textcolor{red}{\textit{Catatan: apapun yang diambil dari tulisan orang lain harus disitasi seperti dicontohkan \cite{ferdiana2012agile}.}}

% \begin{figure}[ht]
% 	\centering
% 	\includegraphics[width=12cm]{contents/chapter-2/gambar-buatan-sendiri.png}
% 	\caption[Contoh gambar]{Contoh gambar \cite{lukito2016}}
% 	\label{Fig:gambar-buatan-sendiri}
% \end{figure}



% \textit{Game design document} adalah sebuah bagian penting dalam pembuatan game baik itu elemen-elemen penyusunnya maupun proses pengembangannya. Game design yang telah dibuat, dijabarkan satu persatu mengenai tahapan dalam pembuatan game dan hasilnya disatukan dalam bentuk dokumentasi \textit{game design document} yang digunakan oleh \textit{developer} sebagai buku petunjuk bagaimana membuat \textit{game} \cite{lukito2016}.

% Dalam buku \textit{Game Design Essentials} disebutkan \textit{game design document} merupakan metode yang menghubungkan elemen-elemen penyusun \textit{game}, baik itu \textit{art, sound, program, 
% gameplay} sehingga semuanya terdokumentasi menjadi satu dan menjadi acuan bagi para \textit{developer} dalam membuat \textit{game} \cite{wibirama2013dual}. 
\section{Penelitian Terkait}

\subsection{Studi Menggabungkan LLM dengan Learning Analytics}
Beberapa penelitian terbaru telah mengintegrasikan Large Language Models (LLM) dengan 
teknik learning analytics untuk meningkatkan pemberian umpan balik dan tutoring. 
Misalnya, TutorLLM (Li dkk., 2024) menggabungkan model knowledge tracing (KT) dengan 
retrieval-augmented generation (RAG) dalam LLM. TutorLLM memanfaatkan data jejak 
belajar tiap siswa (dari model KT BERT-based) serta pencarian konteks relevan, 
sehingga LLM dapat memberikan rekomendasi belajar yang dipersonalisasi sesuai 
status pengetahuan siswa dan mengurangi halusinasi [1]. Hasil evaluasi TutorLLM 
menunjukkan peningkatan kepuasan pengguna ~10\% dan skor kuis ~5\% dibanding 
penggunaan LLM umum tanpa personalisasi [1].

Studi LLM-KT (Wang dkk., 2025) juga menunjukkan pendekatan serupa dengan fokus 
pada knowledge tracing. LLM-KT menggunakan kerangka plug-and-play untuk menyelaraskan 
LLM dengan tugas KT, memanfaatkan kemampuan penalaran dan pengetahuan dunia luas 
dari LLM sekaligus memasukkan rekaman interaksi siswa secara sekuensial seperti 
pada model KT tradisional [2]. Melalui penyisipan konteks pertanyaan dan urutan 
jawaban historis ke dalam LLM, model hybrid ini mencapai kinerja state-of-the-art 
dalam memprediksi jawaban siswa di beberapa dataset KT klasik [2]. Ini menunjukkan 
potensi framework yang memadukan kekuatan LLM (fleksibilitas bahasa dan penalaran) 
dengan analitik pembelajaran tradisional (pelacakan pengetahuan sekuensial).

Selain itu, Reddig dkk. (2025) mengevaluasi penggunaan GPT-4 untuk memberikan umpan 
balik personal dalam konteks Intelligent Tutoring System (ITS). Studi ini 
menganalisis data kesalahan siswa dalam tutor aljabar lalu *mem-*prompt GPT-4 
untuk menghasilkan hint/koreksi spesifik terhadap kesalahan tersebut [3]. Hasilnya, 
model LLM cukup efektif mendiagnosis berbagai kesalahan siswa dan menghasilkan 
umpan balik relevan; namun sekitar 35\% hint yang dihasilkan terlalu umum, kurang 
tepat, atau justru langsung memberi jawaban [3]. Temuan ini menekankan bahwa meskipun 
LLM dapat meningkatkan skala dan personalisasi umpan balik, diperlukan mekanisme 
kontrol kualitas agar saran yang menyesatkan tidak ditampilkan pada siswa [3]. 
Menariknya, Reddig dkk. juga menguji kemampuan LLM untuk secara otomatis menilai 
kualitas umpan balik yang dibuatnya, sebagai upaya menggabungkan praktik tutoring 
terbukti dengan fleksibilitas LLM demi memperoleh “best of both worlds” [3].

Penelitian lain mengindikasikan efektivitas umpan balik berbasis LLM bergantung 
pada keterlibatan pelajar. Thomas dkk. (2025) menemukan bahwa dalam skenario 
pelatihan tutor, peserta yang memilih melihat penjelasan feedback dari LLM (ChatGPT) 
mendapat skor post-test lebih tinggi daripada yang tidak menggunakannya, 
dengan effect size moderat (~0.3) pada beberapa lesson [4]. Ini menunjukkan 
potensi LLM untuk memberikan umpan balik seefektif tutor manusia dalam konteks 
tertentu, asalkan penggunaannya terarah dan sesuai kebutuhan.



% [1] Z. Li et al., "TutorLLM: Customizing Learning Recommendations with Knowledge Tracing and Retrieval-Augmented Generation," in Proceedings of the 18th ACM Conference on Recommender Systems, Bari, Italy, Oct. 2024, pp. 1–10. doi: 10.1145/XXXXXX.XXXXXXX.

% [2] Z. Wang, J. Zhou, Q. Chen, M. Zhang, B. Jiang, A. Zhou, Q. Bai, and L. He, "LLM-KT: Aligning Large Language Models with Knowledge Tracing using a Plug-and-Play Instruction," in Proceedings of the XXX Conference, XXX, 2025, pp. 1–10. doi: 10.1145/XXXXXX.XXXXXXX.

% [3] J. M. Reddig, A. Arora, and C. J. MacLellan, "Generating In-Context, Personalized Feedback for Intelligent Tutors with Large Language Models," International Journal of Artificial Intelligence in Education, vol. 35, no. 3, pp. 1–25, Sep. 2025, doi: 10.1007/s40593-025-00505-6.
% [4] D. R. Thomas, C. Borchers, S. Bhushan, E. Gatz, S. Gupta, and K. R. Koedinger, "LLM-Generated Feedback Supports Learning If Learners Choose to Use It," arXiv preprint, arXiv:2506.17006, 2025. [Online]. Available: https://arxiv.org/abs/2506.17006

\subsection{Pendekatan Rekayasa dalam \textit{Learning Analytics}}

Dari sisi pendekatan rekayasa dalam learning analytics, beberapa karya menyoroti 
pentingnya merancang sistem yang dapat mengumpulkan dan menganalisis data proses 
belajar secara efisien, termasuk data “Kanban” atau pelacakan tugas belajar. 
Sebagai contoh, sebuah studi memanfaatkan papan Kanban untuk orkestrasi kelas 
sebagai alat self-regulated learning; papan tersebut menampilkan kartu tugas 
siswa dalam kolom “to do / in progress / done” untuk memvisualisasikan kemajuan 
mereka []1. Data status tugas di Kanban ini memberikan informasi real-time tentang 
progres dan keterlibatan siswa yang dapat dimanfaatkan guru. Bahkan, dikembangkan 
prototipe alat digital Kanban yang dirancang khusus untuk pendidikan 
(tidak bergantung pada Trello dkk. karena isu privasi) agar guru dapat 
menyiapkan template board dan mereplikasi ke banyak kelompok belajar [1].

Ke depan, platform Kanban edukasi semacam itu berpotensi diperluas dengan 
kapabilitas learning analytics langsung. Misalnya, Winter dkk. (2022) merancang 
alat Kanban kelas yang rencananya dilengkapi analytics berupa statistik otomatis, 
identifikasi “tugas yang macet”, rekomendasi khusus, serta dashboard guru untuk 
memantau semua papan siswa secara bersamaan [1]. Integrasi semacam ini menunjukkan 
pendekatan rekayasa di mana data pelacakan tugas mikro (misal, berapa lama tugas 
tertahan di kolom tertentu) dikumpulkan dan dianalisis guna memberi wawasan 
tindakan: guru dapat segera melihat siapa yang butuh bantuan 
(tugasnya lama di “in progress”), atau sistem bisa menyarankan intervensi pada 
tugas spesifik. Perekaman data proses semacam ini juga bermanfaat untuk penelitian 
edukasi dan evaluasi metode belajar, asalkan sesuai aturan privasi [1].

Lebih umum lagi, data proses (process data) dalam learning analytics, yaitu 
rekaman langkah-langkah atau interaksi saat siswa mengerjakan tugas yang dipandang 
kian penting untuk memahami pola belajar. Mazzullo dkk. (2023) menekankan bahwa 
pemanfaatan data proses (misal urutan klik, waktu respon, transisi antar tugas) 
dapat menghasilkan insight yang lebih interpretable tentang perilaku belajar 
dibanding sekadar nilai akhir [2]. Pendekatan rekayasa LA yang baik perlu mampu 
menangkap data proses ini dan menyajikannya secara informatif. Tantangan yang 
diidentifikasi meliputi bagaimana mendesain sistem LA dengan landasan pedagogis 
kuat, memastikan insight mudah dipahami, prediksi akurat, dan umpan balik yang 
dapat ditindaklanjuti [2]. Dengan kata lain, arsitektur LA harus dirancang tidak 
hanya untuk mengumpulkan data (termasuk data “kanban” tugas) tetapi juga untuk 
menganalisis dan menyajikannya dalam bentuk yang mendukung pengambilan keputusan 
pembelajaran.

% [1] S. Strickroth, M. Kreidenweis, and Z. Wurm, "Learning from Agile Methods: Using a Kanban Board for Classroom Orchestration," in Proceedings of the [Nama Konferensi], [Lokasi Konferensi], [Tahun], pp. [XX-YY]. doi: [DOI yang sesuai].
% [2] E. Mazzullo, O. Bulut, T. Wongvorachan, and B. Tan, "Learning Analytics in the Era of Large Language Models," Analytics, vol. 2, no. 4, pp. 877-898, Nov. 2023, doi: 10.3390/analytics2040046.


\subsection{Menghubungkan Hasil \textit{Learning Analytics} dengan Prompt \textit{Context-Aware} pada LLM}

Bidang ini semakin berkembang menuju penggabungan insight dari learning analytics 
dengan prompt engineering yang context-aware untuk meningkatkan kualitas output LLM.
Idenya adalah menjadikan LLM lebih “sadar konteks” situasi belajar individu, 
sehingga respon yang dihasilkan lebih tepat sasaran. Beberapa studi telah 
mengeksplorasi pendekatan ini.

Venugopalan dkk. (LAK 2025) mempelajari skenario hybrid tutoring di mana sistem 
tutoring tradisional digabung dengan LLM untuk mendukung orang tua yang membimbing 
anaknya belajar matematika. Mereka menggunakan prompt engineering dengan memasukkan 
konteks real-time dari ITS (misal: langkah pengerjaan siswa, kesalahan yang 
dilakukan, hint yang sudah diberikan) ke prompt LLM, ditambah contoh praktik 
tutoring yang baik (few-shot). Hasilnya, LLM (Llama 3) mampu menghasilkan 
rekomendasi percakapan bagi orang tua yang dinilai membantu meningkatkan dukungan 
metakognisi siswa (misal mendorong anak menjelaskan pikirannya) []. Studi ini 
menunjukkan bahwa memberikan konteks situasional (dari analytics ITS) dalam 
prompt dapat meng-align output LLM dengan strategi pedagogis yang diinginkan.

Demikian pula, TutorLLM yang disebut sebelumnya memanfaatkan contextual prompt 
secara otomatis: modul “Scraper” dalam arsitekturnya mengambil konten teks 
terkait materi belajar selama sesi online, lalu informasi itu bersama prediksi 
model KT tentang kelemahan siswa disuplai ke LLM (GPT-4) untuk menghasilkan 
jawaban yang akurat dan sesuai tingkat pemahaman siswa []. Dengan menambah 
pengetahuan latar kontekstual ke prompt, TutorLLM terbukti mengurangi risiko 
halusinasi dan meningkatkan relevansi jawaban terhadap kebutuhan spesifik 
siswa []. Ini adalah contoh konkret bagaimana hasil learning analytics 
(dalam hal ini profil pengetahuan siswa dari KT dan materi relevan yang 
di-retrieve) dapat tersambung langsung ke LLM sehingga responnya terpersonalisasi 
dan kontekstual.

Pendekatan serupa tampak pada studi Reddig dkk. (2025) tadi: alih-alih LLM 
bekerja “kosong”, mereka mem-prompt GPT-4 dengan input berupa deskripsi kesalahan 
spesifik yang dilakukan siswa pada tutor algebra, seolah memberikan konteks 
masalah dan kesalahan untuk diperbaiki []. Strategi prompting yang context-aware 
ini memungkinkan GPT-4 memberikan feedback yang lebih tepat karena “tahu” 
kesalahan mana yang terjadi. Reddig dkk. juga membahas pentingnya format 
prompt dan kriteria penilaian keluaran agar LLM tidak memberi jawaban terlalu 
langsung atau keliru []. Hal ini menggarisbawahi perlunya prompt engineering 
berbasis insight LA: misalnya menentukan informasi apa saja yang harus 
disertakan dalam prompt (error siswa, riwayat upaya, dll.) dan bagaimana 
meminta LLM memberikan keluaran (misal hint yang membimbing, bukannya solusi 
instan) []. Penelitian Stamper dkk. (2024) bahkan menyusun kerangka sistematis 
untuk merancang prompt LLM berbasis prinsip umpan balik ITS yang sudah teruji, 
seperti menentukan kapan LLM diberi trigger untuk menilai jawaban siswa, 
informasi apa yang perlu disertakan dalam prompt input ke LLM, dan jenis 
keluaran umpan balik apa yang diharapkan []. Pendekatan teoritis ini 
memastikan penggunaan LLM selaras dengan teori pendidikan (mis. umpan balik 
segera, spesifik, mendorong self-explanation) sehingga kualitas output-nya 
lebih terjamin.

Secara keseluruhan, tren riset ini menunjukkan upaya menggabungkan kekuatan 
learning analytics dengan kecerdasan generatif LLM. Learning analytics 
menyediakan data-driven insights tentang proses dan status belajar (misal: 
apa yang sudah dikuasai, kesalahan yang sering muncul, progress task di 
Kanban, dll.), sementara LLM dapat memanfaatkan konteks tersebut untuk 
menghasilkan umpan balik atau bimbingan yang adaptif. Mazzullo dkk. (2023) 
menyatakan bahwa implementasi LLM dalam LA dapat membantu memberikan insight 
yang lebih mudah dipahami, umpan balik yang lebih cepat dan actionable, 
peningkatan personalisasi, serta mendukung tugas-tugas guru secara lebih 
luas []. Dengan mengaitkan hasil analitik (misal deteksi kebuntuan tugas 
atau prediksi kemampuan) ke dalam prompt atau modul pengetahuan LLM, 
diharapkan output AI menjadi lebih relevan konteks dan berkualitas 
tinggi dalam mendukung pembelajaran. Ini juga area kebaruan yang bisa 
peneliti tekankan: membedakan bagaimana pendekatan mereka menyambungkan 
LA dan LLM secara lebih erat atau efektif dibanding studi-studi 
terdahulu seperti TutorLLM, LLM-KT, atau Reddig dkk. di atas.

% [1] D. Venugopalan, Z. Yan, C. Borchers, J. Lin, and V. Aleven, "Combining Large Language Models with Tutoring System Intelligence: A Case Study in Caregiver Homework Support," in Proceedings of the 15th International Conference on Learning Analytics & Knowledge (LAK '25), 2025, pp. 1–11. doi: 10.1145/3706468.3706516. arXiv preprint arXiv:2412.11995. [Online]. Available: https://arxiv.org/abs/2412.11995
% [2] Z. Li et al., "TutorLLM: Customizing Learning Recommendations with Knowledge Tracing and Retrieval-Augmented Generation," in Proceedings of the 18th ACM Conference on Recommender Systems, Bari, Italy, Oct. 2024, pp. 1–10. doi: 10.1145/XXXXXX.XXXXXXX.
% [3] J. M. Reddig, A. Arora, and C. J. MacLellan, "Generating In-Context, Personalized Feedback for Intelligent Tutors with Large Language Models," International Journal of Artificial Intelligence in Education, vol. 35, no. 3, pp. 1–25, Sep. 2025, doi: 10.1007/s40593-025-00505-6.
% [4] J. Stamper, R. Xiao, and X. Hou, "Enhancing LLM-Based Feedback: Insights from Intelligent Tutoring Systems and the Learning Sciences," in Proceedings of the [Conference Name], [Conference Location], [Year], pp. [Page Range]. doi: [DOI].
% [5] E. Mazzullo, O. Bulut, T. Wongvorachan, and B. Tan, "Learning Analytics in the Era of Large Language Models," Analytics, vol. 2, no. 4, pp. 877-898, Nov. 2023, doi: 10.3390/analytics2040046.




\section{Analisis Perbandingan Metode}

Di dalam tinjauan pustaka hasil akhirnya adalah analisis secara kualitatif atau pun secara kuantitatif kelebihan dan kekurangan metode jika dikaitkan dengan masalah, batasan-batasan masalah dan solusi yang dinginkan. Analisis kuantitatif tidak wajib teapi mempunyai nilai tambah di dalam tugas akhir saudara. Bagian ini menjelaskan kenapa metode tersebut dipilih dan uraikan dengan lebih jelas metode pelaksanaan tugas akhir yang ingin Anda lakukan. 

\section{Pertanyaan Tugas Akhir (Jika Perlu)}

Pertanyaan tugas akhir bersifat opsional dan dapat ditambahkan untuk menekankan hal-hal yang hendak diketahui dari tugas akhir berdasar pada tujuan tugas akhir. Pertanyaan tugas akhir dikenal dengan RQ (\textit{Research Question}) dan harus memiliki keterkaitan dengan RO (\textit{Research Objective}). Satu RO dapat memiliki satu atau lebih dari satu RQ. 

