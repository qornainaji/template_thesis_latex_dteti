\chapter{Tinjauan Pustaka dan Dasar Teori}


% \section{Tinjauan Pustaka}

% Pada bab ini, akan dibahas mengenai dasar teori, penelitian sebelumnya yang berkaitan dengan penggunaan
% data \textit{learning analytics} untuk meningkatkan performa LLM dalam memberikan umpan balik 
% ============= versi 1 ================
% Pada bab ini dibahas dasar teori dan penelitian sebelumnya yang berkaitan 
% dengan penggunaan data \textit{learning analytics} dan teknik 
% \textit{context engineering} (termasuk \textit{prompt engineering}) untuk 
% meningkatkan performa LLM dalam memberikan umpan balik (kognitif), dukungan 
% motivasional, dan dukungan apresiatif. Uraian dimulai dari landasan 
% \textit{Self‑Regulated Learning} (SRL) dan peran umpan balik dalam fase 
% perencanaan, pelaksanaan, dan refleksi. Kemudian mendefinisikan 
% \textit{prompt engineering} serta \textit{context engineering} beserta 
% perbedaan keduanya dan implikasinya bagi rancangan sistem tutor‑AI. 
% Selanjutnya, bab ini menguraikan konsep \textit{learning analytics}—cakupan, 
% sumber data proses (mis. log LMS, urutan aktivitas, \textit{time‑on‑task}, 
% perpindahan tugas, beban/WIP), serta cara mengekstraksinya—dan bagaimana 
% sinyal‑sinyal tersebut direkayasa menjadi konteks \textit{prompt} agar LLM 
% mampu menghasilkan bimbingan yang lebih terstruktur, \textit{actionable}, 
% koheren, dan berempati. Bagian tinjauan juga membandingkan karya‑karya 
% terkait yang mengintegrasikan LA dan LLM (misalnya pendekatan berbasis 
% \textit{knowledge tracing} dan pemetaan kesalahan untuk umpan balik 
% personal) guna menegaskan posisi penelitian ini, sekaligus menyoroti isu 
% skalabilitas umpan balik personal dan kebutuhan evaluasi hibrida kualitas 
% respons. Sebagai penutup, bab ini merangkum kesenjangan penelitian dan 
% menjelaskan kontribusi yang diusulkan—yakni \textit{pipeline} perakitan 
% konteks berbasis \textit{learning analytics} yang instrumen‑agnostik 
% (Kanban hanya digunakan sebagai alat pengumpul/penyaji data proses), untuk meningkatkan 
% kualitas respons LLM agar mendekati mutu pakar manusia baik secara kuantitatif maupun 
% kualitatif.

%  =========== versi 2 ================
Bab ini menyajikan tinjauan komprehensif yang disusun secara sistematis untuk membangun 
landasan penelitian. Tinjauan dimulai dengan analisis terhadap penelitian-penelitian terdahulu, 
dilanjutkan dengan komparasi kritikal, dan diakhiri dengan pembahasan dasar teori yang relevan.

Pertama, dibahas terlebih dahulu kumpulan penelitian sebelumnya yang berfokus pada upaya meningkatkan kualitas 
umpan balik dari Large Language Models (LLMs) dalam konteks pendidikan. Termasuk di dalamnya 
adalah berbagai strategi optimasi yang telah diusulkan serta metode-metode evaluasi yang 
digunakan untuk mengukur efektivitas umpan balik yang dihasilkan. 
Kedua, dilakukan komparasi mendalam terhadap penelitian-penelitian tersebut untuk 
mengidentifikasi 
kesenjangan yang ada di dalam literatur. Analisis komparatif ini membantu 
memetakan posisi penelitian ini dalam lanskap penelitian yang lebih luas.
Ketiga, dibahas metode-metode evaluasi yang telah digunakan dalam studi-studi sebelumnya.
Hal ini mencakup evaluasi baik dari segi kuantitatif maupun kualitatif.
Keempat, berdasarkan identifikasi kesenjangan tersebut, disajikan dasar teori yang melandasi 
penelitian ini. Pembahasan mencakup peran LLM dalam dunia pendidikan, kerangka teoritis 
Self-Regulated Learning (SRL), konsep Prompt Engineering dan Context Engineering, 
pendekatan Learning Analytics beserta metode-metode analitik yang relevan untuk konteks pembelajaran, 
serta metode evaluasi yang dapat digunakan di dalam penelitian ini.

Melalui struktur ini, bab ini tidak hanya memberikan fondasi teoretis yang kuat, tetapi 
juga memperjelas kontribusi penelitian dalam mengisi celah yang teridentifikasi dari 
penelitian-penelitian sebelumnya.

\section{Tinjauan Pustaka}

% Bagian ini menelusuri lanskap penelitian tentang umpan balik LLM dalam pendidikan 
% dengan menekankan benang merah yang menghubungkan gagasan, temuan, dan praktik di 
% kelas. Uraian difokuskan pada koherensi pedagogis, keterhubungan dengan data 
% proses, serta kelayakan implementasi sehingga pembaca memperoleh orientasi yang 
% jernih tanpa perlu daftar topik yang eksplisit. Dari pijakan ini, arah rancangan 
% dan strategi evaluasi pada penelitian ini dibangun secara bertahap.
Bagian ini menyajikan tinjauan terhadap penelitian-penelitian sebelumnya yang menjadi 
landasan bagi pengembangan sistem umpan balik LLM dalam pendidikan. Tinjauan ini mencakup 
dua fokus utama yaitu strategi peningkatan kualitas umpan balik LLM dan metode evaluasi 
yang digunakan. 

Melalui analisis komparatif terhadap berbagai pendekatan yang ada, diidentifikasi 
pola, tren, dan kesenjangan dalam literatur. Pemetaan ini tidak hanya memberikan 
konteks bagi penelitian ini, tetapi juga memperjelas kontribusi unik yang ditawarkan 
dalam mengatasi keterbatasan-keterbatasan yang masih ada pada penelitian-penelitian 
sebelumnya.

\subsection{Peningkatan Umpan Balik LLM dengan \textit{Direct Preference Optimization} (DPO)}
Juliette Woodrow, Sanmi Koyejo, dan Chris Piech (Stanford), mengajukan makalah 
“\textit{Improving Generative AI Student Feedback: Direct Preference Optimization with Teachers in 
the Loop}” pada EDM 2025 \cite{woodrow2025dpo_feedback}. Mereka memotret persoalan klasik 
pada umpan balik berbasis LLM yaitu, walau model mampu menghasilkan 
teks yang koheren, gaya, ketelitian, dan terminologi, 
sering kali tidak selaras dengan preferensi pengajar dan konteks spesifik mata kuliah. 
“\textit{Feedback Alignment Challenge}” disebutkan sebagai tantangan menyesuaikan keluaran 
AI dengan ketelitian, terminologi, dan gaya respons yang diharapkan tim pengajar, sehingga 
\textit{feedback} terasa “\textit{course-specific}”, bukan \textit{feedback} generik.

Solusi yang ditawarkan adalah \textit{Direct Preference Optimization} (DPO) 
dengan guru atau \textit{teaching assistant} (TA) di 
dalam loopnya. Inti dari DPO adalah selama proses penilaian, 
sistem menampilkan dua kandidat umpan balik AI untuk 
setiap jawaban mahasiswa, asisten dosen dapat memilih, mengedit, atau 
menulis ulang. Pilihan ini menjadi pasangan preferensi (menang\-kalah) yang 
kemudian dipakai untuk \textit{fine-tuning} model menggunakan DPO, 
tanpa perlu membangun reward model seperti pada 
\textit{Reinforcement Learning from Human Feedback} (RLHF) pada Subbab \ref{subsection:rlhf} 
sehingga alurnya lebih sederhana dan langsung menekan 
probabilitas keluaran yang disukai dibanding yang tidak disukai. Dirancang 
pipa tiga tahap yaitu koleksi preferensi saat grading, pelatihan DPO antar tugas, dan 
inferensi untuk tugas berikutnya sehingga mewujudkan sistem \textit{self-improving} yang semakin selaras 
dengan preferensi pengajar dari satu \textit{assignment} ke \textit{assignment} berikutnya.
Ilustrasi alur DPO dapat dilihat pada Gambar \ref{Fig:fig_dpo}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{contents/chapter-2/fig_dpo.png}
    \caption{Alur Kerja \textit{Direct Preference Optimization} (DPO) dengan Guru di Dalam Loop
    \cite{woodrow2025dpo_feedback}}
    \label{Fig:fig_dpo}
\end{figure}

% Dalam implementasinya, mereka men-fine-tune Llama 3.1 8B Instruct (Hugging Face DPOTrainer), 
% satu periode latih $\approx 7$ jam pada 3 $\times$ A6000, rata-rata 1.408 pasangan preferensi 
% per gelombang; tahap “noticing” (mengumpulkan observasi atas pekerjaan mahasiswa) 
% mengandalkan rubrik/tes otomatis/LLM lain—di sini GPT-4o—yang kemudian disisipkan 
% ke prompt terstruktur untuk memicu respons yang lebih tepat sasaran.
Dalam implementasinya, mereka melakukan \textit{fine-tuning} pada model Llama 3.1 8B Instruct 
menggunakan HuggingFace DPOTrainer. Proses pelatihan berlangsung sekitar tujuh jam 
pada tiga GPU A6000 dengan rata-rata 1.408 pasangan preferensi per gelombang. 
Pada tahap noticing, yaitu pengumpulan observasi atas pekerjaan mahasiswa, mereka 
memanfaatkan rubrik, tes otomatis, dan juga bantuan model LLM lain (GPT-4o). Hasil 
dari tahap ini kemudian disusun ke dalam prompt terstruktur agar model dapat 
menghasilkan respons yang lebih tepat sasaran.

Pengujian pendekatan ini dilakukan pada dua skenario. Pertama, studi terkontrol 
buta yakni digunakan 10 evaluator ahli (staf pengajar) membandingkan umpan 
balik dari beberapa model pada kiriman mahasiswa yang dianonimkan di mana
mereka tidak mengetahui identitas 
model dan menilai preferensi, \textit{Insightfulness}, serta \textit{Naturalness}. 
Kedua, deployment 
nyata di dua penyelenggaraan mata kuliah universitas besar 
($\approx 330$ dan $\approx 289$ mahasiswa; >10 \textit{teaching assistants} 
(TA) per semester), di mana setiap generasi 
model dilatih dari preferensi tugas sebelumnya lalu dipakai pada tugas berikutnya. 
Dilakukan juga pencatatan potensi \textit{confounding variable} dalam deployment 
(mis. setiap soal dinilai oleh satu TA sehingga preferensi pribadi bisa 
memengaruhi pemilihan \textit{feedback}; variasi soal antar generasi menyulitkan isolasi 
efek model).

Untuk evaluasi, dilakukan pemadanan penilaian manusia secara buta dan penilaian otomatis 
berbasis \textit{critic model}. Pada sisi otomatis, mereka mengadopsi kerangka Scarlatos 
et al. \cite{scarlatos2024validity} guna menilai lima dimensi yaitu,
\textit{Correctness, Not-revealing-the-answer, Suggestions, Positive tone}, serta skor total. 
Kerangka ini juga harusnya memuat \textit{“diagnosing errors”} namun 
tidak difokuskan di hasil tabel karena tidak sejalan dengan tugas utama studi ini. 
Di luar itu, dilakukan juga pengenalan \textit{critic model} baru dengan tiga dimensi yaitu 
\textit{Assertiveness}, \textit{Accuracy}, dan \textit{Helpfulness} yang lebih 
umum untuk berbagai tipe jawaban (benar/salah). 
Kedua kerangka ini menggunakan GPT-4o sebagai evaluator otomatis; prompts dan kode 
penilaian dibuka untuk umum.

% Hasil studi terkontrol menunjukkan DPO lebih disukai dibanding baseline kuat 
% GPT-4o: 56,8\% vs 40,2\% (3\% “Neither”), p = 0,007. Pada metrik Insightfulness, 
% DPO lebih tinggi signifikan daripada GPT-4o (rata-rata 3,13 vs 2,79) dan model SFT (2,82); 
% sedangkan Naturalness tidak berbeda signifikan di antara model-model yang diuji. Ulasan 
% kualitatif evaluator menggarisbawahi bahwa ketika DPO dipilih, alasannya mencakup 
% spesifisitas yang lebih tinggi, relevansi masalah, nada yang mendorong, dan saran yang 
% lebih dapat ditindaklanjuti; ketika GPT-4o dipilih, alasan utamanya adalah kejelasan dan 
% keringenkasan (sementara DPO kadang terlalu panjang atau agak canggung secara gaya).

Hasil studi terkontrol menunjukkan bahwa model DPO lebih disukai dibanding baseline 
kuat GPT-4o dengan persentase 56,8\% berbanding 40,2\% sementara 3\% responden memilih 
netral. Pada metrik \textit{Insightfulness}, DPO juga memperoleh skor lebih 
tinggi secara signifikan dibanding GPT-4o (rata-rata 3,13 berbanding 2,79) maupun model 
SFT (2,82). Sebaliknya, pada metrik \textit{Naturalness} tidak ditemukan perbedaan signifikan 
antar model. Ulasan kualitatif evaluator menegaskan bahwa alasan memilih DPO adalah 
karena tingkat kekhususan yang lebih tinggi, relevansi terhadap masalah, nada yang 
mendorong, serta saran yang lebih dapat ditindaklanjuti. Sementara itu, alasan utama 
dipilihnya GPT-4o adalah kejelasan dan keringkasan, sementara DPO terkadang dinilai terlalu 
panjang atau agak canggung dari segi gaya.

Pada evaluasi otomatis (kerangka Scarlatos), DPO melampaui GPT-4o pada 4/5 
metrik \textit{Correctness} (0,932 ± 0,004 vs 0,862 ± 0,006), \textit{Not-revealing-the-answer} 
(0,980 ± 0,002 vs 0,973 ± 0,003), \textit{Positive tone} (0,989 ± 0,002 vs 0,905 ± 0,005), dan 
skor total (0,724 ± 0,004 vs 0,664 ± 0,005). Satu-satunya area yang lebih baik pada 
GPT-4o adalah \textit{Suggestions} (GPT-4o 0,229 ± 0,007 vs DPO 0,163 ± 0,006), menandakan bahwa 
keluaran GPT-4o relatif lebih banyak memberi saran eksplisit, sementara DPO unggul dalam 
ketepatan, menjaga agar tidak membocorkan jawaban, dan mempertahankan nada positif. 
Di critic model baru, sebaran titik menunjukkan klaster DPO lebih konsisten di area 
akurasi dan helpfulness yang tinggi, sedangkan GPT-4o menampilkan variasi lebih besar 
berikut klaster pada wilayah rendah akurasi dan rendah helpfulness; secara kuantitatif, 
umpan balik GPT-4o 8,73 kali lebih mungkin tergolong unhelpful dan 7 kali lebih mungkin inaccurate 
dibanding DPO (tingkat assertiveness relatif sebanding). Hasil deployment memperlihatkan 
kelayakan integrasi di kelas besar dan penguatan preferensi TA terhadap DPO dalam seting 
riil, seraya membuka jalan untuk monitoring otomatis dan eksplorasi awal fairness 
(gender) yang dapat diperluas ke demografi lain. 

\subsection{Peningkatan \textit{Feedback} LLM dengan \textit{Prompt Engineering}}
Artikel ini ditulis oleh Lucas Jasper Jacobsen dan Kira Elena Weber 
(Universität Hamburg) \cite{jacobsen2025promises}. Tujuan utamanya ada dua: 
(1) mengidentifikasi jenis prompt seperti apa yang dibutuhkan agar LLM 
dapat menghasilkan umpan balik berkualitas tinggi di pendidikan guru, dan 
(2) membandingkan kualitas umpan balik LLM dengan umpan balik manusia dari 
kelompok novice (calon guru/preservice teachers) dan expert. Latar masalah 
yang mereka tekankan: studi empiris yang langsung membandingkan kualitas umpan 
balik LLM vs manusia masih jarang, dan belum ada manual/kerangka berbasis teori 
untuk menilai kualitas prompt di konteks pendidikan tinggi, padahal umpan 
balik berkualitas penting namun sumber daya manusia dan waktu dosen sering terbatas.

Sebagai respons, dilakukan pengembangan sebuah manual prompt berbasis teori. 
Manual ini merangkum kategori-kategori kualitas prompt (mencakup aspek 
konteks/peran-audiens-medium, misi, kejernihan dan spesifikasi—misalnya format, 
kekonkretan, spesifik domain, dan logika instruksi). Berdasarkan manual tersebut, 
mereka merancang tiga versi prompt dengan kualitas rendah-menengah-tinggi. 
Seluruh generasi umpan balik LLM menggunakan ChatGPT-4, dengan alasan 
kesesuaian praktik nyata di pendidikan tinggi saat penelitian dilakukan. 
Gagasannya sederhana: jika mutu prompt dapat disistematiskan, kualitas umpan 
balik LLM akan lebih konsisten dan bisa dibandingkan secara adil dengan umpan 
balik manusia.

Tugas yang dipakai berupa learning goal di topik geometri (mengenali segitiga 
siku-siku dan teorema Pythagoras), lengkap dengan tiga jenis kesalahan yang 
umum pada perumusan tujuan pembelajaran. Dari tiga kualitas prompt 
(rendah-menengah-tinggi), dihasilkan 20 umpan balik per prompt 
(total 60 keluaran LLM) yang kemudian dikodekan oleh tiga coder terlatih. 
Untuk pembandingan antar penyedia umpan balik, kelompok novice dan expert 
juga diminta menulis umpan balik dengan menggunakan prompt terbaik (kualitas tinggi), 
sehingga perbandingan dengan LLM berlangsung pada kondisi instruksi yang 
optimal. Desain ini memungkinkan isolasi efek “kualitas prompt” pada kinerja 
LLM sekaligus membangun baseline manusia yang kuat pada kondisi yang sama.

Kualitas umpan balik dianalisis dengan skema kodifikasi yang mencakup 
dimensi-dimensi pedagogis seperti concreteness (kriteria dan penjelasan), 
activation (mis. keberadaan pertanyaan pemandu), empathy 
(nada, penggunaan orang pertama), specificity, serta errors (kesalahan isi). 
Analisis statistik dilakukan untuk membandingkan LLM vs novice vs expert, 
dengan pengujian post hoc (Bonferroni) pada beberapa subkategori. Dengan 
pendekatan ini, dilakukan penilaian tidak hanya pada “siapa yang lebih baik”, tetapi 
juga pada aspek apa LLM unggul/kurang, sehingga relevan bagi desain intervensi 
dan prompting ke depan. 

Studi tersebut menunjukkan bahwa hanya prompt berkualitas tinggi yang secara 
konsisten memicu LLM menghasilkan umpan balik bermutu, sehingga desain prompt 
menjadi faktor kunci. Dibanding penilai pemula, LLM unggul pada hampir semua 
subkategori, sementara pada aspek afektif tertentu seperti valensi dan penggunaan 
orang pertama keunggulan itu tidak tampak. Dibanding pakar, LLM melampaui 
pada explanation, questions, dan specificity dengan selisih rata-rata 
(M\textsubscript{diff}) masing-masing 0{,}46 
(CI 95\%: 0{,}17–0{,}74; p<0{,}001), 0{,}50 (CI 95\%: 0{,}07–0{,}93; p<0{,}05), dan 0{,}96 (CI 95\%: 0{,}52–1{,}41). 
Dari sisi efisiensi, ChatGPT-4 mampu menghasilkan sekitar 49 umpan balik 
dalam waktu yang sama ketika seorang pakar hanya menyusun satu, sehingga LLM 
berpotensi menjadi alternatif yang skalabel untuk umpan balik berkualitas 
asalkan perancangan prompt dilakukan dengan tepat.

Dilakukan penekanan bahwa kualitas prompt harus diajarkan sebagai 
keterampilan bagi pendidik; manual yang dikembangkan dapat dijadikan 
panduan praktis. Namun, terdapat keterbatasan yang perlu diperhatikan misalnya, 
halusinasi masih mungkin terjadi pada prompt tertentu, dan persepsi siswa 
terhadap umpan balik LLM serta transfer ke konteks/mata kuliah lain perlu 
diteliti lebih lanjut. Dengan kata lain, LLM berpotensi menjadi alternatif 
berkualitas dan efisien untuk sebagian peran feedback pakar, tetapi desain 
prompt serta pengawasan pedagogis tetap penting agar umpan balik selaras 
dengan kebutuhan dan konteks kursus.


\subsection{\textit{Reinforcement Learning from Human Feedback} (RLHF) untuk Peningkatan Kualitas Respons}
\label{subsection:rlhf}
Makalah berjudul “\textit{Training language models to follow instructions 
with human feedback}” ini ditulis oleh Long Ouyang, Jeff Wu, Xu Jiang, 
Diogo Almeida, Carroll L. Wainwright, dkk. 
\cite{ouyang2022traininglanguagemodelsfollow}, sebagai proyek tim Alignment 
di OpenAI. Mereka memulai dari pengamatan bahwa memperbesar model bahasa 
tidak otomatis membuatnya lebih mampu mengikuti niat pengguna; model besar 
tetap bisa menghasilkan keluaran yang tidak benar, toksik, atau tidak membantu 
sehingga tidak selaras (misaligned) dengan kebutuhan pengguna. Paper ini 
menawarkan arah untuk menyelaraskan model dengan niat pengguna pada beragam 
tugas melalui penyelarasan berbasis umpan balik manusia (fine-tuning with human feedback).

Masalah utamanya adalah ketidakselarasan tujuan pelatihan model bahasa 
(memprediksi token berikutnya dari web) dengan tujuan penggunaan di dunia 
nyata (mengikuti instruksi secara membantu, jujur, dan aman). Konsekuensinya, 
meski bisa diprompt untuk banyak tugas, model sering “membuat fakta”, 
bias/toksik, atau tidak mengikuti instruksi pengguna. Tim menekankan 
kebutuhan menyelaraskan model agar helpful-honest-harmless dalam 
penggunaan sehari-hari.
Solusi mereka adalah pipeline RLHF (reinforcement learning from human 
feedback) dengan tiga tahap: (1) Supervised fine-tuning (SFT) pada demonstrasi 
yang ditulis pelabel tentang perilaku model yang diinginkan; (2) pelatihan 
reward model (RM) dari perbandingan/ranking beberapa keluaran model oleh 
pelabel; (3) optimasi kebijakan dengan PPO menggunakan RM sebagai sinyal 
ganjaran. Dataset dikumpulkan dari prompt yang ditulis pelabel dan prompt 
nyata yang disubmit melalui OpenAI API, sehingga mencerminkan distribusi 
penggunaan riil. Hasilnya adalah keluarga model InstructGPT.

Secara operasional, RM akhir diinisialisasi dari GPT-3 6B yang telah 
di-\textit{fine-tune} pada beragam dataset NLP publik; pelatihan RM 
dilakukan satu \textit{epoch} pada himpunan latih, dan mereka menemukan 
pelatihan sensitif terhadap jumlah \textit{epoch} (multi-\textit{epoch} 
cepat \textit{overfit}), sementara \textit{learning rate} tidak terlalu 
sensitif. Untuk model RLHF, kebijakan diinisialisasi dari model SFT 
dengan campuran 10\% data pra-latih (membantu stabilitas PPO), 
kemudian dilatih sebanyak 256{,}000 episode yang mencakup sekitar 
31{,}000 \textit{prompt} unik (setelah penyaringan PII dan deduplikasi). 
\textit{Batch} per iterasi sebanyak 512 (dipecah menjadi 8 \textit{minibatch} 
berukuran 64) dan hanya satu \textit{inner epoch} per iterasi; 
\textit{warmup} pada 10 iterasi pertama, ditambah KL reward mengikuti 
Stiennon dkk.\ ($\beta=0{,}02$). Rincian ini memperlihatkan setup 
yang hati-hati agar PPO stabil pada skala 1{,}3B/6B/175B.

Evaluasi utama menggunakan preferensi manusia di atas distribusi prompt 
API (mencerminkan use-case riil), serta metrik safety seperti 
truthfulness dan toxicity (dengan regresi kinerja minimal pada dataset 
NLP publik). Mereka juga memformalkan tujuan evaluasi selaras dengan 
kerangka \textit{helpful, honest, harmless}. Visualisasi utama (Figur 1) menampilkan 
seberapa sering keluaran model lebih disukai dibanding \textit{baseline} GPT-3 175B (SFT).

Secara konsisten, InstructGPT menunjukkan perbaikan yang berarti: model 
1.3B mereka lebih sering dipilih manusia dibanding GPT-3 175B, meski 100 kali 
lebih kecil; ada peningkatan truthfulness dan penurunan toksisitas, sambil 
menjaga regresi kinerja pada dataset publik tetap minimal. Ini memperlihatkan 
bahwa penyelarasan dengan umpan balik manusia lebih menentukan daripada 
sekadar memperbesar parameter. Selain itu terdapat keterbatasan model yang 
masih bisa melakukan kesalahan sederhana. Namun, arah ini dinilai menjanjikan 
untuk menyelaraskan model dengan niat pengguna di banyak aplikasi.

\subsection{Regulasi Diri dalam Pendidikan Pemrograman Berbasis LLM dengan \textit{Learning Analytics}}
Makalah \textit{Design of AI-Powered Tool for Self-Regulation Support in Programming 
Education} karya Huiyong Li dan Boxuan Ma dari Kyushu University 
\cite{li2025designaipoweredtoolselfregulation}, disajikan pada CHI 2025 Workshop: 
Augmented Educators and AI, berangkat dari tantangan integrasi AI di pendidikan 
pemrograman. Banyak alat berbasis LLM yang digunakan mahasiswa berjalan di luar 
LMS institusional seperti Moodle. Keterpisahan ini memutus keterkaitan penting 
dengan konteks perkuliahan, misalnya materi kuliah, rincian soal, dan hasil 
eksekusi kode. Dampaknya, umpan balik AI sering kurang selaras dengan tujuan 
dan ruang lingkup mata kuliah, sementara dosen kesulitan menelusuri dampak jangka 
panjang interaksi mahasiswa dengan AI karena tidak ada jejak data proses yang 
terkumpul secara sistematis di lingkungan LMS. Pada saat yang sama, sebagian besar 
riset LLM di domain ini masih memfokuskan akuisisi pengetahuan (seperti generasi 
kode dan perbaikan bug) sehingga perhatian pada keterampilan SRL seperti perencanaan, 
monitoring, dan refleksi—relatif kurang. Kekhawatiran lain adalah ketergantungan 
mahasiswa pada jawaban instan LLM, yang berisiko mengurangi upaya kognitif mendalam 
yang dibutuhkan pemula untuk membangun kemandirian belajar.

Untuk menjawab celah tersebut, dirancang solusi bernama CodeRunner Agent, sebuah alat 
LLM yang menempel langsung pada ekosistem Moodle. Ia memadukan \textit{lecture viewer} 
untuk penyajian materi, plugin CodeRunner guna menjalankan dan menilai kode secara 
otomatis, serta \textit{xAPI logging} ke Learning Record Store sehingga setiap 
interaksi penting—mulai dari akses materi, percobaan \textit{test case}, hingga 
permintaan bantuan yang terekam sebagai data proses. Di sisi pedagogis, dukungan SRL 
dioperasionalkan lewat model PPESS (\textit{Planning, Program creation, Error 
correction, Self-monitoring, Self-reflection}) yang menurunkan kerangka SRL Zimmerman 
khusus untuk pembelajaran pemrograman. Dengan pendekatan ini, mahasiswa bisa meminta 
bantuan sesuai fase SRL yang sedang dijalani, sehingga umpan balik AI tidak acak, 
melainkan terarah pada kebutuhan regulasi diri saat itu.

Arsitektur CodeRunner Agent menonjol karena mengandalkan dua mesin konteks. 
Pertama, LACE (\textit{Learning Analytics Context Engine}) yang merangkum metrik 
keterlibatan dan performansi dari jejak xAPI, seperti waktu yang dihabiskan, 
frekuensi upaya, tingkat keberhasilan, dan pola kesalahan, lalu menyuntikkan 
ringkasan tersebut ke \textit{prompt} agar respons LLM memanfaatkan sinyal 
perilaku SRL nyata. Kedua, KCE (\textit{Knowledge Context Engine}) yang mengelola 
basis pengetahuan materi kuliah dan latihan, termasuk konsep kunci, prasyarat, 
tingkat kesulitan, solusi, dan \textit{typical mistakes}, sehingga umpan balik 
AI selaras kurikulum dan menghindari kebocoran solusi langsung. Dosen dapat 
mengunggah materi, memutakhirkan basis pengetahuan, dan menyetel parameter 
konteks agar gaya dan standar umpan balik ``menjadi milik mata kuliah'' alih-alih 
generik.

Skenario penggunaan disiapkan untuk kelas pemrograman pemula. Mahasiswa menulis 
kode di CodeRunner, menjalankan \textit{test cases}, lalu mengakses panel 
LLM-based Support dan memilih fase SRL yang relevan, misalnya \textit{error 
correction} ketika menghadapi pesan kesalahan. Permintaan itu seperti identitas 
latihan, waktu, dan tipe bantuan tercatat sebagai xAPI. Dengan demikian 
terbentuk alur \textit{end-to-end} dari log pembelajaran, rekayasa 
konteks, dan respons LLM yang dapat dianalisis untuk penyelarasan 
pedagogis dan perbaikan berkelanjutan. Pada tahap ini, makalah berposisi sebagai 
paper rancangan dengan merencanakan \textit{pilot} jangka pendek dan 
eksperimen satu semester lintas beberapa kelas untuk memvalidasi rancangan pada 
situasi nyata.

Rencana evaluasi memanfaatkan log xAPI untuk melihat perubahan pola percobaan, 
akurasi, waktu penyelesaian, serta pergeseran strategi SRL ketika dukungan AI 
diaktifkan. Di luar metrik kuantitatif, dirancang juga studi kelas 
guna menilai kualitas, relevansi, dan keamanan pedagogis dari umpan balik LLM, 
termasuk apakah agen berhasil menjaga SRL (memberi \textit{scaffold} dan 
pertanyaan pemandu) alih-alih langsung membocorkan jawaban. Pendekatan evaluasi 
ganda ini menggabungkan analitik perilaku yang objektif dan penilaian pedagogis yang 
kualitatif ditujukan untuk memastikan alat tidak hanya berfungsi, tetapi 
bermanfaat bagi kemandirian belajar mahasiswa.

Kontribusi utama paper ini adalah rancangan terintegrasi yang menghubungkan 
data proses LMS dengan rekayasa konteks dan \textit{scaffolding} SRL berbasis 
LLM di lingkungan yang benar-benar digunakan kampus. Pemetaan PPESS memberi 
kerangka operasional agar bantuan AI selalu terkait fase SRL yang tepat, 
sementara LACE dan KCE memastikan umpan balik kontekstual, selaras kurikulum, 
dan mendorong kemandirian. Hasil yang ditekankan bukan angka evaluasi, 
melainkan kelayakan implementasi dan janji untuk kelas besar yang ingin 
memanfaatkan analitik pembelajaran serta dukungan AI tanpa mengorbankan tujuan 
pengembangan SRL. Validasi empiris disiapkan melalui \textit{pilot} dan studi 
semeseter penuh pada tahap berikutnya.

\subsection{Dashboard \textit{Real-time} untuk Orkestrasi Kelas Berbasis Kanban}

Makalah ini ditulis oleh Sven Strickroth, Melanie Kreidenweis, dan Andreas Götzfried. 
Mereka menyoroti tantangan nyata pada pembelajaran berbasis tugas di kelas yang bersifat 
kolaboratif. Ketika beberapa kelompok bergerak pada tugas berbeda dalam waktu yang sama, 
guru sulit memiliki pandangan menyeluruh tentang status pekerjaan setiap kelompok. Versi 
awal alat mereka, AgileBoard4Teaching, memang memungkinkan perencanaan dan pelaksanaan 
dengan papan Kanban per kelompok, tetapi berjalan sepenuhnya \textit{offline}. Guru 
perlu menyalurkan berkas ke semua siswa, berkeliling memeriksa satu per satu, serta 
tidak memiliki ringkasan progres kelas secara langsung. Di sisi lain, solusi profesional 
seperti Trello tidak ideal untuk sekolah karena fitur dan kebijakan privasi. Kebutuhan 
akan \textit{dashboard} \textit{real-time} menjadi titik mula rancangan mereka.

Solusi yang diusulkan adalah memperluas AgileBoard4Teaching menjadi sistem berjaringan 
dengan arsitektur \textit{client-server}. Di sisi guru tersedia \textit{authoring mode} 
untuk menyusun tugas dan putaran kerja lalu menggandakan papan untuk banyak kelompok. 
Di sisi siswa tersedia antarmuka Kanban tiga kolom \textit{ToDo}, \textit{In Progress}, 
\textit{Done} dengan unggah hasil dan permintaan \textit{review}. Inti pembeda adalah 
\textit{dashboard} guru yang menampilkan kotak ringkas untuk tiap kelompok. Guru dapat 
melihat jumlah tugas per kolom, daftar pekerjaan yang menunggu persetujuan, serta 
sinyal seperti \textit{raise hand}. Tersedia pula pengiriman pesan massal, penetapan 
\textit{timer}, dan jeda tampilan siswa. Secara teknis, sistem menggunakan 
Java Servlets dan MariaDB di \textit{backend}, penyimpanan papan sebagai JSON, 
komunikasi WebSocket untuk sinkronisasi perubahan secara langsung, dan opsi 
\textit{deployment} via Docker. Mekanisme bergabung untuk siswa menggunakan kode 
grup agar tetap ramah privasi tanpa akun individual.

Dilakukan dua studi evaluasi. Pertama, studi lapangan di kelas TIK tingkat 
8 pada topik \textit{CAD} selama tiga minggu dengan dua sesi per minggu. Desainnya 
\textit{within-subjects}. Satu minggu pertama menggunakan versi \textit{offline}, 
lalu beralih ke versi jaringan untuk membandingkan pengalaman secara adil. 
Total 18 siswa dalam 9 kelompok berpartisipasi. Pengumpulan data meliputi observasi 
langsung, kuesioner fitur, \textit{System Usability Scale} (SUS), wawancara dengan 
guru, serta analisis \textit{log} interaksi server. Kedua, studi simulasi berupa 
lokakarya dua jam yang diikuti 18 guru dan \textit{trainer} berpengalaman. Pada 
lokakarya ini, prototipe dipakai untuk mengorkestrasi kegiatan sehingga peserta 
mengalami peran “siswa” sekaligus menilai kegunaan alat.

Temuan dari studi lapangan menunjukkan pergeseran preferensi yang kuat ke versi 
jaringan. Siswa menyatakan alur kerja lebih lancar karena tidak perlu impor dan 
simpan manual. Fitur seperti \textit{raise hand}, pesan, \textit{timer}, dan 
\textit{pause} dinilai membantu koordinasi. SUS siswa mencapai 84 yang tergolong 
sangat baik dan SUS guru 92 yang termasuk kategori pengalaman terbaik. Analisis 
\textit{log} memperlihatkan intensitas penggunaan tinggi di kelas serta 
pemanfaatan di luar kelas untuk persiapan dan \textit{review}. Guru menyampaikan 
bahwa \textit{dashboard} paling berguna untuk meninjau progres banyak kelompok 
sekaligus dan menyiapkan pertemuan berikutnya. Selama sesi tatap muka, guru 
tidak selalu menatap \textit{dashboard} karena fokus pada pendampingan langsung. 
Beberapa saran muncul seperti tampilan yang lebih ringkas untuk kelas besar, 
pembuatan putaran baru secara cepat, serta statistik waktu dan progres.

Pada studi simulasi, para guru mengapresiasi sinkronisasi waktu nyata dan 
kemudahan kloning papan untuk banyak kelompok. SUS rata-rata 69 yang tetap 
masuk kategori baik. Skor ini dipengaruhi kejadian \textit{bug} yang membuat 
sebagian peserta terkendala masuk ke putaran kedua. Meski demikian, mayoritas 
peserta menyatakan ingin mencoba alat ini di kelas mereka. Masukan tambahan 
menyangkut kebutuhan versi terkelola yang stabil dan peningkatan visibilitas 
opsi komunikasi.

Secara keseluruhan, kontribusi utama makalah adalah desain dan prototipe 
\textit{dashboard} \textit{real-time} yang mendukung orkestrasi kelas 
\textit{agile} berbasis Kanban, lengkap dengan bukti kegunaan dari dua 
konteks evaluasi. Solusi ini menjembatani celah antara alat perencanaan 
yang kuat dan kebutuhan pemantauan langsung di kelas. Hasilnya menyiratkan 
kesiapan untuk dilanjutkan ke tahap produksi dan pengayaan fitur 
\textit{learning analytics} seperti waktu penyelesaian dan deviasi dari 
target. Ditekankan juga pentingnya menjaga keseimbangan antara informasi 
yang cukup dan beban kognitif guru agar \textit{dashboard} tetap dapat 
dibaca sekejap sekaligus memberi sinyal tindakan yang jelas.

\subsection{Perbandingan Metode Peningkatan Kualitas Respons LLM}
\label{subsection:tinjauan_perbandingan_metode}
Dapat dilihat, Tabel~\ref{tab:komparasi-llm-feedback} merangkum karya 
kunci yang mewakili dua arus utama yakni penyelarasan \textit{model} 
melalui \textit{fine-tuning} misalnya \textit{DPO} dan \textit{RLHF} 
serta penyelarasan \textit{konteks} melalui \textit{prompt} dan 
\textit{context engineering} serta orkestrasi kelas berbasis Kanban. 
% Setiap studi diringkas menurut empat aspek yaitu tujuan dan masalah 
% yang disasar, pendekatan dan teknik inti, konteks atau skenario 
% penggunaan dan evaluasi, serta temuan utama. Fokus komparasi 
% diarahkan pada kesesuaian dengan batasan penelitian ini tanpa 
% pelatihan ulang model, memanfaatkan model \textit{open source} 
% melalui Groq API, menggunakan bahasa Indonesia, serta bergantung 
% pada sinyal proses dari papan Kanban, dan pada implikasinya 
% bagi rancangan \textit{pipeline} yang menempatkan guru 
% \textit{in the loop}. Hasil perbandingan pada tabel menjadi 
% dasar pemilihan pendekatan orkestrasi ala Strickroth yang kemudian 
% dikombinasikan dengan \textit{LLM} dan \textit{learning analytics} 
% pada bagian berikut.

\clearpage
\begin{landscape}
\begin{table}[p]
\centering
\caption{Komparasi penelitian peningkatan kualitas umpan balik LLM di pendidikan}
\label{tab:komparasi-llm-feedback}
\scriptsize
\begin{tabular}{|p{2.8cm}|p{3.1cm}|p{3.2cm}|p{2.8cm}|p{4.2cm}|}
\hline
\textbf{Studi} & \textbf{Tujuan} & \textbf{Pendekatan Inti} & \textbf{Pelaksanaan Penelitian} & \textbf{Temuan Utama} \\
\hline
Woodrow et al.\ (EDM 2025) \cite{woodrow2025dpo_feedback} &
Menyelaraskan gaya dan isi feedback AI dengan preferensi pengajar &
\textit{Direct Preference Optimization} dengan guru/TA di dalam loop. Preferensi menang-kalah dari dua kandidat umpan balik dipakai untuk fine-tuning &
Mata kuliah besar. Siklus antartugas. Observasi pekerjaan mahasiswa diringkas ke prompt terstruktur &
Studi terkontrol menunjukkan DPO lebih disukai daripada GPT-4o. Skor insight lebih tinggi. \textit{Naturalness} setara. Evaluasi otomatis juga lebih baik pada empat dari lima dimensi. DPO kadang lebih panjang \\
\hline
Jacobsen \& Weber\ (2025) \cite{jacobsen2025promises} &
Menentukan desain prompt yang memicu feedback LLM berkualitas serta membandingkan LLM dengan manusia &
Manual prompt berbasis teori. Tiga kualitas prompt rendah menengah tinggi. LLM dibanding novice dan expert pada tugas geometri &
Feedback pada learning goal dan miskonsepsi umum. Semua pihak memakai prompt berkualitas tinggi untuk pembandingan adil &
Prompt berkualitas tinggi menghasilkan feedback terbaik. LLM mengungguli novice di hampir semua subkategori. LLM melampaui expert pada explanation questions specificity. Efisiensi LLM jauh lebih tinggi \\
\hline
Ouyang et al.\ (InstructGPT, 2022) \cite{ouyang2022traininglanguagemodelsfollow} &
Menyelaraskan model agar mengikuti instruksi yang membantu jujur dan aman &
\textit{RLHF} tiga tahap. SFT pada demonstrasi manusia. Reward model dari perbandingan keluaran. PPO untuk mengoptimalkan kebijakan &
Berbagai tugas umum. Prompt dari pelabel dan pengguna API. Bukan konteks kursus spesifik &
Model kecil yang telah selaras lebih sering dipilih manusia dibanding GPT-3 yang jauh lebih besar. Truthfulness naik dan toksisitas turun. Kerangka selaras tugas umum bukan feedback proses belajar \\
\hline
Li \& Ma\ (CHI 2025 WS) \cite{li2025designaipoweredtoolselfregulation} &
Merancang alat LLM yang mendukung SRL di pemrograman serta tetap terhubung ke LMS &
Rekayasa konteks ganda. LACE untuk ringkasan learning analytics berbasis xAPI. KCE untuk pengetahuan kurikulum. Pemetaan SRL ke PPESS &
Moodle dengan CodeRunner. Log xAPI merekam akses materi upaya tes dan bantuan. Fase SRL dipilih pengguna untuk memicu bantuan yang tepat &
Paper rancangan. Rencana uji lapangan dan studi satu semester. Menekankan kelayakan integrasi. Fokus pada dukungan SRL dan kontrol kebocoran jawaban. Belum ada angka hasil akhir \\
\hline
Strickroth et al.\ (2025) \cite{Strickroth2025LiveTeacherDashboard} &
\textit{Dashboard} \textit{real-time} untuk orkestrasi kelas Kanban agar guru memantau progres banyak kelompok &
Ekstensi AgileBoard4Teaching ke sistem \textit{client--server}. \textit{Dashboard} guru. Sinkronisasi \textit{WebSocket}. Penyimpanan papan JSON. Opsi \textit{deployment} Docker. Mekanisme kode grup ramah privasi &
Kelas TIK tingkat 8 topik \textit{CAD}. 18 siswa 9 kelompok. Desain \textit{within-subjects} \textit{offline} ke jaringan. Lokakarya dua jam dengan 18 guru/\textit{trainer}. Data observasi kuesioner SUS wawancara dan \textit{log} server &
Preferensi kuat ke versi jaringan. Alur kerja lebih lancar. SUS siswa 84 dan SUS guru 92. Lokakarya SUS 69. Masukan lanjutan meliputi tampilan ringkas kelas besar pembuatan putaran cepat serta statistik waktu dan progres \\
\hline
\end{tabular}
\end{table}
\end{landscape}
\clearpage

% \subsection{Sintesis Kritis dan Rasional Pemilihan Pendekatan}
 
Tabel~\ref{tab:komparasi-llm-feedback} secara garis besar menjelaskan
karya terdahulu yang berpencar ke dua arus utama. Arus pertama 
berfokus pada penyelarasan \textit{model} melalui \textit{fine-tuning}, misalnya 
\textit{Direct Preference Optimization} (DPO) \cite{woodrow2025dpo_feedback} dan 
\textit{Reinforcement Learning from Human Feedback} (RLHF) 
\cite{ouyang2022traininglanguagemodelsfollow}. Arus kedua menekankan penyelarasan 
\textit{konteks} melalui perancangan \textit{prompt} dan lingkungan interaksi 
beserta pemanfaatan data proses pembelajaran, sebagaimana tampak pada 
\cite{jacobsen2025promises} dan \cite{li2025designaipoweredtoolselfregulation}. 
Di luar itu, \cite{Strickroth2025LiveTeacherDashboard} menawarkan orkestrasi 
kelas berbasis papan Kanban dengan \textit{dashboard} \textit{real-time} yang 
kaya sinyal proses sehingga menyediakan landasan operasional untuk memantau 
dan menindaklanjuti progres kelompok secara langsung.

Dari sisi tujuan intervensi, DPO dan RLHF mengubah parameter model agar keluaran 
lebih selaras dengan preferensi manusia 
\cite{woodrow2025dpo_feedback,ouyang2022traininglanguagemodelsfollow}. 
Sebaliknya, \cite{jacobsen2025promises} memperlihatkan bahwa \textit{prompt} 
berkualitas tinggi dapat mendorong kualitas umpan balik tanpa perlu pelatihan 
ulang, sementara \cite{li2025designaipoweredtoolselfregulation} menekankan 
rekayasa konteks yang ditopang oleh \textit{learning analytics}. 
Penelitian Woodrow juga tidak berfokus pada konteks SRL, melainkan pada
penyelarasan gaya dan isi umpan balik sesuai preferensi pengajar. Walaupun 
metrik evaluasi otomatis yang digunakan Woodrow dkk.\ (kerangka Scarlatos 
\cite{scarlatos2024validity}) mendukung adanya fungsi pedagogis yang mendukung
SRL, hal tersebut bukan fokus utama penelitian mereka.

Menariknya, \cite{Strickroth2025LiveTeacherDashboard} 
secara tidak langsung menyediakan
fitur yang mendukung guru untuk melakukan tugas \textit{learning analytics}.
Hal ini dapat dilihat dari kemampuan \textit{dashboard} dalam menampilkan 
seperti jumlah tugas per kolom, daftar pekerjaan, dan waktu yang dihabiskan
oleh siswa pada setiap tugas. Dengan demikian, guru dapat memantau
aktivitas pembelajaran secara real-time dan mengambil tindakan yang diperlukan.
Penelitian ini memosisikan diri pada jalur kedua, yaitu optimalisasi 
konteks, sejalan dengan batasan metodologis bahwa tidak 
dilakukan \textit{fine-tuning}.

Penelitian \cite{jacobsen2025promises} memperlihatkan bagaimana 
rekayasa \textit{prompt} 
(\textit{prompt engineering}) memengaruhi kualitas umpan balik dari 
\textit{Large Language Models} (LLM). Metode yang digunakan adalah 
mengembangkan sebuah panduan perancangan \textit{prompt} berbasis 
(\textit{theory-driven prompt manual}) untuk menciptakan 
tiga jenis \textit{prompt} dengan kualitas berbeda yaitu rendah, 
sedang, dan tinggi. Berikut adalah hasil dari yang dikerjakan oleh Jacobsen.

% Tambahkan di preamble:
% \usepackage{booktabs,tabularx}
% \clearpage 
% Tidak perlu \begin{landscape}

% \begin{table}[htbp] diganti menjadi:
% ====== Preamble (pastikan paket ini tersedia) ======
% \usepackage{booktabs}
% \usepackage{tabularx}

\clearpage
% \begin{landscape}
	
% === Preamble (sekali saja di preamble dokumen Anda) ===
% \usepackage{tabularx}
% \usepackage{booktabs}
% \usepackage{array}

% Tipe kolom Y = raggedright versi X (bisa taruh di preamble)
\newcolumntype{Y}{>{\raggedright\arraybackslash}X}

% === Tabel (siap tempel) ===
\begin{table}[htbp]
\centering
\caption{Prompt manual to ensure the development of high-quality prompts.}
\label{tab:prompt-manual}

\begingroup
\setlength{\tabcolsep}{8pt}        % rapatkan kolom (opsional)
\renewcommand{\arraystretch}{1.5} % tinggi baris (opsional)
\scriptsize                        % <<< kecilkan font tabel (ganti ke \footnotesize/\tiny bila perlu)

\begin{tabularx}{\textwidth}{@{}p{2.3cm}p{3.0cm}YYY@{}}
\toprule
\textbf{Kategori} & \textbf{Subkategori} & \textbf{Tinggi (2)} & \textbf{Sedang (1)} & \textbf{Rendah (0)} \\
\midrule
% draw a horizontal rule only across columns 3-5:
% \cmidrule(lr){3-5}

Context & Role &
Peran LLM dan penanya dijelaskan &
Hanya satu peran yang dijelaskan &
Tidak ada peran LLM maupun penanya yang dijelaskan \\[-0.2em]
\cmidrule(lr){2-5}

% Example: “You are a mathematics tutor assisting a high school student with geometry problems. I am the teacher creating a learning goal for this task”.

 & Target audience &
Ada target audiens yang jelas didefinisikan dan dijelaskan &
Target audiens dijelaskan secara kasar &
Target audiens tidak ditentukan \\[-0.2em]
\cmidrule(lr){2-5}
% Example: “The audience is high school students learning geometry in grade 10, with a focus on foundational concepts like the Pythagorean theorem”.

 & Medium/channel &
Media atau saluran tempat informasi disajikan dijelaskan dengan jelas &
Media atau saluran dijelaskan secara kasar &
Media atau saluran tidak disebutkan \\[-0.2em]
\midrule
% Clarifying: specify platform/format (tweet, essay, email, slides) so tone/structure fit.

Mission & Mission/question &
Misi LLM dijelaskan dengan jelas &
Misi LLM dijelaskan secara kasar &
Misi LLM tidak jelas \\[-0.2em]
\midrule
% Example: “Create a clear learning goal for a grade-10 geometry class on the Pythagorean theorem and its applications”.

Clarity dan specificity & Format and constraints &
Properti stilistika serta spesifikasi panjang yang dideskripsikan &
Hanya properti stilistika ATAU spesifikasi panjang yang diberikan &
Tidak ada properti stilistika maupun spesifikasi panjang yang diberikan \\[-0.2em]
\cmidrule(lr){2-5}
% Example: “Use concise bullet points (≤20 words each), total ≤200 words”.

 & Conciseness &
\textit{Prompt} hanya berisi informasi yang langsung terkait dan relevan dengan output, serta jelas dan ringkas &
\textit{Prompt} ringkas dengan sedikit informasi berlebih &
\textit{Prompt} mengandung banyak informasi yang tidak relevan dengan misi/pertanyaan \\[-0.2em]
\cmidrule(lr){2-5}
% Clarifying: keep only essential info to avoid diluting focus.

 & Domain specificity & 
Istilah teknis digunakan dengan benar dan memungkinkan LLM merujuknya di dalam jawaban &
Istilah teknis digunakan sesekali atau tanpa penjelasan &
Tidak menggunakan kosakata spesifik yang relevan dengan bidang subjek \\[-0.2em]
\cmidrule(lr){2-5}
% Example: “right triangle”, “hypotenuse”, “Pythagorean theorem”.

 & Logic & 
\textit{Prompt} memiliki alur baca yang sangat baik, koherensi logis internal, urutan informasi yang koheren, dan hubungan yang jelas antara konten dan misi &
\textit{Prompt} hanya memenuhi beberapa kondisi ini &
\textit{Prompt} disusun secara tidak logis \\
\midrule
% final partial rule for last row of scores:
% \cmidrule(lr){3-5}

\bottomrule
\end{tabularx}

\endgroup
\end{table}
% \end{landscape}
% Tidak perlu \end{landscape}

Studi ini menemukan bahwa hanya \textit{prompt} 
dengan kualitas terbaik yang secara konsisten menghasilkan umpan 
balik berkualitas tinggi, yang kualitasnya bahkan melampaui umpan 
balik dari para ahli (\textit{experts}) dalam beberapa kategori 
seperti penjelasan, pertanyaan, dan spesifisitas. Pendekatan ini 
sangat berpotensi untuk diterapkan karena menawarkan efisiensi tinggi 
dengan menghasilkan umpan balik berkualitas yang jauh lebih cepat 
daripada ahli. Hal ini juga tidak memerlukan \textit{fine-tuning} 
model, sehingga relatif murah dari segi sumber daya komputasi dan 
waktu.


Untuk perspektif sumber daya dan kelayakan, pendekatan DPO/RLHF menuntut 
data preferensi atau label serta infrastruktur pelatihan. Hal tersebut tidak 
selaras dengan rancangan studi ini yang memanfaatkan model \textit{open source} 
melalui Groq API tanpa pelatihan ulang. 
Pendekatan \textit{prompt}/\textit{context engineering} 
lebih ringan dijalankan, mudah direplikasi, dan sesuai dengan keterbatasan 
komputasi maupun waktu. Penelitian \cite{Strickroth2025LiveTeacherDashboard} 
memanfaatkan \textit{dashboard real-time} 
dan jejak proses Kanban yang memungkinkan pemantauan 
banyak kelompok sekaligus, pengumpulan sinyal proses yang autentik, dan 
pengambilan tindakan cepat oleh pengajar. Tidak seperti penelitian Li dan Ma
\cite{li2025designaipoweredtoolselfregulation} yang menggunakan Moodle sebagai
\textit{backbone} platform, platform \textit{dashboard real-time} milik Strickroth dkk.\
dapat memberikan data yang lebih luas dan fleksibel untuk memantau keseluruhan
proses pembelajaran kolaboratif berbasis Kanban. Penggunaan papan Kanban oleh
pada penelitian \cite{Strickroth2025LiveTeacherDashboard} juga sesuai
dengan keselarasan pada pembahasan latar belakang penelitian ini yaitu pemanfaatan 
jejak proses belajar mahasiswa yang direpresentasikan dalam bentuk papan kanban. Komponen-komponen ini 
belum tercakup pada studi yang berfokus pada \textit{prompt} semata oleh Ouyang 
\cite{ouyang2022traininglanguagemodelsfollow}. 
Hal ini membuat beberapa komponen yang ada di
penelitian Strickroth dkk.\ dapat dimanfaatkan untuk memperkaya konteks
umpan balik LLM.
% Karena itu, penelitian 
% ini memilih menjadikan pendekatan Strickroth sebagai \textit{backbone} orkestrasi 
% sekaligus sumber data proses.

Dari sisi kontrol pedagogis, tetap dipertahankan melalui penilaian kualitatif yang akan
ditinjau langsung oleh pakar pendidikan. Keluaran LLM yang berupa \textit{feedback}
ditinjau dan dinilai melalui rubrik penilaian yang telah dipersiapkan. 
Dengan cara ini, kualitas pedagogis tetap terjaga dan sejalan dengan 
kebutuhan untuk dilakukan penilaian oleh pakar manusia.

% Kombinasi pilihan di atas dioperasionalkan melalui kerangka integrasi 
% \textit{Kanban} $\rightarrow$ \textit{Learning Analytics} $\rightarrow$ 
% \textit{LLM} $\rightarrow$ \textit{Guru}. Pertama, sinyal proses dari papan 
% Kanban—waktu tinggal kartu per kolom, jumlah perpindahan, deteksi \textit{blocked}, 
% \textit{work-in-progress} per kelompok, dan status \textit{review}—diakuisisi dari 
% \textit{dashboard} ala \cite{Strickroth2025LiveTeacherDashboard}. Kedua, sinyal 
% tersebut diringkas menjadi paket \textit{learning analytics} yang dipetakan ke 
% fase SRL (perencanaan, pelaksanaan, refleksi) beserta indikator risiko seperti 
% kartu lama di \textit{In Progress}, banyak \textit{reopen}, atau \textit{idle time} 
% yang tinggi, terinspirasi rancangan konteks pada 
% \cite{li2025designaipoweredtoolselfregulation}. Ketiga, paket konteks disisipkan ke 
% templat \textit{prompt} yang menargetkan tiga fungsi pedagogis—\textit{feedback} 
% kognitif, dukungan motivasional, dan dukungan apresiatif—dengan gaya instruksi 
% yang disempurnakan mengikuti temuan \cite{jacobsen2025promises}. Keempat, respons 
% dihasilkan oleh LLM melalui Groq API tanpa \textit{fine-tuning} dengan kontrol 
% parameter \textit{decoding} untuk stabilitas keluaran. Kelima, guru melakukan 
% \textit{review} singkat atas keluaran sebelum disalurkan ke kelompok.

% Implikasi evaluasi menyentuh dua sisi. Secara kuantitatif, kualitas keluaran 
% diukur terhadap acuan pakar melalui kesepadanan isi, spesifisitas saran, kepatuhan 
% format, dan metrik klasifikasi seperti \textit{precision}, \textit{recall}, 
% serta \textit{macro F1}. Secara kualitatif, \textit{expert review} menilai 
% tiga fungsi pedagogis dan keberterimaan dalam konteks kelas. Selain itu, 
% indikator proses dari \textit{dashboard}—misalnya waktu tanggap intervensi, 
% penurunan tugas yang macet, dan konsistensi progres—digunakan untuk melihat 
% dampak orkestrasi terhadap aktivitas kelompok.

Dengan demikian, penelitian ini mendapatkan celah perbaruan di mana 
pendekatan \textit{prompting} dan \textit{context engineering} yang murah
sumber daya dan biaya digabungkan dengan \textit{learning analytics} yang
berasal dari papan Kanban untuk memperkaya konteks umpan balik LLM. Kombinasi
tersebut belum pernah dibahas sebelumnya oleh literatur yang ada. Celah 
penelitian ini akan dievaluasi secara kuantitatif untuk mengukur kualitas
keluaran LLM terhadap acuan pakar serta secara kualitatif melalui penilaian
pakar pendidikan untuk menjaga kualitas pedagogis. Melalui batasan-batasan
yang telah ditetapkan, rancangan ini menawarkan solusi praktis dan efektif.
Pilihan metodologis ini konsisten dengan batasan penelitian, 
memanfaatkan data proses untuk memperkuat konteks \textit{prompt}, 
menjaga peran guru sebagai pengarah kualitas, dan menghadirkan 
kesiapan implementasi di lapangan.

% Dengan demikian, kontribusi yang diposisikan menjadi jelas. Dibanding DPO/RLHF, 
% rancangan ini tidak menambah biaya pelatihan dan dapat diadopsi dengan cepat. 
% Dibanding pendekatan yang mengandalkan \textit{prompt} saja, rancangan ini 
% memperkaya konteks dengan sinyal proses autentik dari Kanban sehingga umpan 
% balik lebih tepat sasaran. Dibanding rancangan LA yang melekat pada LMS 
% tertentu, pendekatan ini bersifat instrumen-agnostik melalui papan Kanban 
% dan siap diterapkan di kelas kolaboratif berbahasa Indonesia. Pilihan 
% metodologis ini konsisten dengan batasan penelitian, memanfaatkan data proses 
% untuk memperkuat konteks \textit{prompt}, menjaga peran guru sebagai pengarah 
% kualitas, dan menghadirkan kesiapan implementasi di lapangan.

% % 

% \usepackage{pdflscape}
% \newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}

% \begin{landscape}
%     \begin{longtable}{|p{2.5cm}|p{1.3cm}|p{5.7cm}|p{3.2cm}|p{4.8cm}|p{5.7cm}|}
%         \caption{Perbandingan Penelitian M-Paspor}
%         \label{tab:Tabel_Penelitian_MPaspor}
%         \\
        
%         % Header pada halaman pertama
%         \hline \footnotesize
%         \textbf{Penulis} & \footnotesize \textbf{Tahun} & \footnotesize \textbf{Tujuan Penelitian} & \footnotesize \textbf{Objek Penelitian} & \footnotesize \textbf{Metode Penelitian} & \footnotesize \textbf{Hasil Penelitian} \\
%         \hline
%         \endfirsthead

%         % Header pada halaman berikutnya
%         \hline
%         \footnotesize \textbf{Penulis} & \footnotesize \textbf{Tahun} & \footnotesize \textbf{Tujuan Penelitian} & \footnotesize \textbf{Objek Penelitian} & \footnotesize \textbf{Metode Penelitian} & \footnotesize \textbf{Hasil Penelitian} \\
%         \hline
%         \endhead

%         % Footer (nomor halaman atau penanda lainnya)
%         \hline
%         \multicolumn{6}{|r|}{ \footnotesize Lanjutan pada halaman berikutnya} \\
%         \hline
%         \endfoot

%         % Footer pada halaman terakhir
%         \hline
%         \multicolumn{6}{|r|}{\footnotesize Akhir Tabel} \\
%         \hline
%         \endlastfoot
        
%         % Mengecilkan font lebih lanjut
%         % Data Penelitian 1
%         \footnotesize Steven Mavish, Henoch Juli Christanto, Stephen Aprius Sutresno & \footnotesize 2024 & \footnotesize Menganalisis dan meredesain aplikasi M-Paspor menggunakan metode Design Thinking untuk meningkatkan usability dan pengalaman pengguna. & \footnotesize Aplikasi M-Paspor & \footnotesize
%             \begin{itemize}[left=0pt, nosep]
%                 \item Design Thinking
%                 \item Evaluasi usability
%             \end{itemize}
%         & \footnotesize Redesain aplikasi meningkatkan navigasi yang lebih intuitif, formulir lebih efisien, dan mengurangi kesalahan pengguna. Kepuasan pengguna meningkat, dengan rekomendasi untuk pengembangan fitur lebih lanjut dan evaluasi berkelanjutan. \\
%         \hline
%         % Data Penelitian 2
%         \footnotesize Shiddiq Muhammad Taufiq & \footnotesize 2022 & \footnotesize Mengembangkan tampilan pada aplikasi M-Paspor dengan metode five planes agar terlihat lebih menarik dan nyaman di gunakan sehingga dapat meningkatkan pelayanan terhadap masyarakat & \footnotesize Aplikasi M-Paspor & \footnotesize Perancangan UX dengan pendekatan Five Planes dan analisis deskriptif kualitatif. Pengujian usability dilakukan menggunakan UEQ. & \footnotesize Perbaikan UI/UX meningkatkan daya tarik, kejelasan, dan efisiensi aplikasi. Evaluasi UEQ menunjukkan hasil “Good” secara keseluruhan dan “Excellent” untuk kejelasan. \\
%         \hline
%         % Data Penelitian 3
%         \footnotesize Amilia Purnama, Marcelina Lailatul Fitria, Ryandhika Yudhistira Widyaputra, Sunardi 3 & \footnotesize 2024 & \footnotesize Meneliti pengalaman pengguna (user experience) dari aplikasi M-Paspor dengan menganalisis sentimen pengguna serta mengevaluasi antarmuka aplikasi melalui cognitive walkthrough. & \footnotesize Aplikasi M-Paspor & \footnotesize 
%             \begin{itemize}[left=0pt, nosep]
%                 \item Analisis sentimen dari ulasan pengguna
%                 \item Cognitive Walkthrough dengan pengguna berpengalaman dan tidak berpengalaman
%             \end{itemize} & \footnotesize Ditemukan masalah pada beberapa fitur aplikasi. Direkomendasikan fitur penyimpanan login, otomatisasi data, notifikasi kuota, dan perbaikan alur lokasi untuk meningkatkan efisiensi dan kepuasan pengguna. \\
%         \hline
%         % Data Penelitian 4
%         \footnotesize Claudia, Dessi Puji Lestari & \footnotesize 2024 & \footnotesize Mengembangkan desain interaksi M-Paspor Indonesia agar lebih mudah digunakan, dengan alur pendaftaran yang efisien dan efektif sesuai dengan kebutuhan pengguna. & \footnotesize Aplikasi M-Paspor & \footnotesize 
%         \begin{itemize}[left=0pt, nosep]
%                 \item User-Centered Design (UCD) dengan prinsip citizen-centric e-government
%                 \item Pengembangan high-fidelity prototype dengan React Native
%                 \item Evaluasi usability menggunakan SEQ dan SUS
%             \end{itemize}
%             & \footnotesize Diidentifikasi 13 fitur perbaikan untuk aplikasi M-Paspor. Evaluasi SEQ dan SUS menunjukkan peningkatan skor tiap iterasi, membuktikan desain lebih efektif, efisien, mudah dipelajari, dan mendukung proses pendaftaran paspor. \\
%         \hline
%         % Data Penelitian 5
%         \footnotesize Avidhyana Sukma Valenta, Agi Putra Kharisma, Herman Tolle & \footnotesize 2024 & \footnotesize Mengevaluasi usability dan meningkatkan pengalaman pengguna aplikasi M-Paspor dengan merancang solusi berbasis desain menggunakan 4D Framework. & \footnotesize Aplikasi M-Paspor & \footnotesize 
%         \begin{itemize}[left=0pt, nosep]
%             \item Pendekatan 4D Framework
%             \item Heuristic evaluation oleh lima evaluator
%             \item Usability testing (completion rate, missclick rate, task completion time, SEQ)
%             \item Analisis statistik menggunakan chi-square dan t-test
%         \end{itemize} & \footnotesize Desain baru meningkatkan \textit{completion rate} menjadi 89{,}81\%, efisiensi dari 0{,}07 menjadi 0{,}12 \textit{goals/second}, dan kepuasan (SEQ) dari 5{,}07 ke 6{,}83. \textit{T-test} menunjukkan peningkatan signifikan, membuktikan efektivitas pendekatan \textit{4D Framework}. \\
%         \hline
%         % Data Penelitian 6
%         \footnotesize Alexander Ryan Hendarto, Indah Werdiningsih, Kartono & \footnotesize 2023 & \footnotesize Penelitian ini bertujuan untuk mengevaluasi dan memberikan rekomendasi perbaikan antarmuka pengguna (UI) guna meningkatkan pengalaman pengguna (UX) dalam penggunaan aplikasi M-Paspor. & \footnotesize Aplikasi M-Paspor & \footnotesize 
%         \begin{itemize}[left=0pt, nosep]
%             \item Design Thinking (empathize, define, ideate, prototype, dan test)
%             \item Usability test pada 15 responden dengan lima skenario
%         \end{itemize} & \footnotesize Penelitian menunjukkan pengalaman pengguna M-Paspor diuji dengan lima skenario, menghasilkan efektivitas 100\%, efisiensi 0.133 goals/detik, dan kepuasan 5.1/7. Evaluasi memberi tujuh rekomendasi untuk perbaikan UI. \\
%         \hline
%         % Data Penelitian 7
%         \footnotesize Michael J. Albers, Janet Patton Tracy & \footnotesize 2006 & \footnotesize Mengukur cognitive load yang dialami oleh pengguna saat melakukan uji kegunaan situs web, serta untuk menganalisis bagaimana cognitive load mempengaruhi pengalaman pengguna dan pengoptimalan desain situs. & \footnotesize Situs web secara umum. & \footnotesize Pengukuran cognitive load dengan NASA TLX, Sternberg Memory Test, dan Tapping Test. & \footnotesize NASA TLX efektif mendeteksi masalah desain situs, dan perbaikan desain yang mengurangi cognitive load dapat meningkatkan pengalaman pengguna. \\
%         \hline
%         % Data Penelitian 8
%         \footnotesize Neşe Zayım, Hasibe Yıldız, Yılmaz Kemal Yüce & \footnotesize 2023 & \footnotesize Penelitian ini mengukur cognitive workload yang dialami oleh pengguna aplikasi kesehatan ketika melaksanakan tugas-tugas di aplikasi kesehatan pribadi berbasis mobile. & \footnotesize Aplikasi mPHR (Mobile Personal Health Records) & \footnotesize
%         \begin{itemize}[left=0pt, nosep]
%             \item Cognitive workload dengan NASA-TLX pada 30 partisipan.
%             \item Eye tracking device untuk mengukur durasi waktu penyelesaian tugas.
%         \end{itemize} & \footnotesize Terdapat perbedaan signifikan dalam cognitive load antara pengguna berpengalaman dan pemula, meskipun waktu penyelesaian tugas tidak menunjukkan perbedaan signifikan. Cognitive load lebih rendah pada pengguna berpengalaman. \\
%         \hline
%     \end{longtable}
% \end{landscape}

\subsection{Metode Evaluasi Umpan Balik LLM dalam Pendidikan}
\label{subsection:tinjauan_evaluasi_kuantitatif}

Evaluasi kualitas teks yang dihasilkan oleh \textit{Large Language Models} (LLM) 
merupakan tantangan kompleks yang memerlukan pendekatan multi-aspek. Secara historis, 
metrik evaluasi didominasi oleh metode berbasis tumpang tindih leksikal seperti BLEU 
dan ROUGE. Metrik ini bekerja dengan menghitung kesamaan \textit{n-gram} (urutan kata) 
antara teks yang dihasilkan dan teks referensi (\textit{ground truth}) \cite{Tang2023EvaluatingLLMsMedEvidence}. Namun, 
ketergantungan pada pencocokan permukaan ini memiliki kelemahan signifikan; 
metrik ini gagal memahami kesetaraan makna (semantik) dan sering kali memberikan 
skor rendah pada parafrasa yang valid, ketika dua kalimat memiliki arti yang sama 
tetapi menggunakan kosakata yang berbeda \cite{Lakatos2024RAGvsFinetuneKBS}. 
Berbagai studi telah menunjukkan bahwa 
korelasi metrik ini dengan penilaian manusia sering kali rendah, terutama dalam 
tugas-tugas yang menuntut keragaman ekspresi seperti simplifikasi teks atau dialog 
\cite{Sulem2018BLEUNotSuitableTS}.

% reference:
% [1]https://pmc.ncbi.nlm.nih.gov/articles/PMC10449915/
% [2]https://arxiv.org/pdf/2403.09727
% [3]https://www.researchgate.net/publication/334116618_BLEU_is_Not_Suitable_for_the_Evaluation_of_Text_Simplification

Keterbatasan ini mendorong pergeseran paradigma menuju metrik evaluasi yang mampu 
menangkap kesamaan semantik. Pada penelitian ini, evaluasi yang akan dilakukan
dibatasi pada dua faktor yaitu kesamaan semantik dan kualitas relevansinya 
terhadap konteks dan kriteria tertentu. Untuk pendekatan kesamaan semantik, metrik berbasis 
\textit{embedding} kontekstual 
seperti BERTScore dan BARTScore menjadi pilihan utama \cite{zhang2020bertscore,yuan2021bartscore}. 
Lalu,
penilai (dikenal sebagai \textit{LLM-as-a-Judge}) dapat memberikan penilaian 
relevansinya terhadap kriteria tertentu untuk teks yang dihasilkan. 
Metrik berbasis \textit{embedding} seperti BERTScore dan BARTScore 
tidak lagi membandingkan kata secara literal, 
melainkan representasi vektornya yang kaya akan konteks, sehingga lebih selaras 
dengan penilaian kualitas oleh manusia \cite{zhang2020bertscore}. Di sisi lain, pendekatan 
\textit{LLM-as-a-Judge} memanfaatkan kemampuan pemahaman bahasa dari model 
canggih seperti GPT-4 untuk memberikan penilaian kualitatif yang bernuansa, 
meniru proses evaluasi oleh manusia pada skala yang lebih besar \cite{liuetal2023g}.

% reference:
% [1]https://www.researchgate.net/publication/332590189_BERTScore_Evaluating_Text_Generation_with_BERT
% [2]https://www.semanticscholar.org/paper/BARTScore%3A-Evaluating-Generated-Text-as-Text-Yuan-Neubig/a6a7724763d8adba466519489b0b9d209e7f2d15
% [3]https://arxiv.org/pdf/2405.05253v1
% [4]https://aclanthology.org/2023.emnlp-main.153.pdf

% Meskipun menjanjikan, pendekatan \textit{LLM-as-a-Judge} juga memiliki 
% serangkaian pertimbangan penting. Penelitian telah mengidentifikasi beberapa 
% bias inheren yang dapat memengaruhi objektivitasnya. LLM penilai cenderung 
% menunjukkan bias posisi, yaitu lebih menyukai respons yang disajikan pertama 
% kali dalam perbandingan berpasangan[1]. Selain itu, terdapat bias kebertele-telean 
% (\textit{verbosity bias}), ketika respons yang lebih panjang sering kali dinilai 
% lebih baik, serta bias peningkatan diri (\textit{self-enhancement bias}), yang 
% membuat model cenderung menyukai output dari model dalam keluarganya sendiri. 
% Bias-bias ini menggarisbawahi pentingnya desain \textit{prompt} yang cermat dan 
% validasi silang untuk memastikan keandalan penilaian.

Dalam paper ini \cite{zhang2020bertscore} Metrik ini bekerja dengan mengubah setiap token dalam kalimat 
kandidat dan referensi menjadi \textit{embedding} kontekstual menggunakan 
model BERT. Selanjutnya, kesamaan makna diukur dengan menghitung kemiripan 
kosinus (\textit{cosine similarity}) antara setiap pasang token, lalu secara 
serakah (\textit{greedy matching}) mencocokkan token dari satu kalimat ke 
token yang paling mirip di kalimat lainnya untuk menghasilkan skor presisi, 
\textit{recall}, dan F1. Keunggulan utamanya adalah kemampuannya untuk 
mengenali sinonim dan parafrasa, sehingga memberikan evaluasi yang lebih kuat 
terhadap kesetaraan makna dibandingkan metrik \textit{n-gram}.

% referensi:
% [1]https://www.researchgate.net/publication/332590189_BERTScore_Evaluating_Text_Generation_with_BERT

Sementara itu, BARTScore \cite{yuan2021bartscore} menawarkan filosofi yang berbeda secara fundamental 
dengan membingkai evaluasi sebagai "tugas generasi teks". Alih-alih hanya 
membandingkan \textit{embedding}, BARTScore menggunakan model seq2seq 
(sequence-to-sequence) untuk menghitung probabilitas sebuah teks 
dihasilkan dari teks lainnya. Misalnya, untuk mengukur presisi, 
ia akan menghitung seberapa mungkin model BART akan menghasilkan teks 
referensi jika diberi teks kandidat sebagai sumber. 
Skor yang lebih tinggi (\textit{log-probability} yang lebih mendekati nol) 
menandakan kualitas yang lebih baik. Fleksibilitas ini memungkinkan BARTScore 
untuk menilai berbagai aspek seperti kefasihan, koherensi, dan bahkan 
faktualitas hanya dengan mengubah input sumber dan targetnya.
% referensi:
% [1]https://www.semanticscholar.org/paper/BARTScore%3A-Evaluating-Generated-Text-as-Text-Yuan-Neubig/a6a7724763d8adba466519489b0b9d209e7f2d15

Untuk mengatasi subjektivitas dan bias dalam pendekatan \textit{LLM-as-a-Judge}, 
kerangka kerja terstruktur seperti G-Eval telah dikembangkan \cite{liuetal2023g}. 
G-Eval menggunakan 
LLM penilai (misalnya, GPT-4) tetapi memandunya dengan penalaran 
\textit{Chain-of-Thought} (CoT). Alih-alih hanya meminta skor akhir, 
G-Eval terlebih dahulu menginstruksikan LLM untuk 
menghasilkan langkah-langkah evaluasi berdasarkan kriteria yang diberikan pengguna, 
lalu mengikuti langkah-langkah tersebut untuk sampai pada sebuah skor. 
Pendekatan ini membuat proses penilaian lebih transparan, dapat dikontrol, 
dan terbukti mencapai korelasi yang lebih tinggi dengan penilaian manusia 
dibandingkan metode LLM-penilai yang tidak terstruktur. Pada penelitian 
\cite{koutcheme2024openfeedback},
dilakukan juga penilaian umpan balik kode pemrograman yang dihasilkan oleh 
model open-source. Seperti G-Eval, penilai LLM diminta untuk menilai
berdasarkan kriteria yang telah ditentukan. Sehingga dapat disimpulkan bahwa
pendekatan \textit{LLM-as-a-Judge} yang terstruktur dengan kriteria jelas
meningkatkan keandalan penilaian.
% referensi:
% [1]https://aclanthology.org/2023.emnlp-main.153.pdf
% [2]https://arxiv.org/pdf/2405.05253v1

\subsection{Evaluasi Ahli Manusia}
\label{subsection:tinjauan_evaluasi_kualitatif}

Untuk menilai kualitas umpan balik yang dihasilkan oleh LLM secara
komprehensif, evaluasi manusia yang terstruktur
menjadi standar emas, karena mampu menangkap
nuansa pedagogis dan psikologis yang terlewat oleh metrik otomatis.
Penilaian ini dapat dibingkai menggunakan rubrik yang didasarkan pada
prinsip-prinsip teoretis yang telah mapan. Mengacu pada Shute (2008) \cite{Shute2008FocusFormativeFeedback},
kriteria fundamental yang harus dinilai adalah apakah umpan balik LLM
bersifat jelas, akurat, dan relevan dengan konteks tugas yang diberikan.
Penilai manusia dapat secara langsung memverifikasi apakah instruksi yang
diberikan spesifik dan apakah informasi faktualnya benar.

Selanjutnya, dengan mengadopsi model dari Hattie dan Timperley (2007) \cite{HattieTimperley2007PowerOfFeedback},
penilai dapat mengevaluasi kelengkapan struktural umpan balik tersebut.
Rubrik penilaian akan memeriksa apakah LLM mampu menjawab tiga pertanyaan
kunci: (1) Feed Up: Apakah umpan balik mengklarifikasi tujuan akhir
(Where am I going?); (2) Feedback: Apakah ia memberikan analisis tentang
kinerja saat ini terhadap tujuan tersebut (How am I going?); dan (3)
Feed Forward: Apakah ia menawarkan saran yang konkret dan dapat
ditindaklanjuti untuk perbaikan (Where to next?).

Terakhir, dampak motivasional dari umpan balik, sebuah aspek yang
sulit diukur secara otomatis, dapat dinilai melalui lensa
Self-Determination Theory (Deci \& Ryan, 1985)\cite{DeciRyan1985IntrinsicMotivation} dan prinsip penguatan
positif (Fredrickson, 2001)\cite{Fredrickson2001BroadenBuild}. Penilai manusia akan mengevaluasi apakah
bahasa yang digunakan LLM mendukung otonomi (memberikan pilihan,
bukan mendikte), menumbuhkan rasa kompetensi (mengakui usaha dan kemajuan),
dan menggunakan nada yang apresiatif untuk meningkatkan self-efficacy.
Dengan demikian, evaluasi manusia yang berlandaskan teori ini tidak
hanya mengukur kebenaran teknis dari umpan balik, tetapi juga
efektivitasnya dalam memotivasi dan memberdayakan pengguna secara
konstruktif.

Secara keseluruhan, penilaian kualitas umpan balik LLM oleh ahli manusia
menggabungkan evaluasi objektif berdasarkan rubrik yang dikategorikan menjadi
tiga jenis yaitu penilaian secara \textit{feedback}, \textit{motivation support}, dan
\textit{appreciation support}. Setiap kategori dievaluasi menggunakan
skala Likert (1-5) untuk mengukur berbagai dimensi kualitas umpan balik
dari perspektif pedagogis dan psikologis. Dengan cara ini, evaluasi manusia
menyediakan gambaran yang kaya dan bernuansa tentang efektivitas umpan balik
LLM dalam konteks pendidikan.



% Sebaiknya gunakan beragam metrik agar aspek kualitas yang berbeda terukur. 
% Misalnya, metrik berbasis referensi (bandingkan keluaran LLM dengan ground-truth) 
% seperti BLEU/ROUGE mengukur kesamaan n-gram, tetapi kelemahannya signifikan: 
% BLEU/ROUGE tidak menangkap makna semantik dan sering tidak sensitif terhadap 
% sinonim ￼ ￼. Sebagai contoh, Kirim AI mencatat bahwa BLEU menganggap kata 
% “cepat” dan “lekas” berbeda meski maknanya sama ￼. Oleh karena itu BLEU/ROUGE 
% saja kurang cocok bila respons LLM sangat bervariasi secara leksikal. Sebaliknya 
% BERTScore dan BARTScore menggunakan embedding konteks untuk menilai kemiripan 
% semantik. BERTScore menghitung kemiripan kosinus antara embedding kalimat 
% referensi dan respons LLM ￼, sehingga skor tinggi menandakan tumpang tindih 
% semantik yang kuat. BARTScore (Yuan et al. 2021) bahkan memandang evaluasi 
% sebagai tugas generasi teks: model BART menaksir seberapa mudah mengonversi 
% teks model ke referensi (dan sebaliknya), sehingga keluaran yang lebih baik 
% memberi skor lebih tinggi ￼. Pendekatan ini bersifat unsupervised dan dapat 
% mengevaluasi kelancaran atau kebenaran informasi teks. Selain itu ada metrik 
% lain seperti MoverScore, BLEURT, atau chrF++ (untuk variasi morfologis) yang 
% juga menangkap kesamaan makna, meski umumnya BERTScore/BARTScore sudah mencakup 
% aspek semantik utama. Intinya, gunakan beberapa metrik referensi yang menilai 
% overlap leksikal (BLEU/ROUGE) dan semantik (BERTScore/BARTScore dsb) sesuai kebutuhan.


% Berbagai penelitian menunjukkan bahwa evaluasi kualitas umpan balik otomatis oleh LLM sering menggunakan metrik berbasis perbandingan dengan jawaban manusia (ground truth). Metrik tradisional seperti BLEU, ROUGE, METEOR, dan BERTScore banyak dipakai untuk mengukur kemiripan teks umpan balik LLM terhadap referensi manusia \textsuperscript{1, 4}. Contohnya, sebuah studi evaluasi umpan balik mahasiswa memanfaatkan BLEU, ROUGE-L, METEOR, dan BERTScore untuk menilai 6.426 entri umpan balik yang dihasilkan LLM (GPT-4o mini dan LLaMA 3.1) \textsuperscript{2}. Hasilnya menekankan pentingnya strategi prompting dan persona, dengan LLaMA unggul dalam aspek struktur kalimat dan GPT lebih baik pada kemiripan semantik \textsuperscript{2}. Meski efektif dalam kasus sederhana, metrik-metrik ini terutama menangkap tumpang tindih kata-kata atau informasi permukaan saja \textsuperscript{1, 3}, sehingga kurang memadai dalam menilai kedalaman, koherensi, dan kebermanfaatan pedagogis umpan balik di lingkungan pendidikan tinggi.

% Karena keterbatasan metrik berbasis n-gram, muncul pula metrik evaluasi berbasis model bahasa. Misalnya, BERTScore mengukur kemiripan semantik dengan membandingkan embedding BERT dari kalimat keluaran dan referensi \textsuperscript{1, 4}. Pendekatan seperti BERTScore, MoverScore, atau BLEURT menggunakan representasi kontekstual untuk menangkap makna yang lebih dalam dibanding BLEU atau ROUGE \textsuperscript{3}. Namun, penelitian terkini menunjukkan bahwa walau metrik berbasis embedding ini lebih sensitif terhadap makna, mereka pun sulit langsung diadopsi dalam konteks umpan balik pendidikan tanpa penyesuaian, karena aspek kelayakan dan konstruktivitas umpan balik kurang terukur \textsuperscript{3}. Misalnya, umpan balik edukatif idealnya tidak hanya benar secara semantik tapi juga memberikan rekomendasi jelas, konteks khusus, dan saran perbaikan bagi siswa \textsuperscript{7}. Oleh karena itu, literatur menyarankan pengembangan metrik evaluasi khusus domain atau menggunakan data penilaian manusia sebagai pegangan, daripada hanya mengandalkan metrik leksikal atau embedding saja \textsuperscript{3, 7}.

% Pendekatan evaluasi modern lainnya adalah LLM-as-a-judge, yaitu menggunakan LLM kuat untuk menilai keluaran LLM lain. Misalnya, penelitian oleh Koutscheme dkk. (2024) memanfaatkan GPT-4 sebagai penilai otomatis untuk mengevaluasi umpan balik kode pemrograman yang dihasilkan oleh model open-source. GPT-4-as-Judge ini dibandingkan dengan penilaian pakar manusia dan ternyata bersifat optimistis namun memiliki kesesuaian moderat dengan penilai manusia \textsuperscript{2}. Studi tersebut menemukan bahwa GPT-4 cenderung memberikan skor positif, namun masih mampu mengidentifikasi umpan balik berkualitas rendah dengan andal \textsuperscript{2}. Secara keseluruhan, beberapa model open-source (misalnya keluarga Zephyr dan Code Llama) terbukti menawarkan performa yang kompetitif dengan LLM komersial seperti ChatGPT ketika dievaluasi oleh GPT-4-as-Judge \textsuperscript{2}. Pendekatan ini memungkinkan skala evaluasi lebih besar sambil menggabungkan kedalaman penilaian kontekstual manusia. Luasnya penggunaan LLM-as-a-judge sebagai paradigma evaluasi dijelaskan pula dalam literatur, yang menekankan bahwa ide ini memadukan skalabilitas metrik otomatis dengan nalar kontekstual ala pakar \textsuperscript{3}.

% Perkembangan terbaru juga melihat penggunaan LLM open-source seperti LLaMA dalam pipeline evaluasi umpan balik pendidikan. Sebuah studi di Indonesia mengevaluasi umpan balik mahasiswa menggunakan GPT-4o mini dan LLaMA 3.1 dengan berbagai strategi prompting \textsuperscript{2}. Hasilnya, LLaMA 3.1 dinilai unggul dalam struktur kalimat umpan balik, sementara GPT memberikan kemiripan semantik lebih tinggi \textsuperscript{2}. Di ranah yang lebih praktis, riset Vision–Language dan LLM di Indonesia (kelas 4 SD) menggabungkan pengenalan tulisan tangan (OCR) dengan LLM untuk menilai jawaban siswa. Meski menekankan bahwa evaluasi umpan balik dilakukan secara manual, studi ini mencatat bahwa umpan balik berbahasa Indonesia yang dihasilkan model umumnya jelas dan faktual, namun kurang dipersonalisasi dan kurang membantu \textsuperscript{5}. Untuk skor otomatis, LLaMA-3.1 (70B parameter) juga digunakan sebagai salah satu model penilai skor, meski hasilnya kurang akurat dibanding GPT-4 (MAE lebih tinggi) \textsuperscript{5, 6}. Pendekatan pengujian ini menggunakan metrik kuantitatif seperti mean absolute error (MAE) untuk skor benar/salah tugas dan penilaian manual oleh ahli untuk kualitas umpan balik personalisasi \textsuperscript{6}. Data ini menunjukkan bahwa meski ada kemajuan, model open-source perlu penyesuaian lebih lanjut agar setara LLM komersial dalam konteks pendidikan.

% Selain metrik teks-berbasis kemiripan, beberapa penelitian mengevaluasi umpan balik LLM sebagai tugas pendeteksian. Dalam skenario pembuatan umpan balik terstruktur (misalnya kesalahan diagram ERD), digunakan metrik presisi, recall, dan skor-F1 untuk menilai seberapa tepat model menemukan kesalahan siswa \textsuperscript{7}. Dengan membandingkan true positive, false positive, dan seterusnya, peneliti melaporkan nilai presisi dan recall per kategori kesalahan (atribut, relasi, kardinalitas, dll) \textsuperscript{7}. Temuan menunjukkan LLM sering memiliki presisi tinggi (sedikit salah lapor kesalahan), namun recallnya lebih rendah (sering melewatkan beberapa kesalahan) \textsuperscript{7}. Pendekatan ini menyoroti bahwa metrik klasifikasi (precision/recall) berguna bila tugas evaluasi dipandang sebagai masalah deteksi elemen yang benar atau salah, bukan sekadar kesamaan teks.

% Secara keseluruhan, literatur terkini menekankan pentingnya kombinasi metrik otomatis dengan evaluasi LLM-as-judge atau evaluasi manusia. Metrik klasik seperti BLEU dan F1 tetap digunakan untuk membandingkan keluaran LLM dengan acuan, namun metodologi baru memanfaatkan model LLM kuat (GPT-4 atau open-source) sebagai evaluator skala besar. Misalnya, pipeline multi-model mengintegrasikan LLaMA dan GPT-4o untuk menghasilkan dan menilai umpan balik pendidikan \textsuperscript{2}. Di Indonesia, kemampuan evaluasi kualitas keluaran berbahasa lokal mulai dijajaki: baik melalui metrik semantic (BERTScore dengan model IndoBERT) maupun melalui penilaian manual berbasis rubrik pendidikan \textsuperscript{4, 5}. Perkembangan ini menunjukkan bahwa meski tantangan masih ada, terutama dalam memvalidasi kesesuaian pedagogis umpan balik, pendekatan otomatis yang canggih mulai mendekati hasil evaluasi ahli. Kajian-kajian tersebut menekankan bahwa penggabungan berbagai metrik (BLEU/BERTScore/METEOR) dan model penilai LLM merupakan jalur utama untuk evaluasi umpan balik yang lebih akurat dan kontekstual dalam pendidikan \textsuperscript{1, 2}.


% \bibitem{ref1} 
% \url{https://eprints2.undip.ac.id/39509/3/6.%20ABSTRAK.pdf#:~:text=dengan%20empat%20metrik%20otomatis%3A%20BLEU%2C,performa%20lebih%20tinggi%20dalam%20kemiripan}

% \bibitem{ref2} 
% \url{https://arxiv.org/html/2405.05253v1#:~:text=using%20a%20dataset%20from%20an,proprietary%20LLMs%2C%20such%20as%20ChatGPT}

% \bibitem{ref3} 
% \url{https://educationaldatamining.org/edm2025/proceedings/2025.EDM.short-papers.6/index.html#:~:text=Traditional%20evaluation%20methods%20for%20LLMs,9}

% \bibitem{ref4} 
% \url{https://digilib.uin-suka.ac.id/id/eprint/59064/1/21206052001_BAB-I_IV-atau-V_DAFTAR-PUSTAKA.pdf#:~:text=nilai%20hasil%20peringkasan%20dan%20hasil,Bahasa%2C%20IndoBERT%2C%20ROUGE%2C%20BLEU%2C%20BERTScore}

% \bibitem{ref5} 
% \url{https://openreview.net/pdf?id=yXeWp0c7U0#:~:text=087%20feedback%20quality,remain%20notable%20areas%20of%20concern}

% \bibitem{ref6} 
% \url{https://openreview.net/pdf?id=yXeWp0c7U0#:~:text=196%20using%20mean%20absolute%20error,202%205%20Result%20and%20Analysis}

% \bibitem{ref7} 
% \url{https://arxiv.org/html/2412.17892v1#:~:text=as%20a%20correct%20submission,in%20evaluating%20machine%20learning%20methods}

% \subsection{Metode Evaluasi Respons LLM dengan Ahli Pendidikan}

\section{Pertanyaan Penelitian}
Berdasarkan tujuan penelitian yang telah diuraikan dan metode evaluasi 
yang dipilih, serta mempertimbangkan sifat penelitian yang cenderung 
\textbf{eksploratif}, maka fokus utama penelitian ini dirumuskan 
ke dalam beberapa \textbf{pertanyaan penelitian} (\textit{Research Questions}/RQ) 
sebagai berikut:

\begin{enumerate}

    % RQ 1 (Pengganti Hipotesis 1)
    \item \textbf{(RQ 1)} Sejauh mana metode \textit{context 
    engineering} yang digabungkan dengan \textit{learning analytics} (LA) 
    dapat meningkatkan kualitas umpan balik LLM, jika dibandingkan 
    dengan metode \textit{Baseline}?

    % RQ 2 (Pengganti Hipotesis 2)
    \item \textbf{(RQ 2)} Bagaimana persepsi dan penilaian ahli manusia 
    terhadap kualitas, relevansi, dan kelayakan umpan balik yang 
    dihasilkan oleh metode \textit{context engineering} dengan LA?

    % RQ 3 (Pengganti Hipotesis 3)
    \item \textbf{(RQ 3)} Sejauh mana ukuran model bahasa (misalnya, 
    model kecil vs. model besar) memengaruhi kualitas umpan balik 
    yang dihasilkan dalam konteks penelitian ini?

\end{enumerate}



% Penelitian ini mengevaluasi kualitas umpan balik LLM berbahasa Indonesia terhadap konteks data pembelajaran
% (SRL) dan membandingkannya dengan umpan balik ahli manusia. Peningkatan kualitas diupayakan melalui
% perancangan \textit{prompt} serta integrasi \textit{learning analytics} (LA) yang menambah sinyal kontekstual.
% Evaluasi dilakukan secara kuantitatif dan kualitatif. Secara kuantitatif, kita mengukur keselarasan semantik
% dan cakupan rubrik menggunakan (i) BERTScore (kedekatan makna teks ahli vs LLM) dan (ii) LLM-as-a-judge
% (GPT-4) yang memberi label biner per-dimensi rubrik (F1--F5, M1--M5, A1--A5) dan dihitung metrik
% Precision/Recall/F1. Secara kualitatif, pakar manusia menilai kualitas umpan balik (skala Likert) pada dimensi
% yang sama. Selain itu, penelitian ini juga menelaah pengaruh ukuran model (kecil vs besar) terhadap kualitas
% umpan balik dan potensi interaksinya dengan intervensi \textit{prompt}+LA.

% Berdasarkan tujuan penelitian yang telah diuraikan dan metode evaluasi 
% kuantitatif (\textit{BERTScore, BARTScore, dan LLM-as-a-judge}) serta kualitatif 
% (Penilaian skala Likert oleh pakar) yang dipilih, maka hipotesis 
% penelitian ini dirumuskan sebagai berikut:

% \subsection*{Notasi Singkat}
% Misalkan:
% \begin{itemize}
%   \item $Q_{\text{BERT}}$: skor BERTScore (mis. F1) antara respons LLM dan respons ahli.
%   \item $Q_{\text{Judge}}$: skor dari LLM-as-a-judge (mis. macro-F1 atas 15 dimensi rubrik).
%   \item $Q_{\text{Human}}$: rata-rata skor Likert pakar (agregat atau per-dimensi).
%   \item Kondisi \textit{Baseline} (tanpa \textit{prompt}+LA) vs \textit{Intervensi} (\textit{prompt}+LA).
%   \item Ukuran model: \textit{Small} vs \textit{Large}.
% \end{itemize}

% \begin{enumerate}

%     % Hipotesis 1
%     \item \textbf{Hipotesis Efektivitas Metode (\textit{Context Engineering} dengan \textit{Learning Analytics})}
    
%     % Menggunakan \itemize atau \description untuk H0/H1
%     \begin{itemize}
%         \item\textbf{H0} : Tidak ada perbedaan kualitas antara metode \textit{context engineering} digabungkan dengan LA dan \textit{Baseline}.
%         \item\textbf{H1} : Ada perbedaan kualitas antara metode \textit{context engineering} digabungkan dengan LA dan \textit{Baseline}.
%     \end{itemize}

%     % Hipotesis 2
%     \item \textbf{Hipotesis Kualitas Metode (\textit{Context Engineering} dengan \textit{Learning Analytics}) Menurut Ahli Manusia}
    
%     \begin{itemize}
%         \item\textbf{H0} : Hasil evaluasi dari ahli manusia menunjukkan metode \textit{context engineering} digabungkan dengan LA tidak layak digunakan.
%         \item\textbf{H1} : Hasil evaluasi dari ahli manusia menunjukkan metode \textit{context engineering} digabungkan dengan LA layak digunakan.
%     \end{itemize}

%     % Hipotesis 3
%     \item \textbf{Hipotesis Pengaruh Ukuran Model}
    
%     \begin{itemize}
%         \item\textbf{H0} : Ukuran model tidak berpengaruh pada kualitas.
%         \item\textbf{H1} : Model Bahasa berukuran lebih besar menghasilkan kualitas lebih tinggi.
%     \end{itemize}

% \end{enumerate}

% \subsection{Hipotesis Efektivitas Metode(\textit{Context Engineering} dengan \textit{Learning Analytics})}
% \textbf{H0\textsubscript{1}}: Tidak ada perbedaan kualitas antara metode \textit{context engineering} digabungkan dengan LA dan \textit{Baseline}\\
% % \phantom{H0\textsubscript{1}:}\; (mis.\ $\mu^{\text{Interv}}_{Q_{\text{BERT}}} = \mu^{\text{Base}}_{Q_{\text{BERT}}}$ dan 
% % $\mu^{\text{Interv}}_{Q_{\text{Judge}}} = \mu^{\text{Base}}_{Q_{\text{Judge}}}$ serta 
% % $\mu^{\text{Interv}}_{Q_{\text{Human}}} = \mu^{\text{Base}}_{Q_{\text{Human}}}$).

% \textbf{H1\textsubscript{1}}: Ada perbedaan kualitas antara metode \textit{context engineering} digabungkan dengan LA dan \textit{Baseline}\\
% % \phantom{H1\textsubscript{1}:}\; (mis.\ $\mu^{\text{Interv}}_{Q_{\text{BERT}}} > \mu^{\text{Base}}_{Q_{\text{BERT}}}$,
% % $\mu^{\text{Interv}}_{Q_{\text{Judge}}} > \mu^{\text{Base}}_{Q_{\text{Judge}}}$,
% % dan $\mu^{\text{Interv}}_{Q_{\text{Human}}} > \mu^{\text{Base}}_{Q_{\text{Human}}}$).

% \subsection{Hipotesis Kualitas Metode (\textit{Context Engineering} dengan \textit{Learning Analytics}) Menurut Ahli Manusia}
% \textbf{H0\textsubscript{2}}: Hasil evaluasi dari ahli manusia menunjukkan metode \textit{context engineering} digabungkan dengan LA tidak layak digunakan\\
% % \phantom{H0\textsubscript{2}:}\; (mis.\ $\rho(Q_{\text{BERT}}, Q_{\text{Human}})=0$ dan 
% % $\rho(Q_{\text{Judge}}, Q_{\text{Human}})=0$).

% \textbf{H1\textsubscript{2}}: Hasil evaluasi dari ahli manusia menunjukkan metode \textit{context engineering} digabungkan dengan LA layak digunakan\\
% % \phantom{H1\textsubscript{2}:}\; (mis.\ $\rho(Q_{\text{BERT}}, Q_{\text{Human}}) > 0$ dan 
% % $\rho(Q_{\text{Judge}}, Q_{\text{Human}}) > 0$; uji Spearman/Kendall).

% \subsection{Hipotesis Pengaruh Ukuran Model}
% \textbf{H0\textsubscript{3}}: Ukuran model tidak berpengaruh pada kualitas\\
% % \phantom{H0\textsubscript{3}:}\; (mis.\ $\mu^{\text{Large}}_{Q_{\cdot}} = \mu^{\text{Small}}_{Q_{\cdot}}$ untuk semua metrik).

% \textbf{H1\textsubscript{3}}: Model Bahasa berukuran lebih besar menghasilkan kualitas lebih tinggi\\



% \phantom{H1\textsubscript{3}:}\; (mis.\ $\mu^{\text{Large}}_{Q_{\text{BERT}}} > \mu^{\text{Small}}_{Q_{\text{BERT}}}$,
% $\mu^{\text{Large}}_{Q_{\text{Judge}}} > \mu^{\text{Small}}_{Q_{\text{Judge}}}$,
% dan $\mu^{\text{Large}}_{Q_{\text{Human}}} > \mu^{\text{Small}}_{Q_{\text{Human}}}$).

% \subsection*{Hipotesis Interaksi (Opsional, Eksploratif)}
% \textbf{H0\textsubscript{4}}: Tidak ada interaksi antara Intervensi dan Ukuran Model.\\
% \textbf{H1\textsubscript{4}}: Ada interaksi; efek \textit{prompt}+LA berbeda tergantung ukuran model\\
% \phantom{H1\textsubscript{4}:}\; (mis.\ peningkatan akibat Intervensi lebih besar pada model kecil).


\section{Dasar Teori}

Bab ini menyajikan landasan konseptual dan kerangka 
teoretis yang menopang rancangan sistem, metodologi 
eksperimen, serta evaluasi penelitian. Pembahasan 
disusun secara sistematis mulai dari fondasi pedagogis 
hingga implementasi teknis dan metode pengujian.

Pertama, diuraikan \textbf{Tinjauan Teoretis Psikologi Pendidikan} 
yang menjadi standar acuan kualitas sistem, mencakup prinsip 
SRL dalam lingkungan berbasis Kanban , teori umpan 
balik formatif, serta kerangka motivasi 
\textit{Self-Determination Theory} (SDT)  dan psikologi positif. 
Kedua, dibahas karakteristik \textbf{Large Language Models (LLM)}
sebagai mesin utama agen cerdas, dengan fokus pada arsitektur 
model Llama dan implikasi teoritis perbedaan ukuran parameter 
(8B vs 70B) terhadap kapasitas penalaran model.
Ketiga, dijelaskan strategi \textbf{Rekayasa Konteks 
(\textit{Context Engineering})} dan \textit{Prompt Engineering} 
sebagai jembatan antara pedagogi dan teknologi, termasuk 
penerapan mekanisme \textit{ReAct (Reasoning + Acting)} 
untuk meningkatkan logika internal model. 
Keempat, dipaparkan pendekatan \textbf{Learning Analytics} (LA) 
tipe deskriptif yang digunakan untuk mentransformasi data 
mentah aktivitas Kanban menjadi wawasan kontekstual bagi 
LLM. Terakhir, bab ini menjelaskan metodologi 
\textbf{Evaluasi} yang menggabungkan metrik kesamaan 
semantik (\textit{BERTScore}, \textit{BARTScore}) dan 
pendekatan \textit{LLM-as-a-Judge} untuk mengukur kualitas 
respons secara objektif.

% buatkan saya text pengantar dasar teorinya.
% Bagian ini menyajikan landasan konseptual yang menopang rancangan dan metode penelitian. 
% Pertama, diringkas prinsip \textit{Self-Regulated Learning} (SRL)—termasuk peran umpan balik 
% dalam fase perencanaan, pelaksanaan, dan refleksi—serta kaitannya dengan tiga fungsi pedagogis 
% yang dinilai pada penelitian ini: \textit{feedback} kognitif, dukungan motivasional, 
% dan dukungan apresiatif. Kedua, diuraikan konsep \textit{prompt engineering} sebagai 
% praktik perumusan instruksi bagi LLM dan \textit{context engineering} sebagai pengelolaan 
% muatan informasi/konteks yang dipasok ke model; perbedaan keduanya serta implikasinya bagi 
% desain tutor-AI juga dibahas untuk menegaskan peran masing-masing. Ketiga, dipaparkan 
% \textit{learning analytics} (LA) yang mencakup definisi, ruang lingkup, dan jenis data proses (mis. 
% log LMS, urutan aktivitas, \textit{time-on-task}, perpindahan tugas, beban/WIP) beserta 
% cara ekstraksinya. Pada akhirnya, dijelaskan bagaimana sinyal-sinyal LA tersebut direkayasa 
% menjadi konteks \textit{prompt} agar LLM menghasilkan umpan balik yang lebih terstruktur, 
% \textit{actionable}, koheren, dan berempati, sekaligus menekankan kebutuhan evaluasi hibrida 
% (acuan pakar + metrik kuantitatif–kualitatif) untuk memastikan kualitas respons LLM mendekati 
% mutu pakar manusia. 
% Urutan pembahasan pada bagian ini mengikuti alur: 
% (i) \textit{Prompt Engineering}, 
% (ii) \textit{Context Engineering}, 
% (iii) perbedaan keduanya, 
% dan (iv) \textit{Learning Analytics}, 
% yang kemudian menjadi pijakan operasional pada bab metode. 

\subsection{Tinjauan Teoritis Psikologi Pendidikan}
Pada bagian ini dibahas teori-teori psikologi pendidikan yang
menjadi landasan konseptual bagi penelitian ini, meliputi
\textit{Self-Regulated Learning} (SRL), teori umpan balik formatif,
\textit{Self-Determination Theory} (SDT), dan \textit{Positive Psychology}.
Hal ini penting untuk memahami bagaimana umpan balik yang dihasilkan
oleh LLM dapat dirancang agar efektif mendukung proses belajar
mandiri mahasiswa. Selain itu, teori-teori ini memberikan kerangka
untuk mengevaluasi kualitas umpan balik dari perspektif pedagogis
yang akan dilakukan oleh ahli manusia pada bab evaluasi.

\subsubsection{\textit{Self-Regulated Learning} (SRL)}
\textit{Self-Regulated Learning} (SRL), atau Pembelajaran yang Diregulasi Diri, 
merujuk pada otonomi dan kontrol yang dilakukan oleh individu, 
yang secara aktif memantau, mengarahkan, dan meregulasi tindakan 
untuk mencapai tujuan seperti perolehan informasi, 
peningkatan keahlian, dan pengembangan diri \cite{ParisParis2001SRL}.
Dijelaskan juga oleh Zimmerman \cite{Zimmerman1990SRLOverview}
definisi dari SRL bahwa kondisi pelajar yang aktif baik secara metakognitif, 
motivasional, maupun perilaku dalam pembelajaran mereka.
Secara metakognitif, pelajar terampil dalam merencanakan, mengorganisasi, 
menginstruksi diri, memantau diri, dan mengevaluasi diri pada berbagai 
tahap proses belajar. Secara motivasional, pelajar memiliki pandangan diri 
sebagai individu yang otonom, kompeten, dan yakin terhadap kemampuan 
mereka untuk berprestasi. Sementara itu, dari sisi perilaku, pelajar 
mampu memilih, menyusun, dan menciptakan lingkungan yang dapat 
mengoptimalkan proses belajar \cite{Zimmerman1990SRLOverview}.

Untuk mencapai tujuan pembelajaran, SRL memiliki banyak 
model teoretis. Salah satu model yang paling banyak digunakan 
adalah model siklus tiga fase dari Zimmerman dan Moylan 
\cite{ZimmermanMoylan2009ModelSRL},
melalui siklus perencanaan (\textit{forethought}), 
pelaksanaan (\textit{performance}), dan 
refleksi (\textit{self-reflection}) yang saling 
terkait. Dalam fase \textit{forethought}, pelajar menganalisis tugas, 
menetapkan tujuan, dan merencanakan strategi untuk mencapai 
tujuan tersebut, yang didorong oleh keyakinan motivasional. 
Fase \textit{performance} melibatkan eksekusi tugas yang sebenarnya, 
di mana pelajar memantau kemajuan mereka dan menggunakan 
strategi kontrol diri untuk mempertahankan keterlibatan 
kognitif dan motivasi hingga tugas selesai. Terakhir, fase 
\textit{self-reflection} adalah saat pelajar menilai kinerja mereka 
dan membuat atribusi terhadap keberhasilan atau kegagalan 
(misalnya melalui penilaian diri formatif), yang kemudian 
menghasilkan reaksi diri yang akan memengaruhi bagaimana 
pelajar mendekati tugas serupa di masa mendatang.
Gambar \ref{fig:SRL-Zimmerman} mengilustrasikan model siklus tiga fase SRL ini.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{contents/chapter-2/SRL-Zimmerman.png}
    \caption{Model Siklus Tiga Fase \textit{Self-Regulated Learning} (SRL) 
    menurut Zimmerman dan Moylan \cite{ZimmermanMoylan2009ModelSRL}.}
    \label{fig:SRL-Zimmerman}
\end{figure}

% autonomy and control by the individual who monitors, 
% directs, and regulates actions towards goals of information 
% acquisition, expanding expertise and self-improvement
% kapasitas mahasiswa untuk secara aktif merencanakan, 
% memantau, dan mengevaluasi proses belajarnya sendiri. 
% Melalui siklus 
% perencanaan (\textit{forethought}), pelaksanaan (\textit{performance}), dan 
% refleksi (\textit{self-reflection}) yang saling 
% terkait [1], [2]. Pada fase perencanaan, 
% mahasiswa menetapkan tujuan serta strategi. Lalu, pada 
% fase pelaksanaan, mereka menerapkan strategi 
% kognitif dan melakukan pemantauan metakognitif seperti 
% manajemen waktu, monitoring pemahaman). 
% Kemudian, pada fase refleksi, mahasiswa melibatkan 
% penilaian diri terhadap kemajuan dan hasil untuk 
% menyesuaikan strategi berikutnya [1], [2]. Berbekal 
% mekanisme siklikal ini, SRL menggabungkan 
% dimensi kognitif, motivasional, dan perilaku yang 
% bersama-sama menentukan kualitas belajar 
% mandiri di pendidikan tinggi [1], [2].

Di konteks pendidikan tinggi, SRL berperan krusial 
karena lingkungan belajar menuntut kemandirian,
terutama pada pembelajaran digital (daring atau campuran) 
yang memerlukan disiplin diri lebih tinggi
serta kemampuan mengelola distraksi. Kajian terkini 
menunjukkan bahwa SRL berkorelasi dengan
kinerja akademik, keterlibatan, dan ketahanan studi. 
Sebaliknya, kekurangan SRL di
pembelajaran daring atau campuran dapat memperlebar 
kesenjangan capaian yang diperoleh 
mahasiswa \cite{Lobos2024NewChallenges}. 
Namun, tanpa bimbingan yang baik, 
mahasiswa sering kesulitan menafsirkan 
pemahaman mereka dalam melakukan 
pemikiran reflektif tersebut \cite{Lobos2024NewChallenges}.
Dengan demikian,
pengembangan kompetensi SRL termasuk penetapan tujuan, strategi, monitoring, dan
refleksi—menjadi prasyarat penting untuk keberhasilan 
mahasiswa di ekosistem belajar
modern \cite{Lobos2024NewChallenges}.

\subsubsection{Teori Umpan Balik}
Dalam konteks pendidikan, umpan balik 
didefinisikan sebagai informasi yang 
dikomunikasikan kepada pelajar dengan 
niat untuk memodifikasi pemikiran atau 
perilaku guna meningkatkan pembelajaran. 
Hattie dan Timperley memandang umpan balik 
sebagai konsekuensi dari kinerja yang 
disediakan oleh agen seperti guru atau 
teman sebaya yang bertujuan untuk mengurangi 
kesenjangan antara pemahaman saat ini dan 
tujuan yang diinginkan \cite{HattieTimperley2007PowerOfFeedback}. 
Shute \cite{Shute2008FocusFormativeFeedback} memperluas 
perspektif ini dengan menekankan bahwa umpan 
balik formatif harus bersifat non evaluatif 
suportif tepat waktu dan spesifik agar efektif. 
Secara kognitif umpan balik berfungsi untuk 
mengurangi ketidakpastian mengenai seberapa baik 
kinerja mahasiswa dan mengurangi beban kognitif atau 
\textit{cognitive load} terutama bagi mahasiswa 
baru atau yang mengalami kesulitan belajar.

Efektivitas umpan balik dalam menutup kesenjangan 
pembelajaran bergantung pada kemampuannya 
menjawab tiga pertanyaan fundamental. Pertanyaan 
pertama adalah "\textbf{Ke mana saya akan pergi}" yang 
berkaitan dengan penetapan tujuan yang jelas 
dan menantang. Pertanyaan kedua adalah "\textbf{Bagaimana 
saya menjalaninya}" yang memberikan informasi 
mengenai kemajuan siswa relatif terhadap tujuan 
tersebut. Pertanyaan ketiga adalah "\textbf{Langkah 
selanjutnya}" yang mengarahkan siswa pada aktivitas 
lanjutan untuk memperdalam pemahaman \cite{HattieTimperley2007PowerOfFeedback}. 
Shute menambahkan bahwa umpan balik yang efektif dapat 
memfasilitasi pergeseran orientasi tujuan siswa 
dari orientasi kinerja menjadi orientasi 
\textit{learning orientation} yang 
mendorong kegigihan dan penguasaan keterampilan \cite{Shute2008FocusFormativeFeedback}.

Hattie dan Timperley mengategorikan fokus umpan 
balik ke dalam empat tingkatan utama. Tingkat 
tugas atau \textit{Task Level} berfokus pada kebenaran 
faktual dari kinerja dan sering disebut sebagai 
umpan balik korektif. Tingkat proses atau \textit{Process 
Level} menyasar strategi kognitif yang mendasari 
penyelesaian tugas. Tingkat regulasi diri atau 
\textit{Self Regulation Level} mendukung otonomi dan 
pemantauan diri siswa. Tingkat diri atau \textit{Self Level} 
yang berupa pujian pribadi dinilai paling tidak 
efektif karena mengalihkan perhatian dari tugas \cite{HattieTimperley2007PowerOfFeedback}. 
Shute  \cite{Shute2008FocusFormativeFeedback} mendukung pandangan ini dengan temuan bahwa 
umpan balik yang bersifat spesifik atau terelaborasi 
(\textit{elaborated feedback}) umumnya lebih efektif daripada 
umpan balik yang hanya berupa verifikasi benar atau 
salah terutama untuk pembelajaran mendalam. Namun 
kompleksitas umpan balik harus dikelola agar tidak 
membebani siswa dengan informasi yang berlebihan.


% Dalam konteks pendidikan, Hattie dan Timperley 
% \cite{HattieTimperley2007PowerOfFeedback} 
% mengonseptualisasikan umpan balik sebagai informasi 
% yang disediakan oleh agen mengenai aspek kinerja 
% atau pemahaman seseorang. Agen pemberi informasi 
% tersebut dapat meliputi guru teman sebaya buku orang 
% tua atau pengalaman diri sendiri. Umpan balik dipandang 
% sebagai konsekuensi dari kinerja. Tujuan utama dari 
% pemberian umpan balik adalah untuk mengurangi kesenjangan 
% atau diskrepanasi antara pemahaman maupun kinerja saat ini 
% dengan tujuan pembelajaran yang diinginkan. Proses pengurangan 
% kesenjangan ini dapat ditempuh melalui peningkatan usaha 
% siswa, penggunaan strategi yang lebih efektif, atau 
% penyesuaian tujuan pembelajaran oleh guru agar lebih 
% spesifik dan menantang.

% Efektivitas umpan balik dalam rangka meningkatkan pembelajaran 
% sangat bergantung pada kemampuannya untuk menjawab tiga 
% pertanyaan mendasar yang saling berkaitan. Pertanyaan 
% pertama adalah "Ke mana saya akan pergi" atau 
% "\textit{Where am I going}" yang berkaitan dengan
% penetapan tujuan atau \textit{feed up}. 
% Pertanyaan ini menekankan pentingnya kejelasan tujuan 
% bagi mahasiswa agar umpan balik dapat terarah. Pertanyaan 
% kedua adalah "Bagaimana saya menjalaninya" atau 
% "\textit{How am I going}" yang disebut sebagai 
% \textit{feed back}. Dimensi ini 
% memberikan informasi mengenai kemajuan mahasiswa relatif 
% terhadap tujuan awal atau kinerja sebelumnya. Pertanyaan 
% ketiga adalah "Langkah selanjutnya" atau "\textit{Where to next}" 
% yang dikenal sebagai \textit{feed forward}. Pertanyaan ini 
% mengarahkan mahasiswa pada aktivitas lanjutan yang dapat 
% memperdalam pemahaman dan meningkatkan regulasi diri.

% Diajukan model yang membedakan fokus 
% umpan balik ke dalam empat tingkatan yang berbeda yang 
% masing masing memiliki dampak berbeda terhadap pembelajaran.
% Pertama adalah umpan balik tingkat tugas atau \textit{Task Level} 
% yang berfokus pada seberapa baik tugas dipahami atau 
% dilakukan. Jenis ini sering disebut sebagai umpan balik 
% korektif yang membedakan jawaban benar dan salah serta memberikan 
% informasi faktual.
% Kedua adalah umpan balik tingkat proses atau \textit{Process Level} yang 
% menyasar proses utama yang diperlukan untuk memahami atau 
% menyelesaikan tugas. Umpan balik pada tingkat ini lebih efektif 
% untuk pembelajaran mendalam karena membantu siswa membangun 
% hubungan antar ide dan strategi kognitif.

% Ketiga adalah umpan balik tingkat regulasi diri atau 
% \textit{Self-Regulation Level} yang berfokus pada pemantauan 
% pengarahan dan pengaturan tindakan oleh diri sendiri. 
% Tingkat ini melibatkan aspek otonomi disiplin diri dan 
% efikasi diri yang memungkinkan siswa untuk mengevaluasi 
% kinerja mereka sendiri dan mencari umpan balik lebih 
% lanjut secara mandiri.

% \textit{Self Level} yang memberikan evaluasi pribadi dan 
% afeksi positif terhadap siswa sebagai individu. Contoh 
% dari tingkat ini adalah pujian umum yang sering kali 
% tidak memuat informasi spesifik mengenai tugas atau 
% pembelajaran.

% Analisis literatur menunjukkan bahwa efektivitas 
% umpan balik sangat dipengaruhi oleh tingkatan fokusnya. 
% Umpan balik tingkat proses dan regulasi diri dinilai 
% paling efektif dalam meningkatkan penguasaan tugas 
% dan pemahaman mendalam. Umpan balik tingkat tugas 
% tergolong efektif jika digunakan untuk memperbaiki 
% interpretasi yang keliru namun bisa menjadi kurang 
% efektif jika terlalu berfokus pada detail yang tidak 
% mendukung pengembangan strategi. Sebaliknya umpan 
% balik tingkat diri atau Self Level merupakan bentuk 
% yang paling tidak efektif karena sering kali 
% mengalihkan perhatian siswa dari tugas dan tidak 
% memberikan informasi yang dapat digunakan untuk menutup 
% kesenjangan pembelajaran. Oleh karena itu guru 
% disarankan untuk meminimalkan umpan balik yang hanya 
% bersifat evaluasi diri dan lebih fokus pada proses 
% serta regulasi diri untuk memaksimalkan hasil belajar 
% siswa.




\subsubsection{\textit{Self-Determination Theory} (SDT)}
Teori Determinasi Diri atau \textit{Self Determination Theory} 
dijelaskan sebagai pendekatan organismik terhadap motivasi yang 
\textbf{memandang manusia sebagai makhluk aktif dengan kecenderungan 
alamiah menuju pertumbuhan psikologis serta integrasi diri} 
\cite{DeciRyan1985IntrinsicMotivation}. 
Perspektif ini menekankan pentingnya pemenuhan \textbf{tiga kebutuhan 
psikologis dasar yang bersifat bawaan: kebutuhan akan kompetensi, 
kebutuhan akan otonomi (determinasi diri), dan kebutuhan akan 
keterhubungan interpersonal}. Kebutuhan akan kompetensi berkaitan dengan 
keinginan individu untuk merasa efektif dalam berinteraksi dengan lingkungan 
sedangkan kebutuhan akan determinasi diri mengacu pada keinginan individu 
untuk menjadi sumber kausalitas dari perilakunya sendiri tanpa paksaan dari 
kekuatan luar \cite{DeciRyan1985IntrinsicMotivation}.

Dalam kerangka teori ini, motivasi intrinsik didefinisikan 
sebagai energi yang didasarkan pada kebutuhan bawaan untuk 
merasa kompeten dan menentukan nasib sendiri yang mendorong 
individu mencari tantangan optimal demi kepuasan yang melekat 
pada aktivitas itu sendiri \cite{DeciRyan1985IntrinsicMotivation}. 
Melalui subteori yang disebut Teori Evaluasi Kognitif (\textit{Cognitive Evaluation Theory:}) 
dijelaskan bahwa peristiwa eksternal seperti imbalan atau umpan balik 
\textbf{mempengaruhi motivasi intrinsik berdasarkan makna fungsionalnya bagi penerima,
apakah bersifat informasional yang mendukung kompetensi, atau bersifat mengontrol 
yang membatasi otonomi}. Peristiwa yang memfasilitasi persepsi lokus kausalitas 
internal akan meningkatkan motivasi intrinsik sedangkan peristiwa yang 
dipersepsikan mengontrol perilaku akan menggeser lokus kausalitas menjadi 
eksternal dan menurunkan motivasi intrinsik.

Teori ini juga dijelaskan motivasi ekstrinsik melalui Teori 
Integrasi Organismik (\textit{Organismic Integration Theory}) 
yang menggambarkan proses internalisasi regulasi eksternal ke dalam struktur 
diri individu \cite{DeciRyan1985IntrinsicMotivation}. Proses internalisasi ini 
berlangsung dalam sebuah rangkaian mulai dari regulasi eksternal yang sepenuhnya 
dikendalikan oleh kontingensi luar menuju introjeksi identifikasi dan akhirnya 
integrasi di mana nilai eksternal berasimilasi sepenuhnya dengan diri sendiri. 
\textbf{Semakin terintegrasi suatu regulasi eksternal maka perilaku tersebut menjadi 
semakin otonom (self-determined) dan pada akhirnya berkontribusi pada kesehatan 
psikologis serta kualitas kinerja yang lebih baik dibandingkan regulasi yang 
hanya bersifat patuh atau terkontrol.}
% Teori Determinasi Diri atau \textit{Self Determination Theory} \cite{DeciRyan1985IntrinsicMotivation} 
% merupakan pendekatan organismik terhadap motivasi manusia 
% dan kepribadian yang dikembangkan oleh Edward L. Deci dan 
% Richard M. Ryan. Teori ini dibangun di atas asumsi fundamental 
% bahwa manusia adalah organisme yang aktif dan memiliki 
% kecenderungan alamiah menuju pertumbuhan psikologis serta 
% integrasi diri. Dalam perspektif ini manusia tidak dipandang 
% sebagai makhluk pasif yang hanya bereaksi terhadap dorongan 
% fisiologis atau stimulus lingkungan semata melainkan sebagai 
% individu yang secara proaktif terlibat dengan lingkungannya 
% untuk menguasai tantangan dan mengintegrasikan pengalaman 
% baru ke dalam kesatuan diri yang koheren. Energi yang 
% mendasari aktivitas proaktif ini disebut sebagai motivasi 
% intrinsik yang berbeda secara fundamental dari motivasi 
% yang didasarkan pada dorongan fisiologis atau kontrol 
% lingkungan.

% Inti dari \textit{Self-Determination Theory} adalah postulat 
% mengenai keberadaan kebutuhan psikologis dasar yang 
% bersifat bawaan dan universal. Pemenuhan kebutuhan 
% ini dipandang esensial bagi kesehatan psikologis 
% integritas diri dan pertumbuhan yang optimal. Teori 
% ini mengidentifikasi kebutuhan akan kompetensi dan 
% kebutuhan akan determinasi diri sebagai dua elemen 
% motivasional utama. Kebutuhan akan kompetensi mengacu 
% pada keinginan individu untuk merasa efektif dalam 
% berinteraksi dengan lingkungannya dan untuk melatih serta 
% memperluas kapasitas dirinya. Sementara itu kebutuhan 
% akan determinasi diri atau otonomi berkaitan dengan 
% keinginan individu untuk menjadi asal mula atau sumber 
% kausalitas dari perilakunya sendiri. Ketika perilaku 
% dialami sebagai pilihan yang berasal dari diri sendiri 
% maka individu tersebut sedang berfungsi dengan determinasi 
% diri. Sebaliknya jika perilaku dirasakan sebagai akibat dari 
% tekanan atau paksaan maka individu tersebut kehilangan 
% rasa determinasi diri.



\subsubsection{\textit{Positive Psychology} (Appreciation)}
Psikologi positif memiliki misi fundamental untuk 
memahami serta membina faktor faktor yang memungkinkan 
individu komunitas dan masyarakat untuk berkembang atau 
\textit{flourish} secara optimal \cite{Fredrickson2001BroadenBuild}. 
Dalam perspektif ini emosi positif 
tidak sekadar dipandang sebagai penanda kesejahteraan 
subjektif semata melainkan juga berperan aktif dalam 
menghasilkan pertumbuhan psikologis yang berkelanjutan. 
Berbeda dengan \textbf{pendekatan tradisional yang seringkali berfokus 
pada emosi negatif} pendekatan ini menekankan bahwa \textbf{emosi 
positif} seperti kegembiraan ketertarikan kepuasan dan cinta 
memiliki nilai adaptif yang krusial karena emosi tersebut 
\textbf{berfungsi sebagai sarana untuk mencapai pertumbuhan psikologis} 
dan meningkatkan \textbf{kesejahteraan individu}, dalam hal ini mahasiswa, 
dalam jangka panjang \cite{Fredrickson2001BroadenBuild}.

Kerangka teoritis utama yang menjelaskan mekanisme fungsi 
emosi positif ini disebut sebagai \textbf{\textit{broaden and build theory}} 
yang mempostulatkan bahwa pengalaman emosi positif memperluas 
atau \textbf{\textit{broaden repertoar}} pemikiran dan tindakan sesaat individu.
\cite{Fredrickson2001BroadenBuild} 
Mekanisme perluasan ini berbeda secara signifikan dari emosi 
negatif yang cenderung menyempitkan fokus pikiran dan tindakan 
pada perilaku spesifik untuk kelangsungan hidup segera dalam 
situasi mengancam. Sebaliknya emosi positif memperluas cakupan 
kognisi dan perhatian yang memungkinkan munculnya fleksibilitas 
kognitif kreativitas serta keinginan untuk mengeksplorasi dan 
mengintegrasikan informasi baru yang pada akhirnya memperkaya 
repertoar pemikiran dan tindakan individu pada saat tersebut.

Konsekuensi kumulatif dari perluasan pola pikir tersebut adalah 
terbangunnya atau \textit{build} berbagai sumber daya personal yang 
bersifat tahan lama atau \textit{enduring personal resources} yang 
mencakup sumber daya fisik intelektual sosial dan psikologis. 
Sumber daya yang terakumulasi ini berfungsi sebagai cadangan 
berharga yang dapat dimanfaatkan kembali di masa depan untuk 
mengelola ancaman serta memfasilitasi ketahanan psikologis atau 
resiliensi melalui efek pemulihan atau \textit{undoing effect} terhadap 
dampak fisiologis emosi negatif. Dengan demikian kapasitas untuk 
mengalami emosi positif merupakan kekuatan fundamental yang dapat 
memicu spiral ke atas atau \textit{upward spirals} menuju peningkatan 
kesejahteraan emosional dan transformasi diri yang 
lebih baik \cite{Fredrickson2001BroadenBuild}.

\subsection{\textit{Large Language Models} (LLM)}
Pada bagian ini dibahas konsep dasar mengenai 
\textit{Large Language Models} (LLM) yang menjadi
komponen inti dari \textit{Feedback Agent}. Pembahasan 
mencakup arsitektur LLM, karakteristik model Llama, 
serta implikasi perbedaan ukuran model (8B vs 70B)
terhadap kapasitas penalaran dan performa dalam
menghasilkan umpan balik berkualitas tinggi.

\subsubsection{Dasar Teori LLM}
\textit{Kecerdasan Buatan} adalah cabang ilmu komputer yang berfokus 
pada pembuatan sistem yang mampu meniru kecerdasan manusia dalam 
pemecahan masalah dan pengambilan keputusan. Pendekatan awal AI banyak 
bersifat \textit{symbolic} (\textit{rule-based}), namun berkembang 
menuju metode \textit{data-driven} seperti \textit{machine learning}. 
Sejak awal, para peneliti AI telah membayangkan tercapainya 
\textit{general problem solver} yang mampu menyelesaikan berbagai 
tugas secara cerdas [1]. Kemajuan mutakhir di bidang 
\textit{natural language processing} menunjukkan tanda-tanda menuju 
visi tersebut, contohnya model bahasa besar (\textit{large language model}) 
seperti \textit{ChatGPT} yang dilatih dengan miliaran parameter pada 
seluruh teks internet mampu melakukan beragam tugas tekstual secara 
\textit{out-of-the-box} dan menunjukkan kemampuan \textit{emergent} 
mendekati kecerdasan umum manusia [1]. Perkembangan ini menandai lompatan 
signifikan dalam upaya mewujudkan AI yang lebih cerdas dan serbaguna.

\textit{Large Language Models} (LLM) merepresentasikan terobosan signifikan dalam ranah 
Pemrosesan Bahasa Alami (\textit{Natural Language Processing} atau NLP). Teknologi ini 
mendayagunakan jaringan saraf tiruan dengan miliaran parameter untuk mengidentifikasi 
pola bahasa dan memproduksi teks yang kualitasnya setara dengan komunikasi manusia. 
Melalui pelatihan pada himpunan data berskala masif dengan metode \textit{self-supervised learning}, 
LLM mampu melaksanakan berbagai tugas NLP yang kompleks, meliputi pembangkitan teks, 
penerjemahan, peringkasan, sistem tanya-jawab, hingga analisis sentimen. Kehadiran 
teknologi ini telah mengubah lanskap NLP secara mendasar dengan mengatasi keterbatasan 
metode konvensional berbasis aturan dan statistik, seperti \textit{n-grams}, yang 
sebelumnya kurang efektif dalam menangkap ketergantungan jangka panjang maupun nuansa 
kontekstual dalam teks \cite{Sindhu2024Evolution}.

Sejarah perkembangan LLM dicirikan oleh kemajuan bertahap dalam arsitektur jaringan 
saraf. Fase awal dimulai dengan penggunaan \textit{Recurrent Neural Networks} (RNNs) 
di mana digunakan untuk pengolahan data sekuensial, meskipun model ini sering terkendala oleh isu 
\textit{vanishing gradients} yang menghambat proses pembelajaran jangka panjang. 
Kemajuan berikutnya dicapai melalui penerapan \textit{word embeddings} dan representasi 
vektor yang meningkatkan pemahaman semantik dengan memetakan relasi kata dalam ruang 
berdimensi tinggi. Namun, lompatan teknologi terbesar terjadi melalui introduksi 
arsitektur \textit{transformer} yang menerapkan mekanisme \textit{self-attention}. 
Mekanisme ini memungkinkan model untuk memahami hubungan kontekstual secara jauh lebih 
akurat, sekaligus menjadi landasan bagi pengembangan model-model canggih kontemporer 
seperti GPT dan BERT.

Penggunaan LLM telah meluas ke berbagai sektor industri, termasuk di antaranya 
di bidang pendidikan \cite{jacobsen2025promises, li2025designaipoweredtoolselfregulation}. Dalam konteks pendidikan, LLM dimanfaatkan untuk
menghasilkan materi pembelajaran yang dipersonalisasi, memberikan umpan balik
otomatis kepada siswa, serta mendukung sistem tanya jawab interaktif \cite{woodrow2025dpo_feedback, jacobsen2025promises, li2025designaipoweredtoolselfregulation}.


\subsubsection{Llama}
Llama (Large Language Model Meta AI) adalah keluarga model 
bahasa besar yang dikembangkan oleh Meta AI dengan tujuan 
mendorong adopsi luas AI melalui pendekatan terbuka. Meta 
merilis Llama sebagai model open-source \cite{zuckerberg2024opensource}. 
CEO Meta, Mark Zuckerberg, menyatakan bahwa Llama 3 (termasuk varian 
8B, 70B, dan 405B) menawarkan rasio biaya/kinerja yang lebih 
baik dibanding model komersial tertutup (misalnya GPT-4), 
serta mendukung fine-tuning yang luas karena keterbukaannya \cite{zuckerberg2024opensource}. 
Dengan prinsip tersebut, arsitektur Llama dirancang untuk 
efisiensi dan fleksibilitas tinggi. Pengembangan Llama 3.1 
menghadirkan peningkatan signifikan pada arsitektur foundation 
model dengan peluncuran varian \textit{flagship} berkapasitas 405 
miliar parameter yang menggunakan arsitektur \textit{dense 
Transformer} dan mendukung context window hingga 128.000 
token. Berbeda dengan iterasi sebelumnya, model ini dirancang 
dengan dukungan bawaan (native support) untuk kemampuan 
multibahasa, pemrograman (coding), penalaran (reasoning), 
serta penggunaan alat atau tool usage. Meta merilis model 
ini secara terbuka dalam versi pre-trained dan post-trained, 
serta melengkapinya dengan Llama Guard 3 untuk menjaga 
keamanan input dan output. Dalam hal kapabilitas multimodal, 
dokumen teknis memaparkan eksperimen integrasi gambar, video, 
dan suara melalui pendekatan komposisional, meskipun model 
multimodal spesifik ini masih dalam tahap pengembangan aktif 
dan belum dirilis secara luas. Berdasarkan evaluasi empiris, 
performa model Llama 3 405B terbukti kompetitif dan sebanding 
dengan model proprietary terkemuka seperti GPT-4 pada berbagai 
tolok ukur pengujian \cite{dubey2024llama}.

Llama 3.1 8B dan Llama 3.3 70B merupakan dua ujung spektrum di mana 
8B menonjol pada efisiensi dan kemudahan implementasi 
(misalnya aplikasi \textit{mobile} atau \textit{startup} edukasi dengan 
sumber daya terbatas), sedangkan 70B menawarkan kinerja 
unggul pada tugas kompleks dan domain penelitian yang 
menuntut kualitas tinggi. Pemilihan model sebaiknya 
mempertimbangkan kebutuhan aplikasi seperti model 70B ideal untuk 
sistem pembangkitan teks yang memerlukan akurasi tinggi 
(misalnya umpan balik pembelajaran mendalam), sedangkan 
8B cukup untuk tugas-tugas standar dengan latensi dan 
biaya lebih rendah.
\cite{meta2024llama31}


% \subsection{\textit{Prompt Engineering} dan \textit{Context Engineering}}

\subsection{\textit{Prompt Engineering}}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{contents/chapter-2/Diagram_Prompt_Engineering.png}
    \caption{Ilustrasi konsep \textit{Prompt Engineering} sebagai mekanisme pengendali 
    (\textit{steering mechanism}) untuk mengarahkan keluaran LLM \cite{Lee2025}.}
    \label{fig:prompt-engineering}
\end{figure}

\textit{Prompt engineering} merupakan bidang kajian 
baru yang berfokus pada perancangan, penyempurnaan, 
dan implementasi prompt atau instruksi yang diberikan 
kepada model bahasa besar LLM 
untuk mengarahkan keluaran model tersebut \cite{Mesko2023}. Dengan 
kata lain, \textit{prompt engineering} 
adalah “mekanisme pengendali” (\textit{steering mechanism}) 
yang digunakan pengguna kecerdasan buatan 
generatif untuk menyusun \textit{prompt} sedemikian rupa agar 
menghasilkan keluaran yang diinginkan \cite{Lee2025}. 
Konsep ini menjadi semakin penting seiring munculnya LLM 
populer seperti ChatGPT, karena 
kemampuan merancang \textit{prompt} yang efektif memungkinkan 
pengguna untuk mendapatkan jawaban yang 
lebih akurat, relevan, dan sesuai kebutuhan dari model AI \cite{Mesko2023}.

Sebagai suatu keterampilan, \textit{prompt engineering} dapat 
dipelajari dan dikembangkan. 
Para peneliti menuliskan bahwa \textit{prompt engineering} sudah 
mulai diajarkan secara formal, 
misalnya di perguruan tinggi, karena dianggap sebagai 
\textit{skillset} baru yang 
dibutuhkan di era integrasi AI \cite{Lee2025}. Intinya, 
\textit{prompt engineering} 
menekankan seni merumuskan pertanyaan atau perintah 
dalam bahasa natural 
sedemikian rupa sehingga model AI memahami konteks 
tugas dan memberikan respon optimal sesuai 
Pendekatan ini mencakup berbagai strategi, mulai 
dari teknik dasar seperti \textit{Zero-shot} dan \textit{Few-shot} 
\textit{prompting} hingga metode yang lebih maju seperti \textit{Chain-of-Thought}.
Berikut adalah jenis-jenis \textit{prompt engineering}
yang digunakan pada penelitian ini.

\subsubsection{\textit{Few-Shot Prompting}}
\textit{Few-Shot Prompting} (atau \textit{in-context learning}) adalah pendekatan di mana model bahasa diberikan beberapa demonstrasi tugas pada saat inferensi sebagai kondisi, tanpa pembaruan bobot atau \textit{fine-tuning} \cite{Brown2020}. Pendekatan ini memanfaatkan kemampuan yang diperoleh selama pra-pelatihan (\textit{pre-training}) untuk mengenali pola dan beradaptasi dengan tugas baru hanya berdasarkan sejumlah kecil contoh yang disertakan dalam konteks \cite{Brown2020}. Mekanisme utama metode ini adalah menyajikan $K$ contoh masukan-luaran yang diinginkan (jumlah contoh bergantung pada jendela konteks model), lalu diikuti oleh masukan target yang diharapkan dilengkapi oleh model \cite{Brown2020}.

Secara umum, penerapan \textit{Few-Shot Prompting} memiliki karakteristik sebagai berikut:
\begin{enumerate}
    \item Mekanisme \textit{in-context learning}. Model tidak melakukan pembelajaran gradien (\textit{gradient updates}); melainkan memproses instruksi dan contoh-contoh demonstrasi yang diberikan dalam prompt sebagai satu kesatuan sekuens untuk memprediksi keluaran berikutnya. Hal ini mirip dengan bagaimana manusia dapat mempelajari tugas baru hanya dengan melihat beberapa contoh \cite{Brown2020}.
    \item Struktur prompt. Prompt biasanya terdiri dari deskripsi tugas (opsional), diikuti oleh beberapa pasangan contoh (Input $\rightarrow$ Output), dan diakhiri dengan input target yang ingin dijawab.
\end{enumerate}

\subsubsection{\textit{Role-Play}}
\textit{Role-Play Prompting} adalah pendekatan 
konseptual untuk memahami dan mengarahkan perilaku 
agen dialog berbasis \textit{Large Language Models} 
(LLM). Dalam kerangka kerja ini, perilaku agen tidak 
dilihat sebagai ekspresi dari kesadaran atau niat asli 
model, melainkan sebagai hasil dari ``bermain peran'' 
(\textit{role play}) karakter tertentu yang dideskripsikan 
dalam \textit{prompt}.

Konsep ini menekankan bahwa LLM pada dasarnya adalah 
prediktor teks yang memprediksi kelanjutan paling 
masuk akal berdasarkan distribusi data pelatihan. 
Ketika diberikan \textit{prompt} dialog yang 
mendeskripsikan karakter tertentu, model akan 
menghasilkan respons yang sesuai dengan ekspektasi 
karakter tersebut, seolah-olah sedang melakukan 
improvisasi teater.


\subsubsection{\textit{Chain-of-Thought}}
\textit{Chain-of-Thought} (CoT) adalah metode \textit{prompting} sederhana 
yang dirancang untuk memunculkan kemampuan penalaran 
kompleks pada \textit{Large Language Models} (LLM). Metode ini 
bekerja dengan memberikan serangkaian \textit{intermediate reasoning steps} 
dalam bahasa alami yang menuntun model menuju jawaban akhir.

Secara prinsip, CoT meniru proses berpikir manusia saat 
memecahkan masalah yang rumit, yaitu dengan memecah masalah 
besar menjadi langkah-langkah kecil yang logis sebelum 
memberikan kesimpulan.

Metode ini biasanya diterapkan dalam format \textit{few-shot prompting}, 
di mana pengguna memberikan beberapa contoh soal (\textit{exemplars}) 
yang terdiri dari tiga komponen: \textit{Input} (pertanyaan), 
\textit{Chain of Thought} (langkah penalaran), dan \textit{Output} (jawaban). 
Dengan melihat contoh yang memiliki langkah 
penalaran eksplisit, model kemudian 
akan meniru pola tersebut untuk menghasilkan langkah penalarannya 
sendiri saat menjawab pertanyaan baru \cite{Wei2022}.


% % membahas dasar teori prompt engineering dan jenis-jenis prompt engineering
\subsection{\textit{Context Engineering}}

% \subsection{\textit{Learning Analytics} (LA) dan Papan Kanban}
% \subsubsection{Papan Kanban dalam Pendidikan}
% \subsubsection{\textit{Learning Analytics} (LA)}

% \subsection{Metodologi Evaluasi}
% \subsubsection{Evaluasi Berbasis Semantik}
% % Jelaskan mengapa metrik tradisional (seperti BLEU/ROUGE yang berbasis kecocokan kata per kata) tidak cocok untuk tugas kreatif seperti feedback. BERTScore: Mengukur kesamaan makna menggunakan contextual embedding. BARTScore: Menggunakan probabilitas generasi teks untuk menilai kualitas.
% \subsubsection{\textit{LLM-as-a-Judge}}

% ==========================================================================

% \subsection{\textit{Self Regulated Learning} (SRL) dan Peran Umpan Balik}
% % Self-Regulated Learning (SRL) atau pembelajaran regulasi diri adalah konsep di mana peserta didik 
% % secara aktif mengarahkan dan mengontrol proses belajarnya sendiri. Menurut teori sosial-kognitif 
% % Zimmerman (2000), SRL merupakan proses siklikal yang mencakup fase perencanaan, pelaksanaan, 
% % dan evaluasi [7]. Dalam fase perencanaan, mahasiswa menetapkan tujuan belajar dan merencanakan 
% % strategi; fase pelaksanaan melibatkan penerapan strategi kognitif (misalnya membaca, membuat 
% % catatan) serta pemantauan metakognitif (misalnya manajemen waktu) untuk menyelesaikan tugas; 
% % sedangkan fase evaluasi mencakup penilaian diri terhadap kemajuan belajar dan hasil yang dicapai [7]. 
% % Melalui siklus ini, mahasiswa dengan SRL tinggi akan merefleksikan capaian mereka dan menyesuaikan 
% % pendekatan belajarnya secara mandiri agar tujuan pembelajaran tercapai [7].

% % Di tingkat pendidikan tinggi, SRL memegang peran krusial dalam menentukan keberhasilan akademik. 
% % Penelitian menunjukkan bahwa kemampuan regulasi diri berhubungan erat dengan kesuksesan mahasiswa 
% % di perguruan tinggi [7]. Mahasiswa yang terampil dalam SRL cenderung lebih berhasil karena mereka 
% % mampu merencanakan, menetapkan tujuan, mengorganisasi kegiatan belajar, serta melakukan evaluasi 
% % diri secara berkelanjutan selama proses pembelajaran [7]. Kemampuan-kemampuan ini membantu 
% % mahasiswa belajar lebih efektif dan mandiri.

% % Lebih lanjut, berbagai studi di pendidikan tinggi telah mengaitkan SRL dengan sejumlah indikator 
% % positif: kinerja akademik yang lebih baik, tingkat retensi (ketahanan studi) yang lebih tinggi, 
% % keterlibatan yang lebih mendalam dalam aktivitas perkuliahan, dan kemampuan adaptasi yang lebih 
% % baik terhadap kehidupan kampus [7]. Sebagai contoh, mahasiswa yang menguasai strategi SRL 
% % dilaporkan memiliki prestasi yang lebih tinggi dan risiko putus studi yang lebih rendah [7]. 
% % Intervensi pendidikan yang dirancang untuk meningkatkan keterampilan regulasi diri juga 
% % terbukti efektif memperbaiki performa akademis dan mencegah dropout mahasiswa [7]. Hal ini 
% % menegaskan bahwa mengembangkan kompetensi SRL pada mahasiswa merupakan investasi penting 
% % dalam meningkatkan kualitas pembelajaran di pendidikan tinggi.

% % Pendidikan tinggi menuntut mahasiswa untuk lebih mandiri dan proaktif dalam belajar. Mahasiswa 
% % tidak selalu dibimbing secara intens seperti di jenjang sebelumnya; karena itu, kemampuan 
% % regulasi diri menjadi kunci. Apalagi dengan berkembangnya pembelajaran daring dan blended 
% % learning, SRL semakin esensial. Studi terbaru menekankan bahwa dalam lingkungan belajar 
% % online, mahasiswa dituntut memiliki kapasitas regulasi diri lebih besar dibandingkan 
% % pendidikan tatap muka [7]. Tanpa SRL yang memadai, kesenjangan dalam penguasaan materi dan 
% % keterampilan belajar dapat semakin lebar saat pembelajaran beralih ke moda daring [7]. 
% % Oleh sebab itu, perguruan tinggi masa kini menghadapi tantangan untuk membekali mahasiswa 
% % dengan keterampilan SRL agar mereka dapat sukses, baik dalam konteks pembelajaran 
% % konvensional maupun digital.





% % [1] Panadero, E., & Alonso-Tapia, J. (2016). Self-assessment: Theoretical and practical connotations, when it happens, how is it acquired, and what to do to develop it in our students. Electronic Journal of Research in Educational Psychology, 14(1), 551-576.
% % [2] Zimmerman, B. J. (2000). Attaining self-regulation: A social cognitive perspective. In Handbook of self-regulation (pp. 13-39). Academic Press.
% % [3] Hattie, J., & Timperley, H. (2007). The power of feedback. Review of Educational Research, 77(1), 81-112.
% % [4] Wisniewski, B., Zierer, K., & Hattie, J. (2020). The power of feedback revisited: A meta-analysis of educational feedback research. Frontiers in Psychology, 10, 3087.
% % [5] Sun, D., Xu, P., Zhang, J., Liu, R., & Zhang, J. (2025). How Self-Regulated Learning Is Affected by Feedback Based on Large Language Models: Data-Driven Sustainable Development in Computer Programming Learning. Electronics, 14(1), 194.
% % [6] Nakata, Y., Wang, C., & Yamamoto, Y. (2025). Student perceptions of feedback and self-regulated language learning: A mixed-methods investigation. System, 131, 103654.
% % [7] Lobos, K., Cobo-Rendón, R., Jofré, D. B., & Santana, J. (2024). New challenges for higher education: self-regulated learning in blended learning contexts. Frontiers in Education, 9, 1457367.
% % [8] Steinert, S., Küchemann, S., Avila, K. E., et al. (2024). Harnessing large language models to develop research-based learning assistants for formative feedback. Smart Learning Environments, 11(1), 30.

% \textit{Self-Regulated Learning} (SRL) merujuk pada kapasitas mahasiswa untuk secara aktif merencanakan, 
% memantau, dan mengevaluasi proses belajarnya sendiri, melalui siklus 
% perencanaan, pelaksanaan, dan refleksi yang saling terkait [1], [2]. Pada fase perencanaan, 
% mahasiswa menetapkan tujuan serta strategi. Lalu, pada fase pelaksanaan, mereka menerapkan strategi 
% kognitif dan melakukan pemantauan metakognitif (mis. manajemen waktu, monitoring pemahaman). 
% Kemudian, pada fase refleksi, mahasiswa melibatkan penilaian diri terhadap kemajuan dan hasil untuk 
% menyesuaikan strategi berikutnya [1], [2]. Berbekal mekanisme siklikal ini, SRL menggabungkan 
% dimensi kognitif, motivasional, dan perilaku yang bersama-sama menentukan kualitas belajar 
% mandiri di pendidikan tinggi [1], [2].

% Di konteks pendidikan tinggi, SRL berperan krusial karena lingkungan belajar menuntut kemandirian,
% terutama pada pembelajaran digital (daring atau campuran) yang memerlukan disiplin diri lebih tinggi
% serta kemampuan mengelola distraksi. Kajian terkini menunjukkan bahwa SRL berkorelasi dengan
% kinerja akademik, keterlibatan, dan ketahanan studi. Sebaliknya, kekurangan SRL di
% pembelajaran daring atau campuran dapat memperlebar kesenjangan capaian yang diperoleh 
% mahasiswa [3]. Dengan demikian,
% pengembangan kompetensi SRL termasuk penetapan tujuan, strategi, monitoring, dan
% refleksi—menjadi prasyarat penting untuk keberhasilan mahasiswa di ekosistem belajar
% modern [2], [3].

% Kemajuan \textit{Large Language Models} (LLM) membuka peluang penyediaan 
% bimbingan pengarahan (\textit{feedback}) yang personal, 
% cepat, dan interaktif untuk menopang SRL. 
% Studi eksperimental di konteks pemrograman (pendidikan tinggi) menunjukkan 
% \textit{feedback} berbasis LLM dapat meningkatkan strategi metakognitif, 
% motivasi, dan performa mahasiswa dibanding kondisi 
% tanpa \textit{feedback} dari AI [6]. Riset pengembangan menunjukkan asisten belajar 
% berbasis LLM yang dirancang dengan prinsip-prinsip pedagogis 
% mampu menyajikan \textit{feedback} yang scaffolded (bertahap), memicu \textit{self-explanation}, 
% dan menuntun refleksi [7]. Dengan dialog natural, LLM dapat membantu ketiga fase 
% SRL yaitu, (i) perencanaan (menyusun tujuan dan rencana aksi), 
% (ii) pelaksanaan (memberi hint/pertanyaan pemandu saat buntu), 
% dan (iii) refleksi (merangkum kekuatan-kelemahan dan langkah tindak lanjut) [6], [7]. 
% Agar efektif dan aman, \textit{feedback} LLM sebaiknya disejajarkan dengan praktik pedagogis berbasis 
% bukti (fokus pada proses, \textit{actionability}, dan nada empatik) dan dievaluasi kualitasnya 
% secara sistematis.

% % \paragraph{Landasan tiga fungsi pedagogis.}
% Dalam kerangka SRL, efektivitas umpan balik dipahami melalui fokus bertingkat pada 
% \textit{task}, \textit{process}, dan \textit{self-regulation}, serta dampaknya pada 
% keyakinan diri dan ketekunan belajar [4]. Menurut artikel jurnal ini [4], disebutkan bahwa 
% \textit{feedback} kognitif efektif bila spesifik, mendiagnosis miskonsepsi, dan 
% menyarankan langkah perbaikan yang terstruktur. Lalu, \textbf{dukungan motivasional} 
% menjaga \textit{self-efficacy} (keyakinan diri), menetapkan tujuan yang menantang namun realistis, 
% serta mendorong komitmen rencana aksi. Terakhir, pemberian apresiasi yang spesifik 
% terhadap usaha/progres dapat berkontribusi pada afek positif dan keterlibatan yang 
% disertai arahan perbaikan agar tidak menjadi pujian kosong [4]. Oleh karena itu, 
% penelitian ini menilai kualitas respons LLM pada ketiga fungsi tersebut karena ketiganya 
% (\textit{feedback}, \textit{motivation}, dan \textit{appreciation}) 
% secara langsung mendukung fase perencanaan–pelaksanaan–refleksi dalam SRL [1], [2], [4].


% % [1] B. J. Zimmerman, “Becoming a self-regulated learner: An overview,” Theory Into Practice, vol. 41, no. 2, pp. 64–70, 2002.
% % [2] E. Panadero, “A review of self-regulated learning: Six models and four directions for research,” Educational Psychology Review, vol. 29, no. 4, pp. 1–28, 2017.
% % [3] K. Lobos, R. Cobo-Rendón, D. B. Jofré, and J. Santana, “New challenges for higher education: Self-regulated learning in blended learning contexts,” Frontiers in Education, vol. 9, art. 1457367, 2024.
% % [4] D. J. Nicol and D. Macfarlane-Dick, “Formative assessment and self-regulated learning: A model and seven principles of good feedback practice,” Studies in Higher Education, vol. 31, no. 2, pp. 199–218, 2006.
% % [5] J. Hattie and H. Timperley, “The power of feedback,” Review of Educational Research, vol. 77, no. 1, pp. 81–112, 2007.
% % [6] D. Sun, P. Xu, J. Zhang, R. Liu, and J. Zhang, “How self-regulated learning is affected by feedback based on large language models: Data-driven sustainable development in computer programming learning,” Electronics, vol. 14, no. 1, art. 194, 2025.
% % [7] S. Steinert et al., “Harnessing large language models to develop research-based learning assistants for formative feedback,” Smart Learning Environments, vol. 11, no. 1, art. 30, 2024.

% % LLM dalam dunia pendidikan undergraduate

% \subsection{\textit{Large Language Model} (LLM)}

% \textit{Kecerdasan Buatan} adalah cabang ilmu komputer yang berfokus 
% pada pembuatan sistem yang mampu meniru kecerdasan manusia dalam 
% pemecahan masalah dan pengambilan keputusan. Pendekatan awal AI banyak 
% bersifat \textit{symbolic} (\textit{rule-based}), namun berkembang 
% menuju metode \textit{data-driven} seperti \textit{machine learning}. 
% Sejak awal, para peneliti AI telah membayangkan tercapainya 
% \textit{general problem solver} yang mampu menyelesaikan berbagai 
% tugas secara cerdas \cite{Bazelais2024User}. Kemajuan mutakhir di bidang 
% \textit{natural language processing} menunjukkan tanda-tanda menuju 
% visi tersebut, contohnya model bahasa besar (\textit{large language model}) 
% seperti \textit{ChatGPT} yang dilatih dengan miliaran parameter pada 
% seluruh teks internet mampu melakukan beragam tugas tekstual secara 
% \textit{out-of-the-box} dan menunjukkan kemampuan \textit{emergent} 
% mendekati kecerdasan umum manusia \cite{Bazelais2024User}. Perkembangan ini menandai lompatan 
% signifikan dalam upaya mewujudkan AI yang lebih cerdas dan serbaguna.

% % referensi:
% % [1]https://www.ejmste.com/article/user-acceptance-and-adoption-dynamics-of-chatgpt-in-educational-settings-14151#:~:text=Recent%20developments%20in%20natural%20language,days%20of%20artificial%20intelligence%20research

% Salah satu pendekatan utama untuk mencapai AI adalah pembelajaran mesin 
% (machine learning), yakni algoritme yang memungkinkan komputer belajar 
% dari data tanpa diprogram secara eksplisit. Alih-alih merancang aturan 
% manual, pendekatan ini membuat sistem mengekstraksi pola dan pengetahuan 
% langsung dari data. Khususnya, deep learning (pembelajaran mendalam) 
% yang menggunakan jaringan saraf tiruan berlapis banyak telah merevolusi 
% berbagai bidang, mulai dari pengenalan gambar hingga pemrosesan bahasa. 
% Model deep learning mampu mempelajari representasi fitur tingkat tinggi 
% secara hierarkis, sehingga melampaui pendekatan statistik konvensional. 
% Dalam konteks pemodelan bahasa, pendekatan ini menggantikan model n-gram 
% sederhana dengan model neural probabilistik yang memahami semantik lebih 
% dalam [1]. Penerapan jaringan saraf berstruktur dalam (recurrent neural 
% networks dan transformer) terbukti meningkatkan performa sistem NLP 
% secara drastis, membuka jalan bagi terciptanya model bahasa yang semakin 
% kompleks dan akurat.

% % referensi:
% % [1]https://www.preprints.org/manuscript/202408.1483#:~:text=essential%20for%20applications%20requiring%20natural,16

% Pemrosesan Bahasa Alami (natural language processing atau NLP) adalah 
% cabang AI yang berfokus pada interaksi antara komputer dan bahasa manusia. 
% Tugas-tugas NLP mencakup pemahaman teks, terjemahan otomatis, chatbot, 
% ekstraksi informasi, dan lain-lain. Inti dari banyak sistem NLP adalah 
% model bahasa (language model), yaitu model probabilistik yang mempelajari 
% pola dan kecenderungan dalam sekumpulan teks untuk memprediksi kata atau 
% frasa berikutnya dalam sebuah kalimat. Generasi awal model bahasa 
% menggunakan metode statistik (misalnya unigram dan n-gram) yang terbatas 
% dalam menangkap konteks panjang. Perkembangan kemudian beralih ke model 
% berbasis jaringan saraf seperti Recurrent Neural Networks (RNN) dan 
% variannya LSTM/GRU, yang mampu mempertimbangkan urutan kata secara dinamis. 
% Terobosan terbesar datang dengan diperkenalkannya arsitektur Transformer 
% oleh Vaswani dkk. (2017), yang menggunakan mekanisme self-attention. 
% Arsitektur transformer ini membawa perubahan mendasar dalam rancangan 
% model bahasa dengan menangani dependensi jarak jauh secara lebih 
% efisien [1]. Inovasi tersebut menjadi landasan bagi lahirnya generasi 
% model bahasa mutakhir, termasuk keluarga GPT dari OpenAI dan model BERT 
% dari Google, yang menunjukkan pemahaman konteks dan kemampuan generatif 
% yang unggul.

% % referensi:
% % [1]https://www.preprints.org/manuscript/202408.1483#:~:text=The%20advent%20of%20transformer,LLMs%2C%20including%20models%20like%20Generative

% Arsitektur Transformer memungkinkan pemrosesan urutan kata secara 
% paralel, berbeda dengan RNN yang memproses secara sekuensial. 
% Dalam encoder-decoder penuh, model dapat menangani tugas 
% sequence-to-sequence (misal penerjemahan) dengan efisien: encoder 
% menyandikan seluruh kalimat sumber menjadi representasi vektor, 
% lalu decoder secara autoregresif menghasilkan keluaran (kalimat 
% terjemahan) dengan memperhatikan konteks penyandian. Banyak Large 
% Language Model (LLM) generatif (seperti GPT-3 dan GPT-4) menggunakan 
% arsitektur transformer jenis decoder-only untuk menghasilkan teks, 
% sedangkan model seperti BERT menggunakan encoder saja untuk tugas 
% pemahaman bahasa. Fleksibilitas desain ini menjadikan Transformer 
% dapat diadaptasi untuk berbagai skenario NLP, dan skalanya dapat 
% diperbesar dengan menambah jumlah lapisan atau dimensi model untuk 
% mencapai performa yang lebih tinggi [1].

% % referensi:
% % [1]https://www.preprints.org/frontend/manuscript/92e4d57fdff35ee45698968cd472f781/download_pub#:~:text=More%20recent%20efforts%20have%20focused,3%2C%20which%20features%20several


% Large Language Model (LLM) merujuk pada model bahasa berukuran sangat 
% besar (berskala miliaran hingga triliunan parameter) yang dilatih pada 
% korpus teks yang amat luas. LLM dirancang untuk memahami dan menghasilkan 
% bahasa alami dengan tingkat kefasihan tinggi, bahkan mampu menangani 
% berbagai tugas tanpa pelatihan khusus (zero-shot/few-shot learning). 
% Contoh populer adalah GPT-3 dan GPT-4 dari OpenAI, yang masing-masing 
% memiliki sekitar 175 miliar dan diperkirakan 800 miliar parameter [1]. 
% Model sebesar ini dilatih menggunakan supercomputer selama ribuan jam 
% pada himpunan data teks raksasa (misalnya seluruh konten internet) [2]. 
% Dengan skala dan keragaman data tersebut, LLM menunjukkan kemampuan 
% emergen, misalnya dapat menjawab pertanyaan, menulis esai, menerjemahkan, 
% hingga memecahkan soal kode yang semuanya tanpa fine-tuning tambahan [2]. 
% LLM generatif seperti ChatGPT bahkan mampu melakukan dialog interaktif 
% dan memberikan penjelasan yang mendekati gaya humanis.

% % referensi:
% % [1]https://www.preprints.org/manuscript/202408.1483#:~:text=Falcon%202022%20SpaceX%20AI%20Streamlined,solving
% % [2]https://www.ejmste.com/article/user-acceptance-and-adoption-dynamics-of-chatgpt-in-educational-settings-14151#:~:text=Recent%20developments%20in%20natural%20language,days%20of%20artificial%20intelligence%20research

% Peningkatan ukuran model secara konsisten terbukti berbanding lurus 
% dengan peningkatan kinerja pada aneka tugas [1]. Studi menunjukkan tren 
% bahwa semakin banyak parameter dalam model bahasa, akurasi dan kemampuan 
% generalisasi model tersebut meningkat signifikan di berbagai domain [1]. 
% Hal ini mendorong lahirnya model XtremeLLM, istilah untuk LLM dengan 
% lebih dari satu triliun parameter [1]. Namun, lonjakan skala ini juga 
% membawa tantangan besar. Model dengan ratusan miliar parameter memerlukan 
% sumber daya komputasi dan memori yang luar biasa, serta berdampak pada 
% waktu pengembangan dan konsumsi energi yang tinggi [1]. Di samping itu, LLM 
% kerap menghadapi isu hallucination (menghasilkan informasi salah yang 
% terdengar meyakinkan) dan bias yang tertanam dari data latih [2]. 
% Ketiadaan standar baku dalam pengembangan model-model masif ini menambah 
% kompleksitas untuk menjamin keandalan dan keamanan penerapannya [2]. 
% Beberapa kajian bahkan menggarisbawahi masalah etis seperti potensi 
% penyalahgunaan, plagiat, misinformasi, serta pelanggaran privasi dan 
% hak cipta jika LLM digunakan tanpa pengawasan [3]. Oleh karena itu, 
% meskipun LLM menawarkan lompatan kinerja, diperlukan strategi mitigasi 
% terhadap risiko teknis dan etis tersebut.

% % referensi:
% % [1]https://www.preprints.org/frontend/manuscript/92e4d57fdff35ee45698968cd472f781/download_pub#:~:text=Therefore%2C%20our%20work%20introduces%20the,challenges%20and%20opportunities%20they%20present
% % [2]https://journals.lww.com/cmj/fulltext/2024/11050/leveraging_foundation_and_large_language_models_in.3.aspx#:~:text=noteworthy%20limitations%2C%20including%20hallucinations%2C%20biases%2C,50%2C83%E2%80%9385
% % [3]https://research.uaeu.ac.ae/en/publications/large-language-models-in-medical-education-opportunities-challeng/#:~:text=learning%20materials%2C%20student%20assessments%2C%20and,gleaned%20from%20this%20analysis%20will

% Perlu dicatat bahwa LLM dapat bersifat umum maupun spesifik domain. 
% Wong et al. (2024) mengklasifikasikan model AI berbasis 
% foundation model menjadi: (1) model khusus penyakit atau tugas 
% tertentu, (2) model domain umum yang serbaguna di berbagai aplikasi 
% medis, dan (3) model multimodal yang menangani data teks, citra, 
% maupun sinyal sekaligus [1]. Ilustrasi ini menunjukkan bahwa framework 
% LLM cukup fleksibel untuk diadaptasi; sebuah model besar bisa 
% di-fine-tune untuk keperluan sangat khusus (misalnya diagnostik 
% penyakit tertentu), atau dikembangkan sebagai model generalis yang 
% mampu menjawab pertanyaan di banyak topik. Kemampuan integratif ini 
% menjadikan LLM sebagai komponen inti dalam ecosystem AI modern di 
% berbagai bidang.

% % referensi:
% % [1]https://journals.lww.com/cmj/fulltext/2024/11050/leveraging_foundation_and_large_language_models_in.3.aspx#:~:text=In%20this%20review%2C%20our%20focus,data%20types%2C%20to%20enhance%20the


% LLM semakin dilirik untuk diimplementasikan dalam konteks pendidikan 
% karena potensinya yang besar dalam meningkatkan proses 
% belajar-mengajar. Integrasi model bahasa generatif seperti GPT-4 
% ke dalam pendidikan dipandang mampu mentransformasi pengalaman 
% belajar siswa dan meningkatkan pengetahuan serta kompetensi mereka [1]. 
% LLM dapat digunakan untuk mengembangkan kurikulum secara dinamis, 
% menghasilkan materi pembelajaran yang dipersonalisasi sesuai kebutuhan 
% masing-masing siswa, menyusun rencana studi individual, hingga 
% memberikan umpan balik otomatis dalam penilaian tugas [1]. Dalam 
% pendidikan kedokteran, misalnya, LLM berpeluang merevolusi metode 
% pengajaran dan evaluasi dengan menyediakan skenario klinis interaktif, 
% menjawab pertanyaan medis secara instan, dan membantu mahasiswa 
% melatih keterampilan diagnosis dalam lingkungan simulasi [1]. Studi 
% Znamenskiy et al. (2025) menunjukkan sebuah kerangka kerja di mana 
% platform GenAI (seperti ChatGPT, Claude, dan lain-lain) diintegrasikan 
% ke dalam praktikum lab untuk melatih berpikir kritis dan literasi 
% digital mahasiswa. Mahasiswa didorong merumuskan pertanyaan (prompts) 
% disiplin-spesifik dan kemudian mengevaluasi jawaban atau konten 
% yang dihasilkan AI. Hasil uji coba pada kelas astronomi untuk 
% non-sains menunjukkan tingkat keterlibatan dan refleksi kritis 
% yang tinggi; banyak mahasiswa yang secara sukarela melanjutkan 
% eksplorasi di luar jam kelas dan bahkan mempresentasikan temuan 
% mereka di simposium penelitian [2]. Temuan ini mengisyaratkan bahwa 
% interaksi terstruktur dengan LLM, jika dipadu dengan metode asesmen 
% reflektif, dapat meningkatkan motivasi dan hasil belajar mahasiswa [2]. 
% Dengan kata lain, LLM berpotensi berperan sebagai tool pendamping 
% yang memperkaya pembelajaran aktif dan investigatif di lingkungan 
% pendidikan.

% % referensi:
% % [1]https://research.uaeu.ac.ae/en/publications/large-language-models-in-medical-education-opportunities-challeng/#:~:text=The%20integration%20of%20large%20language,overreliance%2C%20plagiarism%2C%20misinformation%2C%20inequity%2C%20privacy
% % [2]https://arxiv.org/abs/2507.00007#:~:text=Students%20formulate%20discipline,See%20the%20guide%20to

% % Meskipun menjanjikan, penerapan LLM di pendidikan juga menghadirkan 
% % sejumlah tantangan dan prasyarat. Salah satu kekhawatiran utama 
% % adalah potensi penyalahgunaan oleh siswa, misalnya menggunakan 
% % ChatGPT untuk menulis esai tugas yang dapat berujung pada 
% % plagiarisme atau penurunan kemampuan berpikir orisinal. Abd-Alrazaq 
% % et al. (2023) mengingatkan bahwa integrasi LLM tanpa kontrol 
% % dapat menimbulkan overreliance pada mesin, bias algoritmik 
% % dalam konten materi, misinformasi ilmiah, hingga pelanggaran 
% % privasi data siswa ￼. Oleh karena itu, pendidik perlu menetapkan 
% % etika penggunaan dan strategi mitigasi, seperti mengecek 
% % orisinalitas karya dan mengedukasi siswa tentang batasan AI. 
% % Dari sisi penerimaan teknologi, faktor manfaat yang dirasakan 
% % terbukti berpengaruh signifikan terhadap adopsi LLM oleh pengguna. 
% % Sebuah studi survei terhadap 138 pelajar menemukan bahwa 
% % performance expectancy (harapan terhadap kinerja/manfaat) berkorelasi 
% % positif dengan niat untuk menggunakan ChatGPT, yang selanjutnya 
% % mendorong penggunaan aktual platform tersebut dalam pembelajaran ￼. 
% % Temuan ini menunjukkan bahwa siswa cenderung menerima dan memakai 
% % LLM apabila mereka meyakini teknologi ini benar-benar membantu 
% % meningkatkan prestasi atau mempermudah tugas belajar.

% % Selain itu, penerapan LLM dalam penilaian (assessment) membutuhkan 
% % kehati-hatian khusus. Di satu sisi, teknologi ini menawarkan peluang 
% % untuk meningkatkan efisiensi penilaian, mengurangi bias penilai 
% % manusia, serta memungkinkan evaluasi yang lebih adaptif dan 
% % personal ￼. Misalnya, LLM dapat dipakai untuk menghasilkan butir 
% % soal kustom sesuai tingkat kemampuan siswa, memberikan umpan balik 
% % otomatis pada jawaban esai, atau bahkan melakukan penskoran awal 
% % atas ujian esai secara konsisten. Namun di sisi lain, inovasi ini 
% % memunculkan kekhawatiran mengenai validitas dan keadilan evaluasi ￼. 
% % Apabila siswa dibantu AI dalam menjawab soal, maka validitas ujian 
% % ebagai pengukur kemampuan asli bisa terkompromi. Demikian pula, aspek 
% % transparansi algoritma LLM dalam penilaian, potensi bias terhadap 
% % kelompok tertentu, dan keamanan (misal kemungkinan kebocoran soal 
% % melalui model) menjadi isu yang harus diantisipasi ￼. 
% % Hao et al. (2024) menekankan bahwa komunitas pendidik dan penilai 
% % perlu meningkatkan literasi AI mereka untuk dapat memanfaatkan LLM 
% % secara efektif sekaligus menjaga integritas asesmen ￼. Artinya, 
% % pelatihan bagi guru/dosen tentang cara kerja dan keterbatasan LLM, 
% % penyusunan kebijakan penggunaan AI dalam ujian, serta pengembangan 
% % metode deteksi kecurangan berbasis AI menjadi sangat penting 
% % seiring semakin terintegrasinya LLM dalam dunia pendidikan.

% % Sebagai kesimpulan, Large Language Model menghadirkan paradigma 
% % baru dalam pendidikan yang bila dimanfaatkan dengan tepat dapat 
% % mengakselerasi pembelajaran, menyediakan pengalaman belajar yang 
% % dipersonalisasi, dan meningkatkan efisiensi pengajaran. Studi 
% % kasus terkini menunjukkan potensi positif LLM untuk mendorong 
% % keterlibatan dan pemikiran kritis mahasiswa ￼, namun juga 
% % mengingatkan kita akan tantangan etis dan pedagogis yang 
% % menyertainya ￼ ￼. Dengan kerangka regulasi dan literasi AI yang 
% % memadai, LLM dapat diimplementasikan sebagai alat bantu inovatif 
% % di berbagai jenjang pendidikan, mulai dari pembelajaran di kelas, 
% % laboratorium, hingga evaluasi, guna melahirkan generasi pembelajar 
% % yang adaptif di era AI.

% \subsection{\textit{Prompt Engineering}}

% \textit{Prompt engineering} merupakan bidang kajian baru yang berfokus pada perancangan, penyempurnaan, 
% dan implementasi prompt atau instruksi yang diberikan kepada model bahasa besar LLM 
% untuk mengarahkan keluaran model tersebut [1]. Dengan kata lain, \textit{prompt engineering} 
% adalah “mekanisme pengendali” (\textit{steering mechanism}) yang digunakan pengguna kecerdasan buatan 
% generatif untuk menyusun \textit{prompt} sedemikian rupa agar menghasilkan keluaran yang diinginkan [2]. 
% Konsep ini menjadi semakin penting seiring munculnya LLM populer seperti ChatGPT, karena 
% kemampuan merancang \textit{prompt} yang efektif memungkinkan pengguna untuk mendapatkan jawaban yang 
% lebih akurat, relevan, dan sesuai kebutuhan dari model AI [1].

% Sebagai suatu keterampilan, \textit{prompt engineering} dapat dipelajari dan dikembangkan. 
% Para peneliti menuliskan bahwa \textit{prompt engineering} sudah mulai diajarkan secara formal, 
% misalnya di perguruan tinggi, karena dianggap sebagai \textit{skillset} baru yang 
% dibutuhkan di era integrasi AI [2]. Intinya, \textit{prompt engineering} 
% menekankan seni merumuskan pertanyaan atau perintah dalam bahasa natural 
% sedemikian rupa sehingga model AI memahami konteks tugas dan memberikan respon optimal sesuai 
% keinginan pengguna.

% \subsection{\textit{Context Engineering}}

% \textit{Context engineering} adalah disiplin yang berkembang untuk melengkapi dan melampaui 
% \textit{prompt engineering}. Jika \textit{prompt engineering} berfokus 
% pada apa yang dikatakan kepada model pada satu waktu, maka \textit{context engineering} 
% berfokus pada apa saja yang diketahui model saat \textit{prompt} tersebut 
% diberikan. Menurut survei terbaru, \textit{context engineering} didefinisikan sebagai disiplin formal 
% yang melampaui sekadar perancangan \textit{prompt} dan mencakup optimisasi sistematis dari informasi 
% konteks yang disuplai ke LLM [3]. Kinerja LLM sangat ditentukan oleh informasi kontekstual 
% yang diberikan selama inferensi, sehingga \textit{context engineering} berusaha memastikan model 
% menerima \textit{payload} informasi yang paling relevan dan berguna.

% Dalam praktiknya, \textit{context engineering} mencakup teknik-teknik seperti \textit{retrieval-augmented 
% generation} (RAG) untuk mengambil pengetahuan eksternal, penggunaan \textit{memory systems} agar 
% model mengingat interaksi sebelumnya, integrasi alat tambahan (\textit{tool-integrated reasoning}), 
% hingga koordinasi \textit{multi-agen} AI [3]. Berbeda dengan \textit{prompt engineering} yang hanya memanipulasi 
% teks \textit{prompt}-nya, \textit{context engineering} mengatur lingkungan dan konteks bagi model, misalnya 
% mengumpulkan data pendukung, menyusun instruksi sistem, mendefinisikan aturan, serta memasukkan 
% memori atau informasi historis sebelum \textit{prompt} diberikan. Tujuannya adalah memaksimalkan kualitas 
% jawaban AI dengan menghadirkan konteks informasi yang optimal dalam batas panjang konteks model 
% tersebut [3]. Dengan demikian, \textit{context engineering} menjadikan AI lebih andal dan \textit{context-aware}, 
% tidak semata-mata mengandalkan satu perintah teks statis.

% \subsection{Jenis Teknik \textit{Prompting}}


% \subsection{Perbedaan \textit{Prompt Engineering} dan \textit{Context Engineering}}
% Meskipun terkait, \textit{prompt engineering} dan \textit{context engineering} memiliki fokus dan pendekatan yang 
% berbeda. Berikut adalah perbedaan utama keduanya [3]:
% % •	Lingkup Input: \textit{Prompt engineering} memandang \textit{prompt} sebagai teks statis tunggal yang 
% % 	menjadi masukan model. Sebaliknya, \textit{context engineering} memandang konteks secara dinamis dan 
% % 	terstruktur, terdiri dari berbagai komponen informasi (instruksi sistem, pengetahuan eksternal, 
% % 	memori percakapan, status pengguna, dll.) yang dirangkai bersama sebagai masukan [3]. 
% % 	Dengan kata lain, \textit{prompt engineering} beroperasi di dalam jendela konteks yang ada, sedangkan 
% % 	\textit{context engineering} menentukan apa saja yang mengisi jendela konteks tersebut.
% % •	Informasi dan Memori: Pada \textit{prompt engineering}, informasi yang diberikan bersifat tetap 
% % 	dalam teks \textit{prompt}, dan interaksi biasanya tanpa memori jangka panjang (setiap \textit{prompt} berdiri 
% % 	sendiri) [3]. Pada \textit{context engineering}, tujuannya adalah memaksimalkan informasi yang relevan 
% % 	dengan tugas dalam batas konteks model [3]. \textit{Context engineering} juga secara eksplisit 
% % 	mempertimbangkan komponen memori atau state, sehingga model dapat memanfaatkan informasi 
% % 	dari interaksi sebelumnya (stateful) [3].
% % •	Pendekatan Optimasi: \textit{Prompt engineering} umumnya mengandalkan percobaan manual dan 
% % 	iteratif dalam merancang kalimat \textit{prompt} hingga didapat keluaran yang diinginkan, sehingga 
% % 	sering dianggap sebagai suatu art (seni coba-coba) [3]. Sebaliknya, \textit{context engineering} 
% % 	menerapkan pendekatan yang lebih sistematis atau scientific. Ia melibatkan optimisasi di 
% % 	level sistem secara menyeluruh, misalnya menentukan fungsi-fungsi pengambil dan pengolah 
% % 	konteks yang ideal, dengan tujuan akhir meningkatkan kualitas output LLM secara konsisten [3]. 
% % 	Dalam \textit{context engineering}, evaluasi dan penyempurnaan bisa dilakukan pada masing-masing 
% % 	komponen konteks (misal modul pencarian pengetahuan atau mekanisme memori) secara terukur, 
% % 	bukan sekadar inspeksi output akhir secara manual [3].
% % •	Skalabilitas dan Kompleksitas: \textit{Prompt engineering} cenderung rapuh ketika \textit{prompt} menjadi 
% % 	terlalu panjang atau kompleks, karena model dapat kehilangan fokus atau konsistensi; 
% % 	pendekatan ini kurang terstruktur untuk skenario kompleks [3]. \textit{Context engineering} dirancang 
% % 	untuk mengatasi hal ini dengan komposisi modular, mengelola konteks panjang melalui 
% % 	segmentasi informasi, hirarki memori, dan kompresi konteks bila perlu [3]. Dengan demikian, 
% % 	\textit{context engineering} lebih siap menangani skala konteks yang besar dan beragam (misalnya 
% % 	input \textit{multi-modal}, pengetahuan berjenjang) dibandingkan pendekatan \textit{prompt-only}.

% \begin{table}[h]
% \centering
% \caption{Perbandingan \textit{Prompt Engineering} dan \textit{Context Engineering}}
% \label{tab:perbandingan}
% \begin{tabular}{|p{0.22\linewidth}|p{0.35\linewidth}|p{0.35\linewidth}|}
% \hline
% \textbf{Aspek} & \textbf{\textit{Prompt Engineering}} & \textbf{\textit{Context Engineering}} \\
% \hline
% Lingkup Input & Memandang \textit{prompt} sebagai teks statis tunggal yang menjadi masukan model. & Memandang konteks secara dinamis dan terstruktur, terdiri dari berbagai komponen informasi (instruksi, pengetahuan, memori, status pengguna) yang dirangkai bersama. \\
% \hline
% Informasi dan Memori & Informasi bersifat tetap dalam teks \textit{prompt}; interaksi biasanya tanpa memori jangka panjang (setiap \textit{prompt} berdiri sendiri). & Mempertimbangkan komponen memori atau \textit{state} secara eksplisit, memungkinkan model memanfaatkan informasi dari interaksi sebelumnya (\textit{stateful}). \\
% \hline
% Pendekatan Optimasi & Mengandalkan percobaan manual dan iteratif; sering dianggap sebagai suatu seni (\textit{art}) coba-coba. & Menerapkan pendekatan yang sistematis dan ilmiah (\textit{scientific}); melibatkan optimisasi di level sistem secara menyeluruh. \\
% \hline
% Skalabilitas dan Kompleksitas & Cenderung rapuh untuk \textit{prompt} yang panjang dan kompleks; kurang terstruktur untuk skenario kompleks. & Dirancang untuk mengelola konteks yang besar dan beragam secara modular (segmentasi, hirarki, kompresi). \\
% \hline
% \end{tabular}
% \end{table}

% % \begin{table}[h]
% % 	\caption{Tabel ini}
% % 	\vspace{0.5em}
% % 	\centering
% % 	\begin{tabular}{|c|c|c|}
% % 		\hline
% % 		ID & Tinggi Badan (cm) & Berat Badan (kg) \\
% % 		\hline \hline
% % 		A23 & 173 & 62 \\
% % 		A25 & 185 & 78 \\
% % 		A10 & 162 & 70 \\ \hline
% % 	\end{tabular}
% % 	\label{Tab: Tabel Tinggi Berat}
% % \end{table}
% % Contoh penulisan tabel bisa dilihat pada Tabel \ref{Tab: Tabel Tinggi Berat}.


% % Kasih Gambar.

% Secara ringkas, \textit{prompt engineering} menitikberatkan cara merumuskan pertanyaan kepada AI, 
% sedangkan \textit{context engineering} menitikberatkan apa saja informasi pendukung yang disertakan 
% agar AI dapat menjawab dengan lebih baik. \textit{Context engineering} mengubah fokus dari sekadar 
% “seni” merangkai prompt menjadi “ilmu” mengelola informasi untuk optimalisasi sistem AI [3]. 
% Kedua pendekatan ini saling melengkapi: prompt yang baik diperlukan, namun penyajian konteks 
% yang tepat akan semakin meningkatkan kemampuan model dalam menyelesaikan tugas secara andal.

% \subsection{\textit{Learning Analytics} dan Cakupannya}
% Learning analytics adalah bidang kajian yang memanfaatkan data pendidikan untuk memahami dan 
% meningkatkan proses pembelajaran. Salah satu definisi yang umum dikutip menyatakan bahwa learning 
% analytics merupakan pengukuran, pengumpulan, analisis, dan pelaporan data tentang peserta didik 
% serta konteksnya, dengan tujuan memahami dan mengoptimalkan pembelajaran serta lingkungan 
% di mana pembelajaran tersebut berlangsung [4]. Dalam praktiknya, learning analytics mencakup 
% penggunaan berbagai sumber data (misalnya data aktivitas pada Learning Management System, 
% nilai akademik, log interaksi, dan sebagainya) untuk memperoleh wawasan yang dapat ditindaklanjuti 
% oleh pendidik, lembaga, ataupun peserta didik sendiri.

% Cakupan learning analytics sangat luas, meliputi beragam skenario dan kepentingan pendidikan. 
% Pada tingkat institusi, learning analytics digunakan untuk memonitor kinerja dan retensi mahasiswa. 
% Studi menunjukkan banyak institusi pendidikan menerapkan learning analytics terutama untuk 
% mengidentifikasi mahasiswa berisiko tinggi (misalnya berpotensi drop-out atau gagal studi) 
% dan mengambil langkah intervensi dini guna meningkatkan retensi [4]. Dengan analisis data 
% yang tepat, institusi dapat bersikap lebih preventif daripada reaktif. Model prediktif dapat 
% menandai siswa yang membutuhkan bantuan, sehingga advisor atau dosen dapat memberikan bimbingan 
% sebelum masalah berkembang lebih jauh [4]. Hasilnya, learning analytics berkontribusi pada 
% peningkatan keberhasilan studi melalui intervensi yang tepat sasaran.

% Di sisi lain, cakupan learning analytics juga mencakup tingkat kelas dan individu. Bagi pendidik, 
% analitik pembelajaran dapat dipakai untuk mengevaluasi efektivitas pengajaran dan kualitas 
% interaksi di kelas. Misalnya, data pola akses e-learning dan keterlibatan siswa dapat dianalisis 
% untuk mengetahui bagian materi mana yang sulit dipahami atau siapa siswa yang kurang aktif, 
% sehingga pendidik dapat menyesuaikan strategi pengajaran. Bagi pelajar, dashboard learning 
% analytics bisa memberikan umpan balik personal tentang progres belajar mereka, membantu 
% self-reflection dan pengambilan keputusan belajar yang lebih baik.

% Sebagai bidang multidisiplin, learning analytics memadukan teknik dari data science,
% machine learning, dan pendidikan. Penerapannya mencakup analisis deskriptif (melaporkan apa 
% yang terjadi dalam pembelajaran), diagnostik (mengapa sesuatu terjadi), prediktif (memprediksi 
% hasil atau risiko di masa depan, seperti kemungkinan drop-out), hingga preskriptif (memberikan 
% rekomendasi intervensi untuk perbaikan). Dengan kata lain, cakupan learning analytics tidak 
% hanya terbatas pada pelaporan statistik, tetapi juga pengambilan keputusan berbasis data 
% dalam pendidikan.

% Secara keseluruhan, learning analytics berperan sebagai alat bantu strategis bagi institusi 
% pendidikan untuk meningkatkan kualitas pembelajaran. Dari meningkatkan outcome belajar siswa, 
% mengoptimalkan penggunaan teknologi pendidikan, menurunkan tingkat putus studi, hingga 
% meningkatkan personalisasi pembelajaran, semuanya termasuk dalam ruang lingkup learning 
% analytics [4]. Dengan dukungan literatur ilmiah yang terus berkembang, learning analytics 
% menawarkan kerangka berbasis data untuk memahami proses belajar mengajar secara lebih 
% mendalam dan mendorong inovasi dalam praktik pendidikan.


% 	% [1]	Bertalan Meskó (2023). “Prompt Engineering as an Important Emerging Skill for Medical Professionals: Tutorial.” J. Med. Internet Res., 25(1):e50638 ￼.
% 	% [2]	Moorhouse, B.L. & Romina Jamieson-Proctor (2025). “Prompt engineering in higher education: a systematic review to help inform curricula.” Int. J. Educ. Technol. High. Educ., 22(39) ￼.
% 	% [3]	Lingrui Mei et al. (2025). “A Survey of Context Engineering for Large Language Models.” arXiv preprint arXiv:2507.13334 ￼ ￼.
% 	% [4]	Marcela Hernández-de-Menéndez et al. (2022). “Learning analytics: state of the art.” Int. J. Interact. Des. Manuf., 16:1209–1230 ￼ ￼.

% % Proses pembuatan \textit{game} dimulai dari pembuatan \textit{game design document} dimana 
% % dokumen ini akan menjadi landasan pengembangan game tersebut serta menginformasikan gambaran keseluruhan game yang akan dibuat \cite{ferdiana2012agile}. \textcolor{red}{\textit{Catatan: apapun yang diambil dari tulisan orang lain harus disitasi seperti dicontohkan \cite{ferdiana2012agile}.}}

% % \begin{figure}[ht]
% % 	\centering
% % 	\includegraphics[width=12cm]{contents/chapter-2/gambar-buatan-sendiri.png}
% % 	\caption[Contoh gambar]{Contoh gambar \cite{lukito2016}}
% % 	\label{Fig:gambar-buatan-sendiri}
% % \end{figure}



% % \textit{Game design document} adalah sebuah bagian penting dalam pembuatan game baik itu elemen-elemen penyusunnya maupun proses pengembangannya. Game design yang telah dibuat, dijabarkan satu persatu mengenai tahapan dalam pembuatan game dan hasilnya disatukan dalam bentuk dokumentasi \textit{game design document} yang digunakan oleh \textit{developer} sebagai buku petunjuk bagaimana membuat \textit{game} \cite{lukito2016}.

% % Dalam buku \textit{Game Design Essentials} disebutkan \textit{game design document} merupakan metode yang menghubungkan elemen-elemen penyusun \textit{game}, baik itu \textit{art, sound, program, 
% % gameplay} sehingga semuanya terdokumentasi menjadi satu dan menjadi acuan bagi para \textit{developer} dalam membuat \textit{game} \cite{wibirama2013dual}. 
% % \section{Penelitian Terkait}

% % \subsection{Studi Menggabungkan LLM dengan Learning Analytics}
% % Beberapa penelitian terbaru telah mengintegrasikan Large Language Models (LLM) dengan 
% % teknik learning analytics untuk meningkatkan pemberian umpan balik dan tutoring. 
% % Misalnya, TutorLLM (Li dkk., 2024) menggabungkan model knowledge tracing (KT) dengan 
% % retrieval-augmented generation (RAG) dalam LLM. TutorLLM memanfaatkan data jejak 
% % belajar tiap siswa (dari model KT BERT-based) serta pencarian konteks relevan, 
% % sehingga LLM dapat memberikan rekomendasi belajar yang dipersonalisasi sesuai 
% % status pengetahuan siswa dan mengurangi halusinasi [1]. Hasil evaluasi TutorLLM 
% % menunjukkan peningkatan kepuasan pengguna ~10\% dan skor kuis ~5\% dibanding 
% % penggunaan LLM umum tanpa personalisasi [1].

% % Studi LLM-KT (Wang dkk., 2025) juga menunjukkan pendekatan serupa dengan fokus 
% % pada knowledge tracing. LLM-KT menggunakan kerangka plug-and-play untuk menyelaraskan 
% % LLM dengan tugas KT, memanfaatkan kemampuan penalaran dan pengetahuan dunia luas 
% % dari LLM sekaligus memasukkan rekaman interaksi siswa secara sekuensial seperti 
% % pada model KT tradisional [2]. Melalui penyisipan konteks pertanyaan dan urutan 
% % jawaban historis ke dalam LLM, model hybrid ini mencapai kinerja state-of-the-art 
% % dalam memprediksi jawaban siswa di beberapa dataset KT klasik [2]. Ini menunjukkan 
% % potensi framework yang memadukan kekuatan LLM (fleksibilitas bahasa dan penalaran) 
% % dengan analitik pembelajaran tradisional (pelacakan pengetahuan sekuensial).

% % Selain itu, Reddig dkk. (2025) mengevaluasi penggunaan GPT-4 untuk memberikan umpan 
% % balik personal dalam konteks Intelligent Tutoring System (ITS). Studi ini 
% % menganalisis data kesalahan siswa dalam tutor aljabar lalu *mem-*prompt GPT-4 
% % untuk menghasilkan hint/koreksi spesifik terhadap kesalahan tersebut [3]. Hasilnya, 
% % model LLM cukup efektif mendiagnosis berbagai kesalahan siswa dan menghasilkan 
% % umpan balik relevan; namun sekitar 35\% hint yang dihasilkan terlalu umum, kurang 
% % tepat, atau justru langsung memberi jawaban [3]. Temuan ini menekankan bahwa meskipun 
% % LLM dapat meningkatkan skala dan personalisasi umpan balik, diperlukan mekanisme 
% % kontrol kualitas agar saran yang menyesatkan tidak ditampilkan pada siswa [3]. 
% % Menariknya, Reddig dkk. juga menguji kemampuan LLM untuk secara otomatis menilai 
% % kualitas umpan balik yang dibuatnya, sebagai upaya menggabungkan praktik tutoring 
% % terbukti dengan fleksibilitas LLM demi memperoleh “best of both worlds” [3].

% % Penelitian lain mengindikasikan efektivitas umpan balik berbasis LLM bergantung 
% % pada keterlibatan pelajar. Thomas dkk. (2025) menemukan bahwa dalam skenario 
% % pelatihan tutor, peserta yang memilih melihat penjelasan feedback dari LLM (ChatGPT) 
% % mendapat skor post-test lebih tinggi daripada yang tidak menggunakannya, 
% % dengan effect size moderat (~0.3) pada beberapa lesson [4]. Ini menunjukkan 
% % potensi LLM untuk memberikan umpan balik seefektif tutor manusia dalam konteks 
% % tertentu, asalkan penggunaannya terarah dan sesuai kebutuhan.



% % % [1] Z. Li et al., "TutorLLM: Customizing Learning Recommendations with Knowledge Tracing and Retrieval-Augmented Generation," in Proceedings of the 18th ACM Conference on Recommender Systems, Bari, Italy, Oct. 2024, pp. 1–10. doi: 10.1145/XXXXXX.XXXXXXX.

% % % [2] Z. Wang, J. Zhou, Q. Chen, M. Zhang, B. Jiang, A. Zhou, Q. Bai, and L. He, "LLM-KT: Aligning Large Language Models with Knowledge Tracing using a Plug-and-Play Instruction," in Proceedings of the XXX Conference, XXX, 2025, pp. 1–10. doi: 10.1145/XXXXXX.XXXXXXX.

% % % [3] J. M. Reddig, A. Arora, and C. J. MacLellan, "Generating In-Context, Personalized Feedback for Intelligent Tutors with Large Language Models," International Journal of Artificial Intelligence in Education, vol. 35, no. 3, pp. 1–25, Sep. 2025, doi: 10.1007/s40593-025-00505-6.
% % % [4] D. R. Thomas, C. Borchers, S. Bhushan, E. Gatz, S. Gupta, and K. R. Koedinger, "LLM-Generated Feedback Supports Learning If Learners Choose to Use It," arXiv preprint, arXiv:2506.17006, 2025. [Online]. Available: https://arxiv.org/abs/2506.17006

% % \subsection{Pendekatan Rekayasa dalam \textit{Learning Analytics}}

% % Dari sisi pendekatan rekayasa dalam learning analytics, beberapa karya menyoroti 
% % pentingnya merancang sistem yang dapat mengumpulkan dan menganalisis data proses 
% % belajar secara efisien, termasuk data “Kanban” atau pelacakan tugas belajar. 
% % Sebagai contoh, sebuah studi memanfaatkan papan Kanban untuk orkestrasi kelas 
% % sebagai alat self-regulated learning; papan tersebut menampilkan kartu tugas 
% % siswa dalam kolom “to do / in progress / done” untuk memvisualisasikan kemajuan 
% % mereka []1. Data status tugas di Kanban ini memberikan informasi real-time tentang 
% % progres dan keterlibatan siswa yang dapat dimanfaatkan guru. Bahkan, dikembangkan 
% % prototipe alat digital Kanban yang dirancang khusus untuk pendidikan 
% % (tidak bergantung pada Trello dkk. karena isu privasi) agar guru dapat 
% % menyiapkan template board dan mereplikasi ke banyak kelompok belajar [1].

% % Ke depan, platform Kanban edukasi semacam itu berpotensi diperluas dengan 
% % kapabilitas learning analytics langsung. Misalnya, Winter dkk. (2022) merancang 
% % alat Kanban kelas yang rencananya dilengkapi analytics berupa statistik otomatis, 
% % identifikasi “tugas yang macet”, rekomendasi khusus, serta dashboard guru untuk 
% % memantau semua papan siswa secara bersamaan [1]. Integrasi semacam ini menunjukkan 
% % pendekatan rekayasa di mana data pelacakan tugas mikro (misal, berapa lama tugas 
% % tertahan di kolom tertentu) dikumpulkan dan dianalisis guna memberi wawasan 
% % tindakan: guru dapat segera melihat siapa yang butuh bantuan 
% % (tugasnya lama di “in progress”), atau sistem bisa menyarankan intervensi pada 
% % tugas spesifik. Perekaman data proses semacam ini juga bermanfaat untuk penelitian 
% % edukasi dan evaluasi metode belajar, asalkan sesuai aturan privasi [1].

% % Lebih umum lagi, data proses (process data) dalam learning analytics, yaitu 
% % rekaman langkah-langkah atau interaksi saat siswa mengerjakan tugas yang dipandang 
% % kian penting untuk memahami pola belajar. Mazzullo dkk. (2023) menekankan bahwa 
% % pemanfaatan data proses (misal urutan klik, waktu respon, transisi antar tugas) 
% % dapat menghasilkan insight yang lebih interpretable tentang perilaku belajar 
% % dibanding sekadar nilai akhir [2]. Pendekatan rekayasa LA yang baik perlu mampu 
% % menangkap data proses ini dan menyajikannya secara informatif. Tantangan yang 
% % diidentifikasi meliputi bagaimana mendesain sistem LA dengan landasan pedagogis 
% % kuat, memastikan insight mudah dipahami, prediksi akurat, dan umpan balik yang 
% % dapat ditindaklanjuti [2]. Dengan kata lain, arsitektur LA harus dirancang tidak 
% % hanya untuk mengumpulkan data (termasuk data “kanban” tugas) tetapi juga untuk 
% % menganalisis dan menyajikannya dalam bentuk yang mendukung pengambilan keputusan 
% % pembelajaran.

% % % [1] S. Strickroth, M. Kreidenweis, and Z. Wurm, "Learning from Agile Methods: Using a Kanban Board for Classroom Orchestration," in Proceedings of the [Nama Konferensi], [Lokasi Konferensi], [Tahun], pp. [XX-YY]. doi: [DOI yang sesuai].
% % % [2] E. Mazzullo, O. Bulut, T. Wongvorachan, and B. Tan, "Learning Analytics in the Era of Large Language Models," Analytics, vol. 2, no. 4, pp. 877-898, Nov. 2023, doi: 10.3390/analytics2040046.


% % \subsection{Menghubungkan Hasil \textit{Learning Analytics} dengan Prompt \textit{Context-Aware} pada LLM}

% % Bidang ini semakin berkembang menuju penggabungan insight dari learning analytics 
% % dengan prompt engineering yang context-aware untuk meningkatkan kualitas output LLM.
% % Idenya adalah menjadikan LLM lebih “sadar konteks” situasi belajar individu, 
% % sehingga respon yang dihasilkan lebih tepat sasaran. Beberapa studi telah 
% % mengeksplorasi pendekatan ini.

% % Venugopalan dkk. (LAK 2025) mempelajari skenario hybrid tutoring di mana sistem 
% % tutoring tradisional digabung dengan LLM untuk mendukung orang tua yang membimbing 
% % anaknya belajar matematika. Mereka menggunakan prompt engineering dengan memasukkan 
% % konteks real-time dari ITS (misal: langkah pengerjaan siswa, kesalahan yang 
% % dilakukan, hint yang sudah diberikan) ke prompt LLM, ditambah contoh praktik 
% % tutoring yang baik (few-shot). Hasilnya, LLM (Llama 3) mampu menghasilkan 
% % rekomendasi percakapan bagi orang tua yang dinilai membantu meningkatkan dukungan 
% % metakognisi siswa (misal mendorong anak menjelaskan pikirannya) []. Studi ini 
% % menunjukkan bahwa memberikan konteks situasional (dari analytics ITS) dalam 
% % prompt dapat meng-align output LLM dengan strategi pedagogis yang diinginkan.

% % Demikian pula, TutorLLM yang disebut sebelumnya memanfaatkan contextual prompt 
% % secara otomatis: modul “Scraper” dalam arsitekturnya mengambil konten teks 
% % terkait materi belajar selama sesi online, lalu informasi itu bersama prediksi 
% % model KT tentang kelemahan siswa disuplai ke LLM (GPT-4) untuk menghasilkan 
% % jawaban yang akurat dan sesuai tingkat pemahaman siswa []. Dengan menambah 
% % pengetahuan latar kontekstual ke prompt, TutorLLM terbukti mengurangi risiko 
% % halusinasi dan meningkatkan relevansi jawaban terhadap kebutuhan spesifik 
% % siswa []. Ini adalah contoh konkret bagaimana hasil learning analytics 
% % (dalam hal ini profil pengetahuan siswa dari KT dan materi relevan yang 
% % di-retrieve) dapat tersambung langsung ke LLM sehingga responnya terpersonalisasi 
% % dan kontekstual.

% % Pendekatan serupa tampak pada studi Reddig dkk. (2025) tadi: alih-alih LLM 
% % bekerja “kosong”, mereka mem-prompt GPT-4 dengan input berupa deskripsi kesalahan 
% % spesifik yang dilakukan siswa pada tutor algebra, seolah memberikan konteks 
% % masalah dan kesalahan untuk diperbaiki []. Strategi prompting yang context-aware 
% % ini memungkinkan GPT-4 memberikan feedback yang lebih tepat karena “tahu” 
% % kesalahan mana yang terjadi. Reddig dkk. juga membahas pentingnya format 
% % prompt dan kriteria penilaian keluaran agar LLM tidak memberi jawaban terlalu 
% % langsung atau keliru []. Hal ini menggarisbawahi perlunya prompt engineering 
% % berbasis insight LA: misalnya menentukan informasi apa saja yang harus 
% % disertakan dalam prompt (error siswa, riwayat upaya, dll.) dan bagaimana 
% % meminta LLM memberikan keluaran (misal hint yang membimbing, bukannya solusi 
% % instan) []. Penelitian Stamper dkk. (2024) bahkan menyusun kerangka sistematis 
% % untuk merancang prompt LLM berbasis prinsip umpan balik ITS yang sudah teruji, 
% % seperti menentukan kapan LLM diberi trigger untuk menilai jawaban siswa, 
% % informasi apa yang perlu disertakan dalam prompt input ke LLM, dan jenis 
% % keluaran umpan balik apa yang diharapkan []. Pendekatan teoritis ini 
% % memastikan penggunaan LLM selaras dengan teori pendidikan (mis. umpan balik 
% % segera, spesifik, mendorong self-explanation) sehingga kualitas output-nya 
% % lebih terjamin.

% % Secara keseluruhan, tren riset ini menunjukkan upaya menggabungkan kekuatan 
% % learning analytics dengan kecerdasan generatif LLM. Learning analytics 
% % menyediakan data-driven insights tentang proses dan status belajar (misal: 
% % apa yang sudah dikuasai, kesalahan yang sering muncul, progress task di 
% % Kanban, dll.), sementara LLM dapat memanfaatkan konteks tersebut untuk 
% % menghasilkan umpan balik atau bimbingan yang adaptif. Mazzullo dkk. (2023) 
% % menyatakan bahwa implementasi LLM dalam LA dapat membantu memberikan insight 
% % yang lebih mudah dipahami, umpan balik yang lebih cepat dan actionable, 
% % peningkatan personalisasi, serta mendukung tugas-tugas guru secara lebih 
% % luas []. Dengan mengaitkan hasil analitik (misal deteksi kebuntuan tugas 
% % atau prediksi kemampuan) ke dalam prompt atau modul pengetahuan LLM, 
% % diharapkan output AI menjadi lebih relevan konteks dan berkualitas 
% % tinggi dalam mendukung pembelajaran. Ini juga area kebaruan yang bisa 
% % peneliti tekankan: membedakan bagaimana pendekatan mereka menyambungkan 
% % LA dan LLM secara lebih erat atau efektif dibanding studi-studi 
% % terdahulu seperti TutorLLM, LLM-KT, atau Reddig dkk. di atas.

% % % [1] D. Venugopalan, Z. Yan, C. Borchers, J. Lin, and V. Aleven, "Combining Large Language Models with Tutoring System Intelligence: A Case Study in Caregiver Homework Support," in Proceedings of the 15th International Conference on Learning Analytics & Knowledge (LAK '25), 2025, pp. 1–11. doi: 10.1145/3706468.3706516. arXiv preprint arXiv:2412.11995. [Online]. Available: https://arxiv.org/abs/2412.11995
% % % [2] Z. Li et al., "TutorLLM: Customizing Learning Recommendations with Knowledge Tracing and Retrieval-Augmented Generation," in Proceedings of the 18th ACM Conference on Recommender Systems, Bari, Italy, Oct. 2024, pp. 1–10. doi: 10.1145/XXXXXX.XXXXXXX.
% % % [3] J. M. Reddig, A. Arora, and C. J. MacLellan, "Generating In-Context, Personalized Feedback for Intelligent Tutors with Large Language Models," International Journal of Artificial Intelligence in Education, vol. 35, no. 3, pp. 1–25, Sep. 2025, doi: 10.1007/s40593-025-00505-6.
% % % [4] J. Stamper, R. Xiao, and X. Hou, "Enhancing LLM-Based Feedback: Insights from Intelligent Tutoring Systems and the Learning Sciences," in Proceedings of the [Conference Name], [Conference Location], [Year], pp. [Page Range]. doi: [DOI].
% % % [5] E. Mazzullo, O. Bulut, T. Wongvorachan, and B. Tan, "Learning Analytics in the Era of Large Language Models," Analytics, vol. 2, no. 4, pp. 877-898, Nov. 2023, doi: 10.3390/analytics2040046.


% % % \section{Hipotesis Penelitian}
% % % Diisi dengan hipotesis h0 dan h1.


% % \section{Analisis Perbandingan Metode}

% % Di dalam tinjauan pustaka hasil akhirnya adalah analisis secara kualitatif atau pun secara kuantitatif kelebihan dan kekurangan metode jika dikaitkan dengan masalah, batasan-batasan masalah dan solusi yang dinginkan. Analisis kuantitatif tidak wajib teapi mempunyai nilai tambah di dalam tugas akhir saudara. Bagian ini menjelaskan kenapa metode tersebut dipilih dan uraikan dengan lebih jelas metode pelaksanaan tugas akhir yang ingin Anda lakukan. 

% % \section{Pertanyaan Tugas Akhir (Jika Perlu)}

% % Pertanyaan tugas akhir bersifat opsional dan dapat ditambahkan untuk menekankan hal-hal yang hendak diketahui dari tugas akhir berdasar pada tujuan tugas akhir. Pertanyaan tugas akhir dikenal dengan RQ (\textit{Research Question}) dan harus memiliki keterkaitan dengan RO (\textit{Research Objective}). Satu RO dapat memiliki satu atau lebih dari satu RQ. 

